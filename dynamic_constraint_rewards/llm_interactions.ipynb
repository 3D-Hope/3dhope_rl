{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66721571",
   "metadata": {},
   "source": [
    "## PHASE 0: System Initialization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b938d0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.console import Console\n",
    "from rich.markdown import Markdown\n",
    "\n",
    "console = Console()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4180206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# different generator for different room types, so different dataset_context for each room type\n",
    "ROOM_TYPE = \"bedroom\"\n",
    "# general intro, idx_to_labels, coordinate system, measurement units,\n",
    "def get_dataset_context(room_type):\n",
    "    if room_type == \"bedroom\":\n",
    "        dataset_context = {  \n",
    "            \"room_type\": \"bedroom\",\n",
    "            \"total_scenes\": 4042,\n",
    "            \"class_frequencies\": {\n",
    "                \"nightstand\": 0.27245508982035926,\n",
    "                \"double_bed\": 0.17138137518067315,\n",
    "                \"wardrobe\": 0.16079909147222796,\n",
    "                \"pendant_lamp\": 0.12693578360520338,\n",
    "                \"ceiling_lamp\": 0.06308073508156102,\n",
    "                \"tv_stand\": 0.029888498864340286,\n",
    "                \"chair\": 0.022816436093330582,\n",
    "                \"single_bed\": 0.021216188313029113,\n",
    "                \"dressing_table\": 0.020854842040057817,\n",
    "                \"cabinet\": 0.020183770390253975,\n",
    "                \"table\": 0.019667561428866404,\n",
    "                \"desk\": 0.016260582283708445,\n",
    "                \"stool\": 0.011459838942804047,\n",
    "                \"shelf\": 0.0081561015899236,\n",
    "                \"kids_bed\": 0.0081561015899236,\n",
    "                \"bookshelf\": 0.0071753045632872185,\n",
    "                \"children_cabinet\": 0.0071753045632872185,\n",
    "                \"dressing_chair\": 0.006142886640512079,\n",
    "                \"armchair\": 0.003716704521990502,\n",
    "                \"sofa\": 0.0014970059880239522,\n",
    "                \"coffee_table\": 0.0009807970266363824\n",
    "            },\n",
    "            \"furniture_counts\": {\n",
    "                \"nightstand\": 5278,\n",
    "                \"double_bed\": 3320,\n",
    "                \"wardrobe\": 3115,\n",
    "                \"pendant_lamp\": 2459,\n",
    "                \"ceiling_lamp\": 1222,\n",
    "                \"tv_stand\": 579,\n",
    "                \"chair\": 442,\n",
    "                \"single_bed\": 411,\n",
    "                \"dressing_table\": 404,\n",
    "                \"cabinet\": 391,\n",
    "                \"table\": 381,\n",
    "                \"desk\": 315,\n",
    "                \"stool\": 222,\n",
    "                \"shelf\": 158,\n",
    "                \"kids_bed\": 158,\n",
    "                \"bookshelf\": 139,\n",
    "                \"children_cabinet\": 139,\n",
    "                \"dressing_chair\": 119,\n",
    "                \"armchair\": 72,\n",
    "                \"sofa\": 29,\n",
    "                \"coffee_table\": 19\n",
    "            },\n",
    "            \"idx_to_labels\": {\n",
    "                \"0\": \"armchair\",\n",
    "                \"1\": \"bookshelf\",\n",
    "                \"2\": \"cabinet\",\n",
    "                \"3\": \"ceiling_lamp\",\n",
    "                \"4\": \"chair\",\n",
    "                \"5\": \"children_cabinet\",\n",
    "                \"6\": \"coffee_table\",\n",
    "                \"7\": \"desk\",\n",
    "                \"8\": \"double_bed\",\n",
    "                \"9\": \"dressing_chair\",\n",
    "                \"10\": \"dressing_table\",\n",
    "                \"11\": \"kids_bed\",\n",
    "                \"12\": \"nightstand\",\n",
    "                \"13\": \"pendant_lamp\",\n",
    "                \"14\": \"shelf\",\n",
    "                \"15\": \"single_bed\",\n",
    "                \"16\": \"sofa\",\n",
    "                \"17\": \"stool\",\n",
    "                \"18\": \"table\",\n",
    "                \"19\": \"tv_stand\",\n",
    "                \"20\": \"wardrobe\",\n",
    "                \"21\": \"empty\"\n",
    "            },\n",
    "            \"num_classes_with_empty\": 22,\n",
    "            \"num_classes_without_empty\": 21,\n",
    "            \"room_type\": \"bedroom\",\n",
    "            \"max_objects\": 12\n",
    "        }\n",
    "    elif room_type == \"livingroom\":\n",
    "        dataset_context = {\n",
    "            \"room_type\": \"livingroom\",\n",
    "        \"total_scenes\": 2926,\n",
    "        \"class_frequencies\": {\n",
    "                \"dining_chair\": 0.25492085340674464,\n",
    "                \"pendant_lamp\": 0.13282863041982107,\n",
    "                \"coffee_table\": 0.08616655196145905,\n",
    "                \"corner_side_table\": 0.07240192704748796,\n",
    "                \"dining_table\": 0.06951135581555402,\n",
    "                \"tv_stand\": 0.06221610461114935,\n",
    "                \"multi_seat_sofa\": 0.05299380591878871,\n",
    "                \"armchair\": 0.048313833448038544,\n",
    "                \"console_table\": 0.037026841018582245,\n",
    "                \"lounge_chair\": 0.03234686854783207,\n",
    "                \"stool\": 0.0264280798348245,\n",
    "                \"cabinet\": 0.023124569855471438,\n",
    "                \"bookshelf\": 0.02202339986235375,\n",
    "                \"loveseat_sofa\": 0.020922229869236062,\n",
    "                \"ceiling_lamp\": 0.018169304886441844,\n",
    "                \"wine_cabinet\": 0.012112869924294563,\n",
    "                \"l_shaped_sofa\": 0.01032346868547832,\n",
    "                \"round_end_table\": 0.0057811424638678595,\n",
    "                \"shelf\": 0.0035788024776324846,\n",
    "                \"chinese_chair\": 0.0031658637302133517,\n",
    "                \"wardrobe\": 0.0027529249827942187,\n",
    "                \"chaise_longue_sofa\": 0.0011011699931176876,\n",
    "                \"desk\": 0.0009635237439779766,\n",
    "                \"lazy_sofa\": 0.0008258774948382657\n",
    "            },\n",
    "            \"furniture_counts\": {\n",
    "                \"dining_chair\": 1852,\n",
    "                \"pendant_lamp\": 965,\n",
    "                \"coffee_table\": 626,\n",
    "                \"corner_side_table\": 526,\n",
    "                \"dining_table\": 505,\n",
    "                \"tv_stand\": 452,\n",
    "                \"multi_seat_sofa\": 385,\n",
    "                \"armchair\": 351,\n",
    "                \"console_table\": 269,\n",
    "                \"lounge_chair\": 235,\n",
    "                \"stool\": 192,\n",
    "                \"cabinet\": 168,\n",
    "                \"bookshelf\": 160,\n",
    "                \"loveseat_sofa\": 152,\n",
    "                \"ceiling_lamp\": 132,\n",
    "                \"wine_cabinet\": 88,\n",
    "                \"l_shaped_sofa\": 75,\n",
    "                \"round_end_table\": 42,\n",
    "                \"shelf\": 26,\n",
    "                \"chinese_chair\": 23,\n",
    "                \"wardrobe\": 20,\n",
    "                \"chaise_longue_sofa\": 8,\n",
    "                \"desk\": 7,\n",
    "                \"lazy_sofa\": 6\n",
    "            },\n",
    "            \"idx_to_labels\": {\n",
    "                \"0\": \"armchair\",\n",
    "                \"1\": \"bookshelf\",\n",
    "                \"2\": \"cabinet\",\n",
    "                \"3\": \"ceiling_lamp\",\n",
    "                \"4\": \"chaise_longue_sofa\",\n",
    "                \"5\": \"chinese_chair\",\n",
    "                \"6\": \"coffee_table\",\n",
    "                \"7\": \"console_table\",\n",
    "                \"8\": \"corner_side_table\",\n",
    "                \"9\": \"desk\",\n",
    "                \"10\": \"dining_chair\",\n",
    "                \"11\": \"dining_table\",\n",
    "                \"12\": \"l_shaped_sofa\",\n",
    "                \"13\": \"lazy_sofa\",\n",
    "                \"14\": \"lounge_chair\",\n",
    "                \"15\": \"loveseat_sofa\",\n",
    "                \"16\": \"multi_seat_sofa\",\n",
    "                \"17\": \"pendant_lamp\",\n",
    "                \"18\": \"round_end_table\",\n",
    "                \"19\": \"shelf\",\n",
    "                \"20\": \"stool\",\n",
    "                \"21\": \"tv_stand\",\n",
    "                \"22\": \"wardrobe\",\n",
    "                \"23\": \"wine_cabinet\",\n",
    "                \"24\": \"empty\"\n",
    "                },\n",
    "            \"num_classes_with_empty\": 25,\n",
    "            \"num_classes_without_empty\": 24,\n",
    "            \"room_type\": \"livingroom\",\n",
    "            \"max_objects\": 21\n",
    "        }\n",
    "    else:\n",
    "        raise ValueError(f\"Room type {room_type} not supported\")\n",
    "\n",
    "    return dataset_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "734f48b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_facts = \"\"\"\n",
    "The dataset being used is 3D-FRONT which uses 3D-FUTURE dataset for furniture models. 3D-FRONT is a collection of synthetic, high-quality 3D indoor scenes, highlighted by professionally and distinctively designed layouts.\n",
    "\n",
    "In this dataset, the following facts are important to know:\n",
    "\n",
    "## Coordinate System\n",
    "- Y-axis: Vertical (up direction)\n",
    "- XZ-plane: Floor plane\n",
    "- Units: Meters (world coordinates, unnormalized)\n",
    "- Empty slots: Have index (num_classes-1), near-zero size/position\n",
    "\n",
    "# Important Facts about 3D-FRONT dataset\n",
    "- Ceiling objects are at y ≈ ceiling_height (typically 2.8m)\n",
    "- Floor objects have y ≈ object_height/2\n",
    "- Ignore empty slots (is_empty == True) in calculations\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c6f83c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_representation = \"\"\"\n",
    "A 3D scene is represented in batch format (parsed_scenes) a dictionary with the following keys and PyTorch tensors as values:\n",
    "    - `positions`: (B, N, 3) - Object centroids in meters (x, y, z)\n",
    "    - `sizes`: (B, N, 3) - Half-extents (sx/2, sy/2, sz/2)\n",
    "    - `object_indices`: (B, N) - Class indices [0, num_classes-1]\n",
    "    - `one_hot`: (B, N, num_classes) - One-hot encoded classes\n",
    "    - `is_empty`: (B, N) - Boolean mask (True = empty slot)\n",
    "    - `orientations`: (B, N, 2) - [cos(θ), sin(θ)] for z-rotation\n",
    "    - `device`: torch.device\n",
    "    Where:\n",
    "        - B = Batch size\n",
    "        - N = Max objects per scene\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c00b529",
   "metadata": {},
   "outputs": [],
   "source": [
    "room_stats = {\n",
    "    \"bedroom\": {\n",
    "        \"max_objects\": 12,\n",
    "        \"num_classes\": 22,\n",
    "        \"num_classes_with_empty\": 22,\n",
    "        \"num_classes_without_empty\": 21,\n",
    "    },\n",
    "    \"livingroom\": {\n",
    "        \"max_objects\": 21,\n",
    "        \"num_classes\": 25,\n",
    "        \"num_classes_with_empty\": 25,\n",
    "        \"num_classes_without_empty\": 24,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cad5d80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility functions for reward calculations\n",
    "import torch\n",
    "\n",
    "# Function templates for utility functions used in reward computations\n",
    "def find_object_front_and_back(position, orientation, size):\n",
    "    \"\"\"\n",
    "    Find the coordinates of the front and back centers of a object.\n",
    "\n",
    "    Args:\n",
    "        position: (1,3) tensor - object centroid (x, y, z)\n",
    "        orientation: (1,2) tensor - [cos(θ), sin(θ)], z-rotation\n",
    "        size: (1,3) tensor - half-extents (sx/2, sy/2, sz/2)\n",
    "    \n",
    "    Returns:\n",
    "        front_center: (1,3) tensor - position of object front\n",
    "        back_center: (1,3) tensor - position of object back\n",
    "    \"\"\"\n",
    "    \n",
    "    position_x, position_y, position_z = position[0]\n",
    "    orientation_cos, orientation_sin = orientation[0]\n",
    "    size_x, _, size_z = size[0]\n",
    "\n",
    "    front_center = torch.tensor([position_x + size_x * orientation_cos, position_y, position_z + size_z * orientation_sin], device=position.device)\n",
    "    back_center = torch.tensor([position_x - size_x * orientation_cos, position_y, position_z - size_z * orientation_sin], device=position.device)\n",
    "    return front_center, back_center\n",
    "\n",
    "def find_closest_wall_to_object(position, orientation, size, floor_polygons):\n",
    "    \"\"\"\n",
    "    Find which wall is closest to the object's front or back and compute its distance.\n",
    "\n",
    "    Args:\n",
    "        position: (1,3) tensor - object centroid (x, y, z)\n",
    "        orientation: (1,2) tensor - z-rotation\n",
    "        size: (1,3) tensor - half-extents (sx/2, sy/2, sz/2)\n",
    "        floor_polygons: list of ordered floor polygon vertices in the format [(x1, z1), (x2, z2), ...(xn, zn)]  where n >= 4, and always forms a closed polygon\n",
    "    \n",
    "    Returns:\n",
    "        wall_index: (1) tensor - index of the wall in floor_polygons (i.e., wall_index = 0 means the wall formed by floor_polygons[0] and floor_polygons[1])\n",
    "        distance: (1) tensor - perpendicular distance from object centroid to wall\n",
    "    \"\"\"\n",
    "    front_center, back_center = find_object_front_and_back(position, orientation, size)\n",
    "    distances = []\n",
    "    for i in range(len(floor_polygons)):\n",
    "        point1 = floor_polygons[i]\n",
    "        point2 = floor_polygons[(i+1)%len(floor_polygons)]\n",
    "        midpoint = (point1 + point2) / 2\n",
    "        distance_front = distance_2d(front_center, midpoint)\n",
    "        distance_back = distance_2d(back_center, midpoint)\n",
    "        distances.append(min(distance_front, distance_back))\n",
    "    return distances.index(min(distances)), min(distances)\n",
    "\n",
    "def compute_angle_between_objects(orientation1, orientation2):\n",
    "    \"\"\"\n",
    "    Calculate angle in degrees between two objects in xz-plane.\n",
    "\n",
    "    Args:\n",
    "        orientation1: orientation of object 1,  (1,2) tensor - [cos(θ), sin(θ)], z-rotation\n",
    "        orientation2: orientation of object 2, (1,2) tensor - [cos(θ), sin(θ)], z-rotation\n",
    "\n",
    "    Returns:\n",
    "        angle_radians: (1) tensor - angle between objects\n",
    "    \"\"\"\n",
    "    # Calculate angle in degrees between the facing direction vectors of two objects in xz-plane\n",
    "    # (i.e., project orientation onto xz-plane, compute relative angle)\n",
    "    orientation1_angle = torch.atan2(orientation1[1], orientation1[0])\n",
    "    orientation2_angle = torch.atan2(orientation2[1], orientation2[0])\n",
    "    delta = orientation2_angle - orientation1_angle\n",
    "    # unwrap to [-pi, pi]\n",
    "    angle_radians = (delta + torch.pi) % (2 * torch.pi) - torch.pi\n",
    "    \n",
    "    return angle_radians\n",
    "    \n",
    "def distance_2d(point1, point2):\n",
    "    \"\"\"\n",
    "    Compute Euclidean distance in the XZ plane between two sets of points.\n",
    "\n",
    "    Args:\n",
    "        position1: (1,3) tensor - xyz\n",
    "        position2: (1,3) tensor - xyz\n",
    "\n",
    "    Returns:\n",
    "        distances: (1) tensor - distance between points\n",
    "    \"\"\"\n",
    "    return torch.sqrt((point1[0] - point2[0])**2 + (point1[2] - point2[2])**2)\n",
    "\n",
    "def get_object_count_in_a_scene(one_hot, class_label, idx_to_labels):\n",
    "    \"\"\"\n",
    "    Count number of objects of a specific class in each scene.\n",
    "\n",
    "    Args:\n",
    "        one_hot: (B, N, num_classes) - One-hot encoded classes\n",
    "        class_label: string, e.g. \"ceiling_lamp\"\n",
    "        idx_to_labels: dict, {idx: label}\n",
    "\n",
    "    Returns:\n",
    "        count: int, number of objects of class_label in the scene\n",
    "    \"\"\"\n",
    "    \n",
    "    labels_to_idx = {v: k for k, v in idx_to_labels.items()}\n",
    "    \n",
    "    for i in range(one_hot.shape[1]):\n",
    "        if one_hot[0, i, labels_to_idx[class_label]] == 1.0:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def has_x_meter_clearance(parsed_scenes, x, direction):\n",
    "    \"\"\"\n",
    "    Check whether there is at least x meters of path clearance around objects.\n",
    "\n",
    "    Args:\n",
    "        parsed_scenes: list/dict with scene info\n",
    "        x: float, required clearance in meters\n",
    "        direction: float, z_angle in radians\n",
    "    Returns:\n",
    "        clearance_mask: tensor/list (B,) - True if scene satisfies clearance\n",
    "    \"\"\"\n",
    "    raise NotImplementedError(\"This function is not implemented\")\n",
    "    \n",
    "    \n",
    "\n",
    "# Utility function to create a scene for testing reward functions\n",
    "def create_scene_for_testing(room_type, num_objects, class_label_indices, translations, sizes, orientations):\n",
    "    \"\"\"\n",
    "    Create a scene for testing reward functions.\n",
    "    Input:\n",
    "        room_type: string, Example: \"bedroom\" or \"livingroom\"\n",
    "        num_objects: int, number of objects in the scene\n",
    "        class_label_indices: list of int, class indices\n",
    "        translations: list of tuple, (x, y, z) translations\n",
    "        sizes: list of tuple, (sx/2, sy/2, sz/2) sizes\n",
    "        orientations: list of tuple, (cos(θ), sin(θ)) orientations\n",
    "        \n",
    "    Output:\n",
    "        parsed_scene: dict, scene representation\n",
    "    \"\"\"\n",
    "    max_num_objects, num_classes = room_stats[room_type][\"max_objects\"], room_stats[room_type][\"num_classes\"]\n",
    "    B = 1  # Single scene for testing\n",
    "    N = max_num_objects\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # Create empty arrays\n",
    "    one_hot = torch.zeros(B, N, num_classes, dtype=torch.float32, device=device)\n",
    "    positions = torch.zeros(B, N, 3, dtype=torch.float32, device=device)\n",
    "    obj_sizes = torch.zeros(B, N, 3, dtype=torch.float32, device=device)\n",
    "    obj_orientations = torch.zeros(B, N, 2, dtype=torch.float32, device=device)\n",
    "    object_indices = torch.full((B, N), num_classes-1, dtype=torch.long, device=device)  # default is empty class\n",
    "    is_empty = torch.ones(B, N, dtype=torch.bool, device=device)  # mark all empty by default\n",
    "\n",
    "    for i in range(num_objects):\n",
    "        idx = class_label_indices[i]\n",
    "        one_hot[0, i, idx] = 1.0\n",
    "        positions[0, i] = torch.tensor(translations[i], dtype=torch.float32, device=device)\n",
    "        obj_sizes[0, i] = torch.tensor(sizes[i], dtype=torch.float32, device=device)\n",
    "        obj_orientations[0, i] = torch.tensor(orientations[i], dtype=torch.float32, device=device)\n",
    "        object_indices[0, i] = idx\n",
    "        is_empty[0, i] = False\n",
    "\n",
    "    # Fill the one_hot for empty slots (if any)\n",
    "    for i in range(num_objects, N):\n",
    "        one_hot[0, i, num_classes - 1] = 1.0  # Mark as \"empty\"\n",
    "\n",
    "    parsed_scene = {\n",
    "        \"one_hot\": one_hot,  # (B, N, num_classes)\n",
    "        \"positions\": positions,  # (B, N, 3)\n",
    "        \"sizes\": obj_sizes,      # (B, N, 3) (half-extents)\n",
    "        \"orientations\": obj_orientations,  # (B, N, 2)\n",
    "        \"object_indices\": object_indices,  # (B, N)\n",
    "        \"is_empty\": is_empty,              # (B, N)\n",
    "        \"room_type\": room_type,\n",
    "        \"device\": torch.device(device),\n",
    "    }\n",
    "    return parsed_scene\n",
    "\n",
    "    \n",
    "\n",
    "# A dictionary of all utility functions stated above with key as function name and value as a dictionary with a function and its description (function docstring itself)\n",
    "utility_functions = {\n",
    "    \"find_object_front_and_back\": {\n",
    "        \"function\": find_object_front_and_back,\n",
    "        \"description\": find_object_front_and_back.__doc__,\n",
    "    },\n",
    "    \"find_closest_wall_to_object\": {\n",
    "        \"function\": find_closest_wall_to_object,\n",
    "        \"description\": find_closest_wall_to_object.__doc__,\n",
    "    },\n",
    "    \"compute_angle_between_objects\": {\n",
    "        \"function\": compute_angle_between_objects,\n",
    "        \"description\": compute_angle_between_objects.__doc__,\n",
    "    },\n",
    "    \"distance_2d\": {\n",
    "        \"function\": distance_2d,\n",
    "        \"description\": distance_2d.__doc__,\n",
    "    },\n",
    "    \"get_object_count_in_a_scene\": {\n",
    "        \"function\": get_object_count_in_a_scene,\n",
    "        \"description\": get_object_count_in_a_scene.__doc__,\n",
    "    },\n",
    "    \"has_x_meter_clearance\": {\n",
    "        \"function\": has_x_meter_clearance,\n",
    "        \"description\": has_x_meter_clearance.__doc__,\n",
    "    },\n",
    "    \"create_scene_for_testing\": {\n",
    "        \"function\": create_scene_for_testing,\n",
    "        \"description\": create_scene_for_testing.__doc__,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7386f32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reward function template, put the detailed arg datatypes and descriptions\n",
    "reward_function_template = f\"\"\"\n",
    "def get_reward(parsed_scenes, idx_to_labels, room_type, floor_polygons, **kwargs):\n",
    "    '''\n",
    "    Input:\n",
    "        - parsed_scenes: list of parsed scenes\n",
    "            Format:\n",
    "            Scenes are provided as dictionaries with PyTorch tensors:\n",
    "                - `positions`: (B, N, 3) - Object centroids in meters (x, y, z)\n",
    "                - `sizes`: (B, N, 3) - Half-extents (sx/2, sy/2, sz/2)\n",
    "                - `object_indices`: (B, N) - Class indices [0, num_classes-1]\n",
    "                - `one_hot`: (B, N, num_classes) - One-hot encoded classes\n",
    "                - `is_empty`: (B, N) - Boolean mask (True = empty slot)\n",
    "                - `orientations`: (B, N, 2) - [cos(θ), sin(θ)] for z-rotation\n",
    "                - `device`: torch.device\n",
    "                Where:\n",
    "                    - B = Batch size\n",
    "                    - N = Max objects per scene\n",
    "        \n",
    "        - idx_to_labels: dictionary mapping class indices to class labels\n",
    "        - room_type: string, Example: \"bedroom\" or \"livingroom\"\n",
    "        - Floor Polygons (floor_polygons): A list of ordered floor_polygons in the format [(x1, z1), (x2, z2), ...(xn, zn)]  where n >= 4, and always forms a closed polygon\n",
    "        - **kwargs: additional keyword arguments\n",
    "\n",
    "    Output:\n",
    "        reward: torch.Tensor of shape (len(parsed_scenes),)\n",
    "    '''\n",
    "    \n",
    "    # Logic of reward function here\n",
    "    return reward\n",
    "\n",
    "def test_reward(idx_to_labels, room_type, floor_polygons, **kwargs):\n",
    "    '''\n",
    "    Input:\n",
    "        - idx_to_labels: dictionary mapping class indices to class labels\n",
    "        - room_type: string, Example: \"bedroom\" or \"livingroom\"\n",
    "        - floor_polygons: A list of ordered floor_polygons in the format [(x1, z1), (x2, z2), ...(xn, zn)]  where n >= 4, and always forms a closed polygon\n",
    "        - **kwargs: additional keyword arguments\n",
    "    '''\n",
    "    # Create a test scene using create_scene_for_testing\n",
    "    # Scene 1\n",
    "    num_objects_1 = 5\n",
    "    class_label_indices_1 = [0, 1, 2, 3, 4]\n",
    "    translations_1 = [(0, 0, 0), (1, 0, 0), (2, 0, 0), (3, 0, 0), (4, 0, 0)]\n",
    "    sizes_1 = [(0.5, 0.5, 0.5), (0.5, 0.5, 0.5), (0.5, 0.5, 0.5), (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)]\n",
    "    orientations_1 = [(1, 0), (1, 0), (1, 0), (1, 0), (1, 0)]\n",
    "    parsed_scene_1 = create_scene_for_testing(room_type, num_objects_1, class_label_indices_1, translations_1, sizes_1, orientations_1)\n",
    "    \n",
    "    # Scene 2\n",
    "    num_objects_2 = 6\n",
    "    class_label_indices_2 = [0, 1, 2, 3, 4, 5]\n",
    "    translations_2 = [(0, 0, 0), (1, 0, 0), (2, 0, 0), (3, 0, 0), (4, 0, 0), (5, 0, 0),]\n",
    "    sizes_2 = [(0.5, 0.5, 0.5), (0.5, 0.5, 0.5), (0.5, 0.5, 0.5), (0.5, 0.5, 0.5), (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)]\n",
    "    orientations_2 = [(1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0)]\n",
    "    parsed_scene_2 = create_scene_for_testing(room_type, num_objects_2, class_label_indices_2, translations_2, sizes_2, orientations_2)\n",
    "    \n",
    "    # Scene 3\n",
    "    num_objects_3 = 4\n",
    "    class_label_indices_3 = [0, 1, 3, 4]\n",
    "    translations_3 = [(0, 0, 0), (1, 0, 0), (2, 0, 0), (3, 0, 0)]\n",
    "    sizes_3 = [(0.5, 0.5, 0.5), (0.5, 0.5, 0.5), (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)]\n",
    "    orientations_3 = [(1, 0), (1, 0), (1, 0), (1, 0)]\n",
    "    parsed_scene_3 = create_scene_for_testing(room_type, num_objects_3, class_label_indices_3, translations_3, sizes_3, orientations_3)\n",
    "    \n",
    "    \n",
    "    parsed_scenes = torch.stack([parsed_scene_1, parsed_scene_2, parsed_scene_3])\n",
    "    rewards = get_reward(parsed_scenes, idx_to_labels, room_type, floor_polygons)\n",
    "    print(\"Rewards:\", rewards)\n",
    "    assert rewards.shape[0] == len(parsed_scenes)\n",
    "    \n",
    "    # write test cases for different scenarios to test syntax and basic functionality along with reward function specific test cases\n",
    "    # TEST CASES HERE\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3caa372",
   "metadata": {},
   "outputs": [],
   "source": [
    "from universal_constraint_rewards.commons import get_all_universal_reward_functions\n",
    "\n",
    "universal_rewards_info = get_all_universal_reward_functions()\n",
    "universal_rewards_info_with_docstrings = {}\n",
    "\n",
    "for reward_name, reward_info in universal_rewards_info.items():\n",
    "    universal_rewards_info_with_docstrings[reward_name] = {\n",
    "        \"function\": reward_info,\n",
    "        \"description\": reward_info.__doc__,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2cee3abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'must_have_furniture': {'function': <function universal_constraint_rewards.must_have_furniture_reward.compute_must_have_furniture_reward(parsed_scene, room_type='bedroom', **kwargs)>,\n",
       "  'description': \"\\n    Calculate reward based on whether the scene contains required furniture for the room type.\\n\\n    For bedrooms: must have at least one bed (single_bed, double_bed, or kids_bed)\\n\\n    Args:\\n        parsed_scene: Dict returned by parse_and_descale_scenes()\\n        room_type: Type of room (default: 'bedroom'). Currently only 'bedroom' is supported.\\n\\n    Returns:\\n        rewards: Tensor of shape (B,) with must-have furniture rewards for each scene\\n    \"},\n",
       " 'non_penetration': {'function': <function universal_constraint_rewards.non_penetration_reward.compute_non_penetration_reward(parsed_scene, **kwargs)>,\n",
       "  'description': '\\n    Calculate reward based on non-penetration constraint using penetration depth.\\n\\n    Following the approach from original authors: reward = sum of negative signed distances.\\n    When objects overlap, we get positive penetration depth, so reward is negative.\\n\\n    Args:\\n        parsed_scene: Dict returned by parse_and_descale_scenes()\\n\\n    Returns:\\n        rewards: Tensor of shape (B,) with non-penetration rewards for each scene\\n    '},\n",
       " 'object_count': {'function': <function universal_constraint_rewards.object_count_reward.compute_object_count_reward(parsed_scene, mode='nll', target_count=5.0, std_dev=1.43, **kwargs)>,\n",
       "  'description': \"\\n    Calculate reward based on object count distribution.\\n\\n    Three modes:\\n    1. KL mode (default, recommended): Uses KL divergence between batch distribution\\n       and empirical training distribution. Encourages diversity and prevents mode collapse.\\n    2. NLL mode: Uses negative log-likelihood per scene (legacy)\\n    3. Gaussian mode: Uses squared deviation from mean (legacy)\\n\\n    Args:\\n        parsed_scene: Dict returned by parse_and_descale_scenes() with batch dimension\\n        mode: 'kl' (default), 'nll', or 'gaussian'\\n        target_count: Expected number of objects (used only for gaussian mode)\\n        std_dev: Standard deviation (used only for gaussian mode)\\n        **kwargs: Additional arguments (ignored, for compatibility)\\n\\n    Returns:\\n        rewards: Tensor of shape (B,) with object count rewards for each scene\\n    \"},\n",
       " 'not_out_of_bound': {'function': <function universal_constraint_rewards.not_out_of_bound_reward.compute_boundary_violation_reward(parsed_scene: Dict[str, torch.Tensor], floor_polygons: torch.Tensor, is_val: bool, indices: List[int], sdf_cache, grid_resolution: float = 0.05, **kwargs) -> torch.Tensor>,\n",
       "  'description': \"\\n    Compute boundary violation reward using cached SDF grids.\\n    \\n    **IMPORTANT**: Call `precompute_sdf_cache()` once before training to generate cache!\\n    \\n    Args:\\n        parsed_scene: Dictionary with positions, sizes, is_empty, device\\n        floor_polygons: (B, num_vertices, 2) - only needed if cache doesn't exist\\n        indices: (B,) - scene indices for SDF lookup\\n        grid_resolution: SDF grid resolution\\n        sdf_cache_dir: Directory containing cached SDF grids\\n        \\n    Returns:\\n        rewards: (B, 1) - sum of negative violation distances per scene\\n    \"},\n",
       " 'accessibility': {'function': <function universal_constraint_rewards.accessibility_reward.compute_accessibility_reward(parsed_scenes: Dict[str, torch.Tensor], floor_polygons: torch.Tensor, is_val: bool, indices: List[int], accessibility_cache=None, grid_resolution: float = 0.1, agent_radius: float = 0.15, save_viz: bool = False, viz_dir: str = './viz', **kwargs) -> Dict[str, torch.Tensor]>,\n",
       "  'description': \"\\n    Compute accessibility reward using cached floor grids or computing on-the-fly.\\n    \\n    Returns dict with 3 components:\\n    - coverage_ratio: [0, 1] - fraction of floor reachable from largest region\\n    - num_regions: [1, ∞) - number of disconnected regions\\n    - avg_clearance: meters - average distance to nearest obstacle in reachable area\\n    \\n    Args:\\n        parsed_scenes: Dictionary with positions, sizes, is_empty, device, object_types\\n        floor_polygons: (B, num_vertices, 2) - floor polygon vertices\\n        is_val: Whether this is validation split\\n        indices: (B,) - scene indices for cache lookup\\n        accessibility_cache: Pre-loaded AccessibilityCache instance (optional)\\n        grid_resolution: Grid resolution in meters (default 0.2m = 20cm)\\n        agent_radius: Agent radius in meters (default 0.15m = 15cm)\\n        save_viz: Whether to save visualization images\\n        viz_dir: Directory to save visualizations\\n        \\n    Returns:\\n        Dictionary with:\\n        - 'coverage_ratio': (B,) - reachable area ratio [0, 1]\\n        - 'num_regions': (B,) - number of disconnected regions [1, ∞)\\n        - 'avg_clearance': (B,) - average clearance in meters\\n    \"},\n",
       " 'gravity_following': {'function': <function universal_constraint_rewards.gravity_following_reward.compute_gravity_following_reward(parsed_scene, tolerance=0.01, **kwargs)>,\n",
       "  'description': '\\n    Calculate gravity-following reward based on how close objects are to the ground.\\n    \\n    Objects should rest on the floor (y_min ≈ 0), except for ceiling objects.\\n    Only penalizes objects that are MORE than tolerance away from the floor(both sinking and floating cases).\\n    \\n    Args:\\n        parsed_scene: Dict returned by parse_and_descale_scenes()\\n        tolerance: Distance threshold in meters (default 0.01m = 1cm)\\n    \\n    Returns:\\n        rewards: Tensor of shape (B,) with gravity-following rewards\\n    '},\n",
       " 'night_tables_on_head_side': {'function': <function universal_constraint_rewards.night_tables_on_head_side_reward.compute_nightstand_placement_reward(parsed_scenes, floor_polygons, idx_to_labels, **kwargs)>,\n",
       "  'description': \"\\n    Penalizes scenes where:\\n      - Both nightstands are placed on the same side of the bed.\\n      - A nightstand is at the foot side of the bed (soft penalty based on distance).\\n    \\n    For each bed-nightstand pair:\\n    1. Find headboard position of bed (same logic as wall proximity)\\n    2. Determine which side of bed each nightstand is on (left/right relative to headboard)\\n    3. Compute how far toward foot side it is; apply distance-based penalty\\n    4. Penalize if both nightstands on same side or too far from head side\\n\\n    Args:\\n        parsed_scenes: Dict with keys:\\n            - 'positions': (B, N, 3) - object positions (x, y, z)\\n            - 'orientations': (B, N, 2) - [cos_theta, sin_theta]\\n            - 'sizes': (B, N, 3) - object half-extents (already halved)\\n            - 'object_indices': (B, N) - object class indices\\n            - 'is_empty': (B, N) - mask for empty slots\\n        floor_polygons: List of length B (not used but kept for signature compatibility)\\n        idx_to_labels: Dict mapping indices to object class names\\n\\n    Returns:\\n        rewards: (B,) - nightstand placement reward per scene (negative penalty)\\n    \"},\n",
       " 'axis_alignment': {'function': <function universal_constraint_rewards.axis_alignment_reward.compute_axis_alignment_reward(parsed_scenes, **kwargs)>,\n",
       "  'description': \"\\n    Reward objects for being axis-aligned (parallel/perpendicular to walls).\\n\\n    Penalizes angular deviation from 0°, 90°, 180°, 270° for furniture that\\n    should typically be placed against walls.\\n\\n    Args:\\n        parsed_scenes: Dict with keys:\\n            - 'orientations': (B, N, 2) - [cos_theta, sin_theta] for each object\\n            - 'object_indices': (B, N) - object class indices\\n            - 'is_empty': (B, N) - mask for empty slots\\n        idx_to_labels: Dict mapping indices to object class names\\n\\n    Returns:\\n        rewards: (B,) - alignment reward per scene (negative of total violation)\\n    \"},\n",
       " 'furniture_against_wall': {'function': <function universal_constraint_rewards.furniture_against_wall_reward.compute_wall_proximity_reward(parsed_scenes, floor_polygons, idx_to_labels, **kwargs)>,\n",
       "  'description': \"\\n    Reward furniture for having their back/headboard close to walls.\\n\\n    For each furniture:\\n    1. Calculate headboard position based on rotation\\n    2. Cast ray from headboard toward wall\\n    3. Find nearest wall edge intersection\\n    4. Measure distance\\n\\n    Args:\\n        parsed_scenes: Dict with keys:\\n            - 'positions': (B, N, 3) - object positions (x, y, z)\\n            - 'orientations': (B, N, 2) - [cos_theta, sin_theta]\\n            - 'sizes': (B, N, 3) - object half-extents (already halved)\\n            - 'object_indices': (B, N) - object class indices\\n            - 'is_empty': (B, N) - mask for empty slots\\n        floor_polygons: List of length B, each containing (M, 2) polygon vertices [x, z]\\n        idx_to_labels: Dict mapping indices to object class names\\n        viz_batch_idx: (optional, int) If provided, will save a visualization for this batch index.\\n\\n    Returns:\\n        rewards: (B,) - wall proximity reward per scene (negative of total distance)\\n    \"}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "universal_rewards_info_with_docstrings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190cb236",
   "metadata": {},
   "source": [
    "## PHASE 1: Initial Constraint Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65ee1277",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_PROMPT = \"A bedroom with 4 ceiling_lamps forming a rectangular shape.\" # out of distribution example\n",
    "ROOM_TYPE = \"bedroom\"\n",
    "\n",
    "dataset_context = get_dataset_context(ROOM_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e821a953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid using f-string here to prevent invalid format specifier error\n",
    "llm_instruction_1 = f\"\"\"\n",
    "# TASK: Constraint Decomposition for 3D Scene Generation\n",
    "\n",
    "You are an expert in 3D scene generation, interior design, and reinforcement learning. Your task is to analyze a user prompt and decompose it into verifiable constraints with Python reward functions.\n",
    "\n",
    "## USER PROMPT\n",
    "\\\"{USER_PROMPT}\\\"\n",
    "\n",
    "## CONTEXT\n",
    "\n",
    "### Dataset: 3D-FRONT\n",
    "{dataset_facts}\n",
    "\n",
    "Note: While generating constraints, no need to verify these facts with you constraints, focus on the constraints other than these facts.\n",
    "\n",
    "In this task, you are provided with a user prompt and a dataset context. Your task is to decompose the user prompt into verifiable constraints with Python reward functions.\n",
    "\n",
    "Here is the dataset information in JSON format about the specific room type: {ROOM_TYPE} you will be working on:\n",
    "{dataset_context}\n",
    "\n",
    "Also, the baseline model is already trained on some universal constraints, so you do not need to consider these constraints while generating new ones. The universal constraints are:\n",
    "{universal_rewards_info_with_docstrings}\n",
    "\n",
    "## YOUR TASK\n",
    "\n",
    "Analyze the user prompt and provide a comprehensive JSON response with the following structure:\n",
    "\n",
    "### 1. CONSTRAINT DECOMPOSITION\n",
    "\n",
    "Generate ALL constraints needed to satisfy the prompt strictly in following format.\n",
    "\n",
    "```json\n",
    "{{\n",
    "  \"constraints\": [\n",
    "    {{\n",
    "      \"id\": \"C1\",\n",
    "      \"name\": \"descriptive_snake_case_name\",\n",
    "      \"description\": \"Clear description of what this checks\"\n",
    "    }},\n",
    "    {{\n",
    "      \"id\": \"C2\",\n",
    "      \"name\": \"descriptive_snake_case_name\",\n",
    "      \"description\": \"Clear description of what this checks\"\n",
    "    }},\n",
    "    ...\n",
    "    {{\n",
    "      \"id\": \"Cn\",\n",
    "      \"name\": \"descriptive_snake_case_name\",\n",
    "      \"description\": \"Clear description of what this checks\"\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "697377ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃                             <span style=\"font-weight: bold\">TASK: Constraint Decomposition for 3D Scene Generation</span>                              ┃\n",
       "┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\n",
       "\n",
       "You are an expert in 3D scene generation, interior design, and reinforcement learning. Your task is to analyze a   \n",
       "user prompt and decompose it into verifiable constraints with Python reward functions.                             \n",
       "\n",
       "\n",
       "                                                    <span style=\"font-weight: bold; text-decoration: underline\">USER PROMPT</span>                                                    \n",
       "\n",
       "\"A bedroom with 4 ceiling_lamps forming a rectangular shape.\"                                                      \n",
       "\n",
       "\n",
       "                                                      <span style=\"font-weight: bold; text-decoration: underline\">CONTEXT</span>                                                      \n",
       "\n",
       "                                                 <span style=\"font-weight: bold\">Dataset: 3D-FRONT</span>                                                 \n",
       "\n",
       "The dataset being used is 3D-FRONT which uses 3D-FUTURE dataset for furniture models. 3D-FRONT is a collection of  \n",
       "synthetic, high-quality 3D indoor scenes, highlighted by professionally and distinctively designed layouts.        \n",
       "\n",
       "In this dataset, the following facts are important to know:                                                        \n",
       "\n",
       "\n",
       "                                                 <span style=\"font-weight: bold; text-decoration: underline\">Coordinate System</span>                                                 \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Y-axis: Vertical (up direction)                                                                                 \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>XZ-plane: Floor plane                                                                                           \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Units: Meters (world coordinates, unnormalized)                                                                 \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Empty slots: Have index (num_classes-1), near-zero size/position                                                \n",
       "\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃                                     <span style=\"font-weight: bold\">Important Facts about 3D-FRONT dataset</span>                                      ┃\n",
       "┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Ceiling objects are at y ≈ ceiling_height (typically 2.8m)                                                      \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Floor objects have y ≈ object_height/2                                                                          \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Ignore empty slots (is_empty == True) in calculations                                                           \n",
       "\n",
       "Note: While generating constraints, no need to verify these facts with you constraints, focus on the constraints   \n",
       "other than these facts.                                                                                            \n",
       "\n",
       "In this task, you are provided with a user prompt and a dataset context. Your task is to decompose the user prompt \n",
       "into verifiable constraints with Python reward functions.                                                          \n",
       "\n",
       "Here is the dataset information in JSON format about the specific room type: bedroom you will be working on:       \n",
       "{'room_type': 'bedroom', 'total_scenes': 4042, 'class_frequencies': {'nightstand': 0.27245508982035926,            \n",
       "'double_bed': 0.17138137518067315, 'wardrobe': 0.16079909147222796, 'pendant_lamp': 0.12693578360520338,           \n",
       "'ceiling_lamp': 0.06308073508156102, 'tv_stand': 0.029888498864340286, 'chair': 0.022816436093330582, 'single_bed':\n",
       "0.021216188313029113, 'dressing_table': 0.020854842040057817, 'cabinet': 0.020183770390253975, 'table':            \n",
       "0.019667561428866404, 'desk': 0.016260582283708445, 'stool': 0.011459838942804047, 'shelf': 0.0081561015899236,    \n",
       "'kids_bed': 0.0081561015899236, 'bookshelf': 0.0071753045632872185, 'children_cabinet': 0.0071753045632872185,     \n",
       "'dressing_chair': 0.006142886640512079, 'armchair': 0.003716704521990502, 'sofa': 0.0014970059880239522,           \n",
       "'coffee_table': 0.0009807970266363824}, 'furniture_counts': {'nightstand': 5278, 'double_bed': 3320, 'wardrobe':   \n",
       "3115, 'pendant_lamp': 2459, 'ceiling_lamp': 1222, 'tv_stand': 579, 'chair': 442, 'single_bed': 411,                \n",
       "'dressing_table': 404, 'cabinet': 391, 'table': 381, 'desk': 315, 'stool': 222, 'shelf': 158, 'kids_bed': 158,     \n",
       "'bookshelf': 139, 'children_cabinet': 139, 'dressing_chair': 119, 'armchair': 72, 'sofa': 29, 'coffee_table': 19}, \n",
       "'idx_to_labels': {'0': 'armchair', '1': 'bookshelf', '2': 'cabinet', '3': 'ceiling_lamp', '4': 'chair', '5':       \n",
       "'children_cabinet', '6': 'coffee_table', '7': 'desk', '8': 'double_bed', '9': 'dressing_chair', '10':              \n",
       "'dressing_table', '11': 'kids_bed', '12': 'nightstand', '13': 'pendant_lamp', '14': 'shelf', '15': 'single_bed',   \n",
       "'16': 'sofa', '17': 'stool', '18': 'table', '19': 'tv_stand', '20': 'wardrobe', '21': 'empty'},                    \n",
       "'num_classes_with_empty': 22, 'num_classes_without_empty': 21, 'max_objects': 12}                                  \n",
       "\n",
       "Also, the baseline model is already trained on some universal constraints, so you do not need to consider these    \n",
       "constraints while generating new ones. The universal constraints are: {'must_have_furniture': {'function':         \n",
       "&lt;function compute_must_have_furniture_reward at 0x7fe8df749000&gt;, 'description': \"\\n    Calculate reward based on   \n",
       "whether the scene contains required furniture for the room type.\\n\\n    For bedrooms: must have at least one bed   \n",
       "(single_bed, double_bed, or kids_bed)\\n\\n    Args:\\n        parsed_scene: Dict returned by                         \n",
       "parse_and_descale_scenes()\\n        room_type: Type of room (default: 'bedroom'). Currently only 'bedroom' is      \n",
       "supported.\\n\\n    Returns:\\n        rewards: Tensor of shape (B,) with must-have furniture rewards for each scene\\n\n",
       "\"}, 'non_penetration': {'function': &lt;function compute_non_penetration_reward at 0x7fe8df7492d0&gt;, 'description': '\\n\n",
       "Calculate reward based on non-penetration constraint using penetration depth.\\n\\n    Following the approach from   \n",
       "original authors: reward = sum of negative signed distances.\\n    When objects overlap, we get positive penetration\n",
       "depth, so reward is negative.\\n\\n    Args:\\n        parsed_scene: Dict returned by parse_and_descale_scenes()\\n\\n  \n",
       "Returns:\\n        rewards: Tensor of shape (B,) with non-penetration rewards for each scene\\n    '},               \n",
       "'object_count': {'function': &lt;function compute_object_count_reward at 0x7fe8df7497e0&gt;, 'description': \"\\n          \n",
       "Calculate reward based on object count distribution.\\n\\n    Three modes:\\n    1. KL mode (default, recommended):   \n",
       "Uses KL divergence between batch distribution\\n       and empirical training distribution. Encourages diversity and\n",
       "prevents mode collapse.\\n    2. NLL mode: Uses negative log-likelihood per scene (legacy)\\n    3. Gaussian mode:   \n",
       "Uses squared deviation from mean (legacy)\\n\\n    Args:\\n        parsed_scene: Dict returned by                     \n",
       "parse_and_descale_scenes() with batch dimension\\n        mode: 'kl' (default), 'nll', or 'gaussian'\\n              \n",
       "target_count: Expected number of objects (used only for gaussian mode)\\n        std_dev: Standard deviation (used  \n",
       "only for gaussian mode)\\n        **kwargs: Additional arguments (ignored, for compatibility)\\n\\n    Returns:\\n     \n",
       "rewards: Tensor of shape (B,) with object count rewards for each scene\\n    \"}, 'not_out_of_bound': {'function':   \n",
       "&lt;function compute_boundary_violation_reward at 0x7fe8df764a60&gt;, 'description': \"\\n    Compute boundary violation   \n",
       "reward using cached SDF grids.\\n    \\n    <span style=\"font-weight: bold\">IMPORTANT</span>: Call <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">precompute_sdf_cache()</span> once before training to generate  \n",
       "cache!\\n    \\n    Args:\\n        parsed_scene: Dictionary with positions, sizes, is_empty, device\\n                \n",
       "floor_polygons: (B, num_vertices, 2) - only needed if cache doesn't exist\\n        indices: (B,) - scene indices   \n",
       "for SDF lookup\\n        grid_resolution: SDF grid resolution\\n        sdf_cache_dir: Directory containing cached   \n",
       "SDF grids\\n        \\n    Returns:\\n        rewards: (B, 1) - sum of negative violation distances per scene\\n    \"},\n",
       "'accessibility': {'function': &lt;function compute_accessibility_reward at 0x7fe8df7664d0&gt;, 'description': \"\\n        \n",
       "Compute accessibility reward using cached floor grids or computing on-the-fly.\\n    \\n    Returns dict with 3      \n",
       "components:\\n    - coverage_ratio: [0, 1] - fraction of floor reachable from largest region\\n    - num_regions: [1,\n",
       "∞) - number of disconnected regions\\n    - avg_clearance: meters - average distance to nearest obstacle in         \n",
       "reachable area\\n    \\n    Args:\\n        parsed_scenes: Dictionary with positions, sizes, is_empty, device,        \n",
       "object_types\\n        floor_polygons: (B, num_vertices, 2) - floor polygon vertices\\n        is_val: Whether this  \n",
       "is validation split\\n        indices: (B,) - scene indices for cache lookup\\n        accessibility_cache:          \n",
       "Pre-loaded AccessibilityCache instance (optional)\\n        grid_resolution: Grid resolution in meters (default 0.2m\n",
       "= 20cm)\\n        agent_radius: Agent radius in meters (default 0.15m = 15cm)\\n        save_viz: Whether to save    \n",
       "visualization images\\n        viz_dir: Directory to save visualizations\\n        \\n    Returns:\\n        Dictionary\n",
       "with:\\n        - 'coverage_ratio': (B,) - reachable area ratio [0, 1]\\n        - 'num_regions': (B,) - number of   \n",
       "disconnected regions [1, ∞)\\n        - 'avg_clearance': (B,) - average clearance in meters\\n    \"},                \n",
       "'gravity_following': {'function': &lt;function compute_gravity_following_reward at 0x7fe8df765d80&gt;, 'description': '\\n\n",
       "Calculate gravity-following reward based on how close objects are to the ground.\\n    \\n    Objects should rest on \n",
       "the floor (y_min ≈ 0), except for ceiling objects.\\n    Only penalizes objects that are MORE than tolerance away   \n",
       "from the floor(both sinking and floating cases).\\n    \\n    Args:\\n        parsed_scene: Dict returned by          \n",
       "parse_and_descale_scenes()\\n        tolerance: Distance threshold in meters (default 0.01m = 1cm)\\n    \\n          \n",
       "Returns:\\n        rewards: Tensor of shape (B,) with gravity-following rewards\\n    '},                            \n",
       "'night_tables_on_head_side': {'function': &lt;function compute_nightstand_placement_reward at 0x7fe875d37640&gt;,        \n",
       "'description': \"\\n    Penalizes scenes where:\\n      - Both nightstands are placed on the same side of the bed.\\n  \n",
       "- A nightstand is at the foot side of the bed (soft penalty based on distance).\\n    \\n    For each bed-nightstand \n",
       "pair:\\n    1. Find headboard position of bed (same logic as wall proximity)\\n    2. Determine which side of bed    \n",
       "each nightstand is on (left/right relative to headboard)\\n    3. Compute how far toward foot side it is; apply     \n",
       "distance-based penalty\\n    4. Penalize if both nightstands on same side or too far from head side\\n\\n    Args:\\n  \n",
       "parsed_scenes: Dict with keys:\\n            - 'positions': (B, N, 3) - object positions (x, y, z)\\n            -   \n",
       "'orientations': (B, N, 2) - [cos_theta, sin_theta]\\n            - 'sizes': (B, N, 3) - object half-extents (already\n",
       "halved)\\n            - 'object_indices': (B, N) - object class indices\\n            - 'is_empty': (B, N) - mask for\n",
       "empty slots\\n        floor_polygons: List of length B (not used but kept for signature compatibility)\\n            \n",
       "idx_to_labels: Dict mapping indices to object class names\\n\\n    Returns:\\n        rewards: (B,) - nightstand      \n",
       "placement reward per scene (negative penalty)\\n    \"}, 'axis_alignment': {'function': &lt;function                    \n",
       "compute_axis_alignment_reward at 0x7fe875d377f0&gt;, 'description': \"\\n    Reward objects for being axis-aligned      \n",
       "(parallel/perpendicular to walls).\\n\\n    Penalizes angular deviation from 0°, 90°, 180°, 270° for furniture that\\n\n",
       "should typically be placed against walls.\\n\\n    Args:\\n        parsed_scenes: Dict with keys:\\n            -      \n",
       "'orientations': (B, N, 2) - [cos_theta, sin_theta] for each object\\n            - 'object_indices': (B, N) - object\n",
       "class indices\\n            - 'is_empty': (B, N) - mask for empty slots\\n        idx_to_labels: Dict mapping indices\n",
       "to object class names\\n\\n    Returns:\\n        rewards: (B,) - alignment reward per scene (negative of total       \n",
       "violation)\\n    \"}, 'furniture_against_wall': {'function': &lt;function compute_wall_proximity_reward at              \n",
       "0x7fe875d379a0&gt;, 'description': \"\\n    Reward furniture for having their back/headboard close to walls.\\n\\n    For \n",
       "each furniture:\\n    1. Calculate headboard position based on rotation\\n    2. Cast ray from headboard toward      \n",
       "wall\\n    3. Find nearest wall edge intersection\\n    4. Measure distance\\n\\n    Args:\\n        parsed_scenes: Dict\n",
       "with keys:\\n            - 'positions': (B, N, 3) - object positions (x, y, z)\\n            - 'orientations': (B, N,\n",
       "2) - [cos_theta, sin_theta]\\n            - 'sizes': (B, N, 3) - object half-extents (already halved)\\n            -\n",
       "'object_indices': (B, N) - object class indices\\n            - 'is_empty': (B, N) - mask for empty slots\\n         \n",
       "floor_polygons: List of length B, each containing (M, 2) polygon vertices [x, z]\\n        idx_to_labels: Dict      \n",
       "mapping indices to object class names\\n        viz_batch_idx: (optional, int) If provided, will save a             \n",
       "visualization for this batch index.\\n\\n    Returns:\\n        rewards: (B,) - wall proximity reward per scene       \n",
       "(negative of total distance)\\n    \"}}                                                                              \n",
       "\n",
       "\n",
       "                                                     <span style=\"font-weight: bold; text-decoration: underline\">YOUR TASK</span>                                                     \n",
       "\n",
       "Analyze the user prompt and provide a comprehensive JSON response with the following structure:                    \n",
       "\n",
       "                                            <span style=\"font-weight: bold\">1. CONSTRAINT DECOMPOSITION</span>                                            \n",
       "\n",
       "Generate ALL constraints needed to satisfy the prompt strictly in following format.                                \n",
       "\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">{</span><span style=\"background-color: #272822\">                                                                                                                 </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">  </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">\"constraints\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">: [</span><span style=\"background-color: #272822\">                                                                                                </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    {</span><span style=\"background-color: #272822\">                                                                                                             </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">      </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">\"id\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">: </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"C1\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">                                                                                                 </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">      </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">\"name\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">: </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"descriptive_snake_case_name\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">                                                                      </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">      </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">\"description\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">: </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"Clear description of what this checks\"</span><span style=\"background-color: #272822\">                                                      </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    },</span><span style=\"background-color: #272822\">                                                                                                            </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    {</span><span style=\"background-color: #272822\">                                                                                                             </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">      </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">\"id\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">: </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"C2\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">                                                                                                 </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">      </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">\"name\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">: </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"descriptive_snake_case_name\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">                                                                      </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">      </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">\"description\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">: </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"Clear description of what this checks\"</span><span style=\"background-color: #272822\">                                                      </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    },</span><span style=\"background-color: #272822\">                                                                                                            </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #ed007e; text-decoration-color: #ed007e; background-color: #1e0010\">...</span><span style=\"background-color: #272822\">                                                                                                           </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    {</span><span style=\"background-color: #272822\">                                                                                                             </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">      </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">\"id\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">: </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"Cn\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">                                                                                                 </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">      </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">\"name\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">: </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"descriptive_snake_case_name\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">                                                                      </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">      </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">\"description\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">: </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"Clear description of what this checks\"</span><span style=\"background-color: #272822\">                                                      </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    }</span><span style=\"background-color: #272822\">                                                                                                             </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">  ]</span><span style=\"background-color: #272822\">                                                                                                               </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">}</span><span style=\"background-color: #272822\">                                                                                                                 </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃                             \u001b[1mTASK: Constraint Decomposition for 3D Scene Generation\u001b[0m                              ┃\n",
       "┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\n",
       "\n",
       "You are an expert in 3D scene generation, interior design, and reinforcement learning. Your task is to analyze a   \n",
       "user prompt and decompose it into verifiable constraints with Python reward functions.                             \n",
       "\n",
       "\n",
       "                                                    \u001b[1;4mUSER PROMPT\u001b[0m                                                    \n",
       "\n",
       "\"A bedroom with 4 ceiling_lamps forming a rectangular shape.\"                                                      \n",
       "\n",
       "\n",
       "                                                      \u001b[1;4mCONTEXT\u001b[0m                                                      \n",
       "\n",
       "                                                 \u001b[1mDataset: 3D-FRONT\u001b[0m                                                 \n",
       "\n",
       "The dataset being used is 3D-FRONT which uses 3D-FUTURE dataset for furniture models. 3D-FRONT is a collection of  \n",
       "synthetic, high-quality 3D indoor scenes, highlighted by professionally and distinctively designed layouts.        \n",
       "\n",
       "In this dataset, the following facts are important to know:                                                        \n",
       "\n",
       "\n",
       "                                                 \u001b[1;4mCoordinate System\u001b[0m                                                 \n",
       "\n",
       "\u001b[1;33m • \u001b[0mY-axis: Vertical (up direction)                                                                                 \n",
       "\u001b[1;33m • \u001b[0mXZ-plane: Floor plane                                                                                           \n",
       "\u001b[1;33m • \u001b[0mUnits: Meters (world coordinates, unnormalized)                                                                 \n",
       "\u001b[1;33m • \u001b[0mEmpty slots: Have index (num_classes-1), near-zero size/position                                                \n",
       "\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃                                     \u001b[1mImportant Facts about 3D-FRONT dataset\u001b[0m                                      ┃\n",
       "┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\n",
       "\n",
       "\u001b[1;33m • \u001b[0mCeiling objects are at y ≈ ceiling_height (typically 2.8m)                                                      \n",
       "\u001b[1;33m • \u001b[0mFloor objects have y ≈ object_height/2                                                                          \n",
       "\u001b[1;33m • \u001b[0mIgnore empty slots (is_empty == True) in calculations                                                           \n",
       "\n",
       "Note: While generating constraints, no need to verify these facts with you constraints, focus on the constraints   \n",
       "other than these facts.                                                                                            \n",
       "\n",
       "In this task, you are provided with a user prompt and a dataset context. Your task is to decompose the user prompt \n",
       "into verifiable constraints with Python reward functions.                                                          \n",
       "\n",
       "Here is the dataset information in JSON format about the specific room type: bedroom you will be working on:       \n",
       "{'room_type': 'bedroom', 'total_scenes': 4042, 'class_frequencies': {'nightstand': 0.27245508982035926,            \n",
       "'double_bed': 0.17138137518067315, 'wardrobe': 0.16079909147222796, 'pendant_lamp': 0.12693578360520338,           \n",
       "'ceiling_lamp': 0.06308073508156102, 'tv_stand': 0.029888498864340286, 'chair': 0.022816436093330582, 'single_bed':\n",
       "0.021216188313029113, 'dressing_table': 0.020854842040057817, 'cabinet': 0.020183770390253975, 'table':            \n",
       "0.019667561428866404, 'desk': 0.016260582283708445, 'stool': 0.011459838942804047, 'shelf': 0.0081561015899236,    \n",
       "'kids_bed': 0.0081561015899236, 'bookshelf': 0.0071753045632872185, 'children_cabinet': 0.0071753045632872185,     \n",
       "'dressing_chair': 0.006142886640512079, 'armchair': 0.003716704521990502, 'sofa': 0.0014970059880239522,           \n",
       "'coffee_table': 0.0009807970266363824}, 'furniture_counts': {'nightstand': 5278, 'double_bed': 3320, 'wardrobe':   \n",
       "3115, 'pendant_lamp': 2459, 'ceiling_lamp': 1222, 'tv_stand': 579, 'chair': 442, 'single_bed': 411,                \n",
       "'dressing_table': 404, 'cabinet': 391, 'table': 381, 'desk': 315, 'stool': 222, 'shelf': 158, 'kids_bed': 158,     \n",
       "'bookshelf': 139, 'children_cabinet': 139, 'dressing_chair': 119, 'armchair': 72, 'sofa': 29, 'coffee_table': 19}, \n",
       "'idx_to_labels': {'0': 'armchair', '1': 'bookshelf', '2': 'cabinet', '3': 'ceiling_lamp', '4': 'chair', '5':       \n",
       "'children_cabinet', '6': 'coffee_table', '7': 'desk', '8': 'double_bed', '9': 'dressing_chair', '10':              \n",
       "'dressing_table', '11': 'kids_bed', '12': 'nightstand', '13': 'pendant_lamp', '14': 'shelf', '15': 'single_bed',   \n",
       "'16': 'sofa', '17': 'stool', '18': 'table', '19': 'tv_stand', '20': 'wardrobe', '21': 'empty'},                    \n",
       "'num_classes_with_empty': 22, 'num_classes_without_empty': 21, 'max_objects': 12}                                  \n",
       "\n",
       "Also, the baseline model is already trained on some universal constraints, so you do not need to consider these    \n",
       "constraints while generating new ones. The universal constraints are: {'must_have_furniture': {'function':         \n",
       "<function compute_must_have_furniture_reward at 0x7fe8df749000>, 'description': \"\\n    Calculate reward based on   \n",
       "whether the scene contains required furniture for the room type.\\n\\n    For bedrooms: must have at least one bed   \n",
       "(single_bed, double_bed, or kids_bed)\\n\\n    Args:\\n        parsed_scene: Dict returned by                         \n",
       "parse_and_descale_scenes()\\n        room_type: Type of room (default: 'bedroom'). Currently only 'bedroom' is      \n",
       "supported.\\n\\n    Returns:\\n        rewards: Tensor of shape (B,) with must-have furniture rewards for each scene\\n\n",
       "\"}, 'non_penetration': {'function': <function compute_non_penetration_reward at 0x7fe8df7492d0>, 'description': '\\n\n",
       "Calculate reward based on non-penetration constraint using penetration depth.\\n\\n    Following the approach from   \n",
       "original authors: reward = sum of negative signed distances.\\n    When objects overlap, we get positive penetration\n",
       "depth, so reward is negative.\\n\\n    Args:\\n        parsed_scene: Dict returned by parse_and_descale_scenes()\\n\\n  \n",
       "Returns:\\n        rewards: Tensor of shape (B,) with non-penetration rewards for each scene\\n    '},               \n",
       "'object_count': {'function': <function compute_object_count_reward at 0x7fe8df7497e0>, 'description': \"\\n          \n",
       "Calculate reward based on object count distribution.\\n\\n    Three modes:\\n    1. KL mode (default, recommended):   \n",
       "Uses KL divergence between batch distribution\\n       and empirical training distribution. Encourages diversity and\n",
       "prevents mode collapse.\\n    2. NLL mode: Uses negative log-likelihood per scene (legacy)\\n    3. Gaussian mode:   \n",
       "Uses squared deviation from mean (legacy)\\n\\n    Args:\\n        parsed_scene: Dict returned by                     \n",
       "parse_and_descale_scenes() with batch dimension\\n        mode: 'kl' (default), 'nll', or 'gaussian'\\n              \n",
       "target_count: Expected number of objects (used only for gaussian mode)\\n        std_dev: Standard deviation (used  \n",
       "only for gaussian mode)\\n        **kwargs: Additional arguments (ignored, for compatibility)\\n\\n    Returns:\\n     \n",
       "rewards: Tensor of shape (B,) with object count rewards for each scene\\n    \"}, 'not_out_of_bound': {'function':   \n",
       "<function compute_boundary_violation_reward at 0x7fe8df764a60>, 'description': \"\\n    Compute boundary violation   \n",
       "reward using cached SDF grids.\\n    \\n    \u001b[1mIMPORTANT\u001b[0m: Call \u001b[1;36;40mprecompute_sdf_cache()\u001b[0m once before training to generate  \n",
       "cache!\\n    \\n    Args:\\n        parsed_scene: Dictionary with positions, sizes, is_empty, device\\n                \n",
       "floor_polygons: (B, num_vertices, 2) - only needed if cache doesn't exist\\n        indices: (B,) - scene indices   \n",
       "for SDF lookup\\n        grid_resolution: SDF grid resolution\\n        sdf_cache_dir: Directory containing cached   \n",
       "SDF grids\\n        \\n    Returns:\\n        rewards: (B, 1) - sum of negative violation distances per scene\\n    \"},\n",
       "'accessibility': {'function': <function compute_accessibility_reward at 0x7fe8df7664d0>, 'description': \"\\n        \n",
       "Compute accessibility reward using cached floor grids or computing on-the-fly.\\n    \\n    Returns dict with 3      \n",
       "components:\\n    - coverage_ratio: [0, 1] - fraction of floor reachable from largest region\\n    - num_regions: [1,\n",
       "∞) - number of disconnected regions\\n    - avg_clearance: meters - average distance to nearest obstacle in         \n",
       "reachable area\\n    \\n    Args:\\n        parsed_scenes: Dictionary with positions, sizes, is_empty, device,        \n",
       "object_types\\n        floor_polygons: (B, num_vertices, 2) - floor polygon vertices\\n        is_val: Whether this  \n",
       "is validation split\\n        indices: (B,) - scene indices for cache lookup\\n        accessibility_cache:          \n",
       "Pre-loaded AccessibilityCache instance (optional)\\n        grid_resolution: Grid resolution in meters (default 0.2m\n",
       "= 20cm)\\n        agent_radius: Agent radius in meters (default 0.15m = 15cm)\\n        save_viz: Whether to save    \n",
       "visualization images\\n        viz_dir: Directory to save visualizations\\n        \\n    Returns:\\n        Dictionary\n",
       "with:\\n        - 'coverage_ratio': (B,) - reachable area ratio [0, 1]\\n        - 'num_regions': (B,) - number of   \n",
       "disconnected regions [1, ∞)\\n        - 'avg_clearance': (B,) - average clearance in meters\\n    \"},                \n",
       "'gravity_following': {'function': <function compute_gravity_following_reward at 0x7fe8df765d80>, 'description': '\\n\n",
       "Calculate gravity-following reward based on how close objects are to the ground.\\n    \\n    Objects should rest on \n",
       "the floor (y_min ≈ 0), except for ceiling objects.\\n    Only penalizes objects that are MORE than tolerance away   \n",
       "from the floor(both sinking and floating cases).\\n    \\n    Args:\\n        parsed_scene: Dict returned by          \n",
       "parse_and_descale_scenes()\\n        tolerance: Distance threshold in meters (default 0.01m = 1cm)\\n    \\n          \n",
       "Returns:\\n        rewards: Tensor of shape (B,) with gravity-following rewards\\n    '},                            \n",
       "'night_tables_on_head_side': {'function': <function compute_nightstand_placement_reward at 0x7fe875d37640>,        \n",
       "'description': \"\\n    Penalizes scenes where:\\n      - Both nightstands are placed on the same side of the bed.\\n  \n",
       "- A nightstand is at the foot side of the bed (soft penalty based on distance).\\n    \\n    For each bed-nightstand \n",
       "pair:\\n    1. Find headboard position of bed (same logic as wall proximity)\\n    2. Determine which side of bed    \n",
       "each nightstand is on (left/right relative to headboard)\\n    3. Compute how far toward foot side it is; apply     \n",
       "distance-based penalty\\n    4. Penalize if both nightstands on same side or too far from head side\\n\\n    Args:\\n  \n",
       "parsed_scenes: Dict with keys:\\n            - 'positions': (B, N, 3) - object positions (x, y, z)\\n            -   \n",
       "'orientations': (B, N, 2) - [cos_theta, sin_theta]\\n            - 'sizes': (B, N, 3) - object half-extents (already\n",
       "halved)\\n            - 'object_indices': (B, N) - object class indices\\n            - 'is_empty': (B, N) - mask for\n",
       "empty slots\\n        floor_polygons: List of length B (not used but kept for signature compatibility)\\n            \n",
       "idx_to_labels: Dict mapping indices to object class names\\n\\n    Returns:\\n        rewards: (B,) - nightstand      \n",
       "placement reward per scene (negative penalty)\\n    \"}, 'axis_alignment': {'function': <function                    \n",
       "compute_axis_alignment_reward at 0x7fe875d377f0>, 'description': \"\\n    Reward objects for being axis-aligned      \n",
       "(parallel/perpendicular to walls).\\n\\n    Penalizes angular deviation from 0°, 90°, 180°, 270° for furniture that\\n\n",
       "should typically be placed against walls.\\n\\n    Args:\\n        parsed_scenes: Dict with keys:\\n            -      \n",
       "'orientations': (B, N, 2) - [cos_theta, sin_theta] for each object\\n            - 'object_indices': (B, N) - object\n",
       "class indices\\n            - 'is_empty': (B, N) - mask for empty slots\\n        idx_to_labels: Dict mapping indices\n",
       "to object class names\\n\\n    Returns:\\n        rewards: (B,) - alignment reward per scene (negative of total       \n",
       "violation)\\n    \"}, 'furniture_against_wall': {'function': <function compute_wall_proximity_reward at              \n",
       "0x7fe875d379a0>, 'description': \"\\n    Reward furniture for having their back/headboard close to walls.\\n\\n    For \n",
       "each furniture:\\n    1. Calculate headboard position based on rotation\\n    2. Cast ray from headboard toward      \n",
       "wall\\n    3. Find nearest wall edge intersection\\n    4. Measure distance\\n\\n    Args:\\n        parsed_scenes: Dict\n",
       "with keys:\\n            - 'positions': (B, N, 3) - object positions (x, y, z)\\n            - 'orientations': (B, N,\n",
       "2) - [cos_theta, sin_theta]\\n            - 'sizes': (B, N, 3) - object half-extents (already halved)\\n            -\n",
       "'object_indices': (B, N) - object class indices\\n            - 'is_empty': (B, N) - mask for empty slots\\n         \n",
       "floor_polygons: List of length B, each containing (M, 2) polygon vertices [x, z]\\n        idx_to_labels: Dict      \n",
       "mapping indices to object class names\\n        viz_batch_idx: (optional, int) If provided, will save a             \n",
       "visualization for this batch index.\\n\\n    Returns:\\n        rewards: (B,) - wall proximity reward per scene       \n",
       "(negative of total distance)\\n    \"}}                                                                              \n",
       "\n",
       "\n",
       "                                                     \u001b[1;4mYOUR TASK\u001b[0m                                                     \n",
       "\n",
       "Analyze the user prompt and provide a comprehensive JSON response with the following structure:                    \n",
       "\n",
       "                                            \u001b[1m1. CONSTRAINT DECOMPOSITION\u001b[0m                                            \n",
       "\n",
       "Generate ALL constraints needed to satisfy the prompt strictly in following format.                                \n",
       "\n",
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m{\u001b[0m\u001b[48;2;39;40;34m                                                                                                                \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m  \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m\"constraints\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[48;2;39;40;34m                                                                                               \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m{\u001b[0m\u001b[48;2;39;40;34m                                                                                                            \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m      \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m\"id\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"C1\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                                                                                \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m      \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m\"name\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"descriptive_snake_case_name\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                                                     \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m      \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m\"description\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"Clear description of what this checks\"\u001b[0m\u001b[48;2;39;40;34m                                                     \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m},\u001b[0m\u001b[48;2;39;40;34m                                                                                                           \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m{\u001b[0m\u001b[48;2;39;40;34m                                                                                                            \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m      \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m\"id\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"C2\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                                                                                \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m      \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m\"name\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"descriptive_snake_case_name\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                                                     \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m      \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m\"description\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"Clear description of what this checks\"\u001b[0m\u001b[48;2;39;40;34m                                                     \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m},\u001b[0m\u001b[48;2;39;40;34m                                                                                                           \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;237;0;126;48;2;30;0;16m.\u001b[0m\u001b[38;2;237;0;126;48;2;30;0;16m.\u001b[0m\u001b[38;2;237;0;126;48;2;30;0;16m.\u001b[0m\u001b[48;2;39;40;34m                                                                                                          \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m{\u001b[0m\u001b[48;2;39;40;34m                                                                                                            \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m      \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m\"id\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"Cn\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                                                                                \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m      \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m\"name\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"descriptive_snake_case_name\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                                                     \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m      \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m\"description\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"Clear description of what this checks\"\u001b[0m\u001b[48;2;39;40;34m                                                     \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m}\u001b[0m\u001b[48;2;39;40;34m                                                                                                            \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m  \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[48;2;39;40;34m                                                                                                              \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m}\u001b[0m\u001b[48;2;39;40;34m                                                                                                                \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "console.print(Markdown(llm_instruction_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07c380d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"constraints\": [\n",
      "    {\n",
      "      \"id\": \"C1\",\n",
      "      \"name\": \"exact_ceiling_lamp_count\",\n",
      "      \"description\": \"The scene must contain exactly 4 objects of the class 'ceiling_lamp'.\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"C2\",\n",
      "      \"name\": \"ceiling_lamps_form_rectangle\",\n",
      "      \"description\": \"The XZ-plane projections of the four 'ceiling_lamp' objects must form a rectangle. This is verified by checking if, for any pairing of the four lamps into two diagonals, the diagonals bisect each other and have equal length. This constraint only applies if there are exactly 4 ceiling lamps.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "llm_response_1 = client.models.generate_content(\n",
    "    model=\"gemini-2.5-pro\",\n",
    "    contents=llm_instruction_1,\n",
    ")\n",
    "\n",
    "print(llm_response_1.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fa7e009",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_instruction_2 = f\"\"\"\n",
    "# TASK: Constraints to reward code mapping\n",
    "\n",
    "You are an expert in 3D scene generation, interior design, and reinforcement learning.\n",
    "Your task is to analyze given constraints and convert them into verifiable reward functions in Python.\n",
    "\n",
    "## USER PROMPT\n",
    "\"{USER_PROMPT}\"\n",
    "\n",
    "## CONTEXT\n",
    "\n",
    "### Dataset: 3D-FRONT\n",
    "{dataset_facts}\n",
    "\n",
    "In this task, you are provided with a user prompt and a dataset context. Your task is to decompose the user prompt into verifiable constraints with Python reward functions.\n",
    "\n",
    "Here is the dataset information in JSON format about the specific room type: {ROOM_TYPE} you will be working on:\n",
    "{dataset_context}\n",
    "\n",
    "\n",
    "### Scene Representation\n",
    "{scene_representation}\n",
    "\n",
    "### You also have the following utility functions at your disposal which you can use according to the given docstrings.\n",
    "{utility_functions}\n",
    "\n",
    "### The baseline model is already trained on some universal constraints, so you do not need to consider these constraints while generating new ones. The universal constraints are:\n",
    "{universal_rewards_info_with_docstrings}\n",
    "\n",
    "\n",
    "## YOUR TASK\n",
    "\n",
    "Analyze the user prompt: {USER_PROMPT}, constraints to be satisfied for that prompt: {llm_response_1.text} and all other context i have provided, then provide a comprehensive JSON response with the following structure:\n",
    "\n",
    "The template for reward function to quantify each constraint satisfaction with python code is as follows:\n",
    "{reward_function_template}\n",
    "\n",
    "```json\n",
    "{{\n",
    "  \"rewards\": [\n",
    "    {{\n",
    "      \"id\": \"R1\",\n",
    "      \"constraint_id\": \"C1\",\n",
    "      \"name\": \"descriptive_snake_case_name\",\n",
    "      \"code\": \"Python Code implementing get_reward and test_reward functions as per the template\",\n",
    "      \"success_threshold\": \"Value in terms of raw reward units as implemented in Python code indicating satisfactory fulfillment of the constraint. This will be used to calculate success rate.\"\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "NOTE: You should use the utility functions exactly as the docstrings provided, all arguments should be passed in the same order as in the docstrings.\n",
    "```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ff62a56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃                                    <span style=\"font-weight: bold\">TASK: Constraints to reward code mapping</span>                                     ┃\n",
       "┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\n",
       "\n",
       "You are an expert in 3D scene generation, interior design, and reinforcement learning. Your task is to analyze     \n",
       "given constraints and convert them into verifiable reward functions in Python.                                     \n",
       "\n",
       "\n",
       "                                                    <span style=\"font-weight: bold; text-decoration: underline\">USER PROMPT</span>                                                    \n",
       "\n",
       "\"A bedroom with 4 ceiling_lamps forming a rectangular shape.\"                                                      \n",
       "\n",
       "\n",
       "                                                      <span style=\"font-weight: bold; text-decoration: underline\">CONTEXT</span>                                                      \n",
       "\n",
       "                                                 <span style=\"font-weight: bold\">Dataset: 3D-FRONT</span>                                                 \n",
       "\n",
       "The dataset being used is 3D-FRONT which uses 3D-FUTURE dataset for furniture models. 3D-FRONT is a collection of  \n",
       "synthetic, high-quality 3D indoor scenes, highlighted by professionally and distinctively designed layouts.        \n",
       "\n",
       "In this dataset, the following facts are important to know:                                                        \n",
       "\n",
       "\n",
       "                                                 <span style=\"font-weight: bold; text-decoration: underline\">Coordinate System</span>                                                 \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Y-axis: Vertical (up direction)                                                                                 \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>XZ-plane: Floor plane                                                                                           \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Units: Meters (world coordinates, unnormalized)                                                                 \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Empty slots: Have index (num_classes-1), near-zero size/position                                                \n",
       "\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃                                     <span style=\"font-weight: bold\">Important Facts about 3D-FRONT dataset</span>                                      ┃\n",
       "┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Ceiling objects are at y ≈ ceiling_height (typically 2.8m)                                                      \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Floor objects have y ≈ object_height/2                                                                          \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Ignore empty slots (is_empty == True) in calculations                                                           \n",
       "\n",
       "In this task, you are provided with a user prompt and a dataset context. Your task is to decompose the user prompt \n",
       "into verifiable constraints with Python reward functions.                                                          \n",
       "\n",
       "Here is the dataset information in JSON format about the specific room type: bedroom you will be working on:       \n",
       "{'room_type': 'bedroom', 'total_scenes': 4042, 'class_frequencies': {'nightstand': 0.27245508982035926,            \n",
       "'double_bed': 0.17138137518067315, 'wardrobe': 0.16079909147222796, 'pendant_lamp': 0.12693578360520338,           \n",
       "'ceiling_lamp': 0.06308073508156102, 'tv_stand': 0.029888498864340286, 'chair': 0.022816436093330582, 'single_bed':\n",
       "0.021216188313029113, 'dressing_table': 0.020854842040057817, 'cabinet': 0.020183770390253975, 'table':            \n",
       "0.019667561428866404, 'desk': 0.016260582283708445, 'stool': 0.011459838942804047, 'shelf': 0.0081561015899236,    \n",
       "'kids_bed': 0.0081561015899236, 'bookshelf': 0.0071753045632872185, 'children_cabinet': 0.0071753045632872185,     \n",
       "'dressing_chair': 0.006142886640512079, 'armchair': 0.003716704521990502, 'sofa': 0.0014970059880239522,           \n",
       "'coffee_table': 0.0009807970266363824}, 'furniture_counts': {'nightstand': 5278, 'double_bed': 3320, 'wardrobe':   \n",
       "3115, 'pendant_lamp': 2459, 'ceiling_lamp': 1222, 'tv_stand': 579, 'chair': 442, 'single_bed': 411,                \n",
       "'dressing_table': 404, 'cabinet': 391, 'table': 381, 'desk': 315, 'stool': 222, 'shelf': 158, 'kids_bed': 158,     \n",
       "'bookshelf': 139, 'children_cabinet': 139, 'dressing_chair': 119, 'armchair': 72, 'sofa': 29, 'coffee_table': 19}, \n",
       "'idx_to_labels': {'0': 'armchair', '1': 'bookshelf', '2': 'cabinet', '3': 'ceiling_lamp', '4': 'chair', '5':       \n",
       "'children_cabinet', '6': 'coffee_table', '7': 'desk', '8': 'double_bed', '9': 'dressing_chair', '10':              \n",
       "'dressing_table', '11': 'kids_bed', '12': 'nightstand', '13': 'pendant_lamp', '14': 'shelf', '15': 'single_bed',   \n",
       "'16': 'sofa', '17': 'stool', '18': 'table', '19': 'tv_stand', '20': 'wardrobe', '21': 'empty'},                    \n",
       "'num_classes_with_empty': 22, 'num_classes_without_empty': 21, 'max_objects': 12}                                  \n",
       "\n",
       "                                               <span style=\"font-weight: bold\">Scene Representation</span>                                                \n",
       "\n",
       "A 3D scene is represented in batch format (parsed_scenes) a dictionary with the following keys and PyTorch tensors \n",
       "as values: - <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">positions</span>: (B, N, 3) - Object centroids in meters (x, y, z) - <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">sizes</span>: (B, N, 3) - Half-extents (sx/2,  \n",
       "sy/2, sz/2) - <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">object_indices</span>: (B, N) - Class indices [0, num_classes-1] - <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">one_hot</span>: (B, N, num_classes) - One-hot   \n",
       "encoded classes - <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">is_empty</span>: (B, N) - Boolean mask (True = empty slot) - <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">orientations</span>: (B, N, 2) - [cos(θ), sin(θ)] \n",
       "for z-rotation - <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">device</span>: torch.device Where: - B = Batch size - N = Max objects per scene                          \n",
       "\n",
       "<span style=\"font-weight: bold\">You also have the following utility functions at your disposal which you can use according to the given docstrings.</span>\n",
       "\n",
       "{'find_object_front_and_back': {'function': &lt;function find_object_front_and_back at 0x7fe8e21afd90&gt;, 'description':\n",
       "'\\n    Find the coordinates of the front and back centers of a object.\\n\\n    Args:\\n        position: (1,3) tensor\n",
       "- object centroid (x, y, z)\\n        orientation: (1,2) tensor - [cos(θ), sin(θ)], z-rotation\\n        size: (1,3) \n",
       "tensor - half-extents (sx/2, sy/2, sz/2)\\n    \\n    Returns:\\n        front_center: (1,3) tensor - position of     \n",
       "object front\\n        back_center: (1,3) tensor - position of object back\\n    '}, 'find_closest_wall_to_object':  \n",
       "{'function': &lt;function find_closest_wall_to_object at 0x7fe8e21afeb0&gt;, 'description': \"\\n    Find which wall is    \n",
       "closest to the object's front or back and compute its distance.\\n\\n    Args:\\n        position: (1,3) tensor -     \n",
       "object centroid (x, y, z)\\n        orientation: (1,2) tensor - z-rotation\\n        size: (1,3) tensor -            \n",
       "half-extents (sx/2, sy/2, sz/2)\\n        floor_polygons: list of ordered floor polygon vertices in the format [(x1,\n",
       "z1), (x2, z2), ...(xn, zn)]  where n &gt;= 4, and always forms a closed polygon\\n    \\n    Returns:\\n                 \n",
       "wall_index: (1) tensor - index of the wall in floor_polygons (i.e., wall_index = 0 means the wall formed by        \n",
       "floor_polygons[0] and floor_polygons[1])\\n        distance: (1) tensor - perpendicular distance from object        \n",
       "centroid to wall\\n    \"}, 'compute_angle_between_objects': {'function': &lt;function compute_angle_between_objects at \n",
       "0x7fe8e21aff40&gt;, 'description': '\\n    Calculate angle in degrees between two objects in xz-plane.\\n\\n    Args:\\n  \n",
       "orientation1: orientation of object 1,  (1,2) tensor - [cos(θ), sin(θ)], z-rotation\\n        orientation2:         \n",
       "orientation of object 2, (1,2) tensor - [cos(θ), sin(θ)], z-rotation\\n\\n    Returns:\\n        angle_radians: (1)   \n",
       "tensor - angle between objects\\n    '}, 'distance_2d': {'function': &lt;function distance_2d at 0x7fe8df748040&gt;,      \n",
       "'description': '\\n    Compute Euclidean distance in the XZ plane between two sets of points.\\n\\n    Args:\\n        \n",
       "position1: (1,3) tensor - xyz\\n        position2: (1,3) tensor - xyz\\n\\n    Returns:\\n        distances: (1) tensor\n",
       "- distance between points\\n    '}, 'get_object_count_in_a_scene': {'function': &lt;function                           \n",
       "get_object_count_in_a_scene at 0x7fe8df7480d0&gt;, 'description': '\\n    Count number of objects of a specific class  \n",
       "in each scene.\\n\\n    Args:\\n        one_hot: (B, N, num_classes) - One-hot encoded classes\\n        class_label:  \n",
       "string, e.g. \"ceiling_lamp\"\\n        idx_to_labels: dict, {idx: label}\\n\\n    Returns:\\n        count: int, number \n",
       "of objects of class_label in the scene\\n    '}, 'has_x_meter_clearance': {'function': &lt;function                    \n",
       "has_x_meter_clearance at 0x7fe8df748160&gt;, 'description': '\\n    Check whether there is at least x meters of path   \n",
       "clearance around objects.\\n\\n    Args:\\n        parsed_scenes: list/dict with scene info\\n        x: float,        \n",
       "required clearance in meters\\n        direction: float, z_angle in radians\\n    Returns:\\n        clearance_mask:  \n",
       "tensor/list (B,) - True if scene satisfies clearance\\n    '}, 'create_scene_for_testing': {'function': &lt;function   \n",
       "create_scene_for_testing at 0x7fe8df7483a0&gt;, 'description': '\\n    Create a scene for testing reward functions.\\n  \n",
       "Input:\\n        room_type: string, Example: \"bedroom\" or \"livingroom\"\\n        num_objects: int, number of objects \n",
       "in the scene\\n        class_label_indices: list of int, class indices\\n        translations: list of tuple, (x, y, \n",
       "z) translations\\n        sizes: list of tuple, (sx/2, sy/2, sz/2) sizes\\n        orientations: list of tuple,      \n",
       "(cos(θ), sin(θ)) orientations\\n        \\n    Output:\\n        parsed_scene: dict, scene representation\\n    '}}    \n",
       "\n",
       "     <span style=\"font-weight: bold\">The baseline model is already trained on some universal constraints, so you do not need to consider these</span>     \n",
       "                       <span style=\"font-weight: bold\">constraints while generating new ones. The universal constraints are:</span>                       \n",
       "\n",
       "{'must_have_furniture': {'function': &lt;function compute_must_have_furniture_reward at 0x7fe8df749000&gt;,              \n",
       "'description': \"\\n    Calculate reward based on whether the scene contains required furniture for the room         \n",
       "type.\\n\\n    For bedrooms: must have at least one bed (single_bed, double_bed, or kids_bed)\\n\\n    Args:\\n         \n",
       "parsed_scene: Dict returned by parse_and_descale_scenes()\\n        room_type: Type of room (default: 'bedroom').   \n",
       "Currently only 'bedroom' is supported.\\n\\n    Returns:\\n        rewards: Tensor of shape (B,) with must-have       \n",
       "furniture rewards for each scene\\n    \"}, 'non_penetration': {'function': &lt;function compute_non_penetration_reward \n",
       "at 0x7fe8df7492d0&gt;, 'description': '\\n    Calculate reward based on non-penetration constraint using penetration   \n",
       "depth.\\n\\n    Following the approach from original authors: reward = sum of negative signed distances.\\n    When   \n",
       "objects overlap, we get positive penetration depth, so reward is negative.\\n\\n    Args:\\n        parsed_scene: Dict\n",
       "returned by parse_and_descale_scenes()\\n\\n    Returns:\\n        rewards: Tensor of shape (B,) with non-penetration \n",
       "rewards for each scene\\n    '}, 'object_count': {'function': &lt;function compute_object_count_reward at              \n",
       "0x7fe8df7497e0&gt;, 'description': \"\\n    Calculate reward based on object count distribution.\\n\\n    Three modes:\\n  \n",
       "1. KL mode (default, recommended): Uses KL divergence between batch distribution\\n       and empirical training    \n",
       "distribution. Encourages diversity and prevents mode collapse.\\n    2. NLL mode: Uses negative log-likelihood per  \n",
       "scene (legacy)\\n    3. Gaussian mode: Uses squared deviation from mean (legacy)\\n\\n    Args:\\n        parsed_scene:\n",
       "Dict returned by parse_and_descale_scenes() with batch dimension\\n        mode: 'kl' (default), 'nll', or          \n",
       "'gaussian'\\n        target_count: Expected number of objects (used only for gaussian mode)\\n        std_dev:       \n",
       "Standard deviation (used only for gaussian mode)\\n        **kwargs: Additional arguments (ignored, for             \n",
       "compatibility)\\n\\n    Returns:\\n        rewards: Tensor of shape (B,) with object count rewards for each scene\\n   \n",
       "\"}, 'not_out_of_bound': {'function': &lt;function compute_boundary_violation_reward at 0x7fe8df764a60&gt;, 'description':\n",
       "\"\\n    Compute boundary violation reward using cached SDF grids.\\n    \\n    <span style=\"font-weight: bold\">IMPORTANT</span>: Call <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">precompute_sdf_cache()</span> \n",
       "once before training to generate cache!\\n    \\n    Args:\\n        parsed_scene: Dictionary with positions, sizes,  \n",
       "is_empty, device\\n        floor_polygons: (B, num_vertices, 2) - only needed if cache doesn't exist\\n              \n",
       "indices: (B,) - scene indices for SDF lookup\\n        grid_resolution: SDF grid resolution\\n        sdf_cache_dir: \n",
       "Directory containing cached SDF grids\\n        \\n    Returns:\\n        rewards: (B, 1) - sum of negative violation \n",
       "distances per scene\\n    \"}, 'accessibility': {'function': &lt;function compute_accessibility_reward at               \n",
       "0x7fe8df7664d0&gt;, 'description': \"\\n    Compute accessibility reward using cached floor grids or computing          \n",
       "on-the-fly.\\n    \\n    Returns dict with 3 components:\\n    - coverage_ratio: [0, 1] - fraction of floor reachable \n",
       "from largest region\\n    - num_regions: [1, ∞) - number of disconnected regions\\n    - avg_clearance: meters -     \n",
       "average distance to nearest obstacle in reachable area\\n    \\n    Args:\\n        parsed_scenes: Dictionary with    \n",
       "positions, sizes, is_empty, device, object_types\\n        floor_polygons: (B, num_vertices, 2) - floor polygon     \n",
       "vertices\\n        is_val: Whether this is validation split\\n        indices: (B,) - scene indices for cache        \n",
       "lookup\\n        accessibility_cache: Pre-loaded AccessibilityCache instance (optional)\\n        grid_resolution:   \n",
       "Grid resolution in meters (default 0.2m = 20cm)\\n        agent_radius: Agent radius in meters (default 0.15m =     \n",
       "15cm)\\n        save_viz: Whether to save visualization images\\n        viz_dir: Directory to save visualizations\\n \n",
       "\\n    Returns:\\n        Dictionary with:\\n        - 'coverage_ratio': (B,) - reachable area ratio [0, 1]\\n        -\n",
       "'num_regions': (B,) - number of disconnected regions [1, ∞)\\n        - 'avg_clearance': (B,) - average clearance in\n",
       "meters\\n    \"}, 'gravity_following': {'function': &lt;function compute_gravity_following_reward at 0x7fe8df765d80&gt;,   \n",
       "'description': '\\n    Calculate gravity-following reward based on how close objects are to the ground.\\n    \\n     \n",
       "Objects should rest on the floor (y_min ≈ 0), except for ceiling objects.\\n    Only penalizes objects that are MORE\n",
       "than tolerance away from the floor(both sinking and floating cases).\\n    \\n    Args:\\n        parsed_scene: Dict  \n",
       "returned by parse_and_descale_scenes()\\n        tolerance: Distance threshold in meters (default 0.01m = 1cm)\\n    \n",
       "\\n    Returns:\\n        rewards: Tensor of shape (B,) with gravity-following rewards\\n    '},                      \n",
       "'night_tables_on_head_side': {'function': &lt;function compute_nightstand_placement_reward at 0x7fe875d37640&gt;,        \n",
       "'description': \"\\n    Penalizes scenes where:\\n      - Both nightstands are placed on the same side of the bed.\\n  \n",
       "- A nightstand is at the foot side of the bed (soft penalty based on distance).\\n    \\n    For each bed-nightstand \n",
       "pair:\\n    1. Find headboard position of bed (same logic as wall proximity)\\n    2. Determine which side of bed    \n",
       "each nightstand is on (left/right relative to headboard)\\n    3. Compute how far toward foot side it is; apply     \n",
       "distance-based penalty\\n    4. Penalize if both nightstands on same side or too far from head side\\n\\n    Args:\\n  \n",
       "parsed_scenes: Dict with keys:\\n            - 'positions': (B, N, 3) - object positions (x, y, z)\\n            -   \n",
       "'orientations': (B, N, 2) - [cos_theta, sin_theta]\\n            - 'sizes': (B, N, 3) - object half-extents (already\n",
       "halved)\\n            - 'object_indices': (B, N) - object class indices\\n            - 'is_empty': (B, N) - mask for\n",
       "empty slots\\n        floor_polygons: List of length B (not used but kept for signature compatibility)\\n            \n",
       "idx_to_labels: Dict mapping indices to object class names\\n\\n    Returns:\\n        rewards: (B,) - nightstand      \n",
       "placement reward per scene (negative penalty)\\n    \"}, 'axis_alignment': {'function': &lt;function                    \n",
       "compute_axis_alignment_reward at 0x7fe875d377f0&gt;, 'description': \"\\n    Reward objects for being axis-aligned      \n",
       "(parallel/perpendicular to walls).\\n\\n    Penalizes angular deviation from 0°, 90°, 180°, 270° for furniture that\\n\n",
       "should typically be placed against walls.\\n\\n    Args:\\n        parsed_scenes: Dict with keys:\\n            -      \n",
       "'orientations': (B, N, 2) - [cos_theta, sin_theta] for each object\\n            - 'object_indices': (B, N) - object\n",
       "class indices\\n            - 'is_empty': (B, N) - mask for empty slots\\n        idx_to_labels: Dict mapping indices\n",
       "to object class names\\n\\n    Returns:\\n        rewards: (B,) - alignment reward per scene (negative of total       \n",
       "violation)\\n    \"}, 'furniture_against_wall': {'function': &lt;function compute_wall_proximity_reward at              \n",
       "0x7fe875d379a0&gt;, 'description': \"\\n    Reward furniture for having their back/headboard close to walls.\\n\\n    For \n",
       "each furniture:\\n    1. Calculate headboard position based on rotation\\n    2. Cast ray from headboard toward      \n",
       "wall\\n    3. Find nearest wall edge intersection\\n    4. Measure distance\\n\\n    Args:\\n        parsed_scenes: Dict\n",
       "with keys:\\n            - 'positions': (B, N, 3) - object positions (x, y, z)\\n            - 'orientations': (B, N,\n",
       "2) - [cos_theta, sin_theta]\\n            - 'sizes': (B, N, 3) - object half-extents (already halved)\\n            -\n",
       "'object_indices': (B, N) - object class indices\\n            - 'is_empty': (B, N) - mask for empty slots\\n         \n",
       "floor_polygons: List of length B, each containing (M, 2) polygon vertices [x, z]\\n        idx_to_labels: Dict      \n",
       "mapping indices to object class names\\n        viz_batch_idx: (optional, int) If provided, will save a             \n",
       "visualization for this batch index.\\n\\n    Returns:\\n        rewards: (B,) - wall proximity reward per scene       \n",
       "(negative of total distance)\\n    \"}}                                                                              \n",
       "\n",
       "\n",
       "                                                     <span style=\"font-weight: bold; text-decoration: underline\">YOUR TASK</span>                                                     \n",
       "\n",
       "Analyze the user prompt: A bedroom with 4 ceiling_lamps forming a rectangular shape., constraints to be satisfied  \n",
       "for that prompt: ```json { \"constraints\": [ { \"id\": \"C1\", \"name\": \"exact_ceiling_lamp_count\", \"description\": \"The  \n",
       "scene must contain exactly 4 objects of the class 'ceiling_lamp'.\" }, { \"id\": \"C2\", \"name\":                        \n",
       "\"ceiling_lamps_form_rectangle\", \"description\": \"The XZ-plane projections of the four 'ceiling_lamp' objects must   \n",
       "form a rectangle. This is verified by checking if, for any pairing of the four lamps into two diagonals, the       \n",
       "diagonals bisect each other and have equal length. This constraint only applies if there are exactly 4 ceiling     \n",
       "lamps.\" } ] }                                                                                                      \n",
       "\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">The template for reward function to quantify each constraint satisfaction with python code is as follows:</span><span style=\"background-color: #272822\">         </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">def get_reward(parsed_scenes, idx_to_labels, room_type, floor_polygons, **kwargs):</span><span style=\"background-color: #272822\">                                </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    '''</span><span style=\"background-color: #272822\">                                                                                                           </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    Input:</span><span style=\"background-color: #272822\">                                                                                                        </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        - parsed_scenes: list of parsed scenes</span><span style=\"background-color: #272822\">                                                                    </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">            Format:</span><span style=\"background-color: #272822\">                                                                                               </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">            Scenes are provided as dictionaries with PyTorch tensors:</span><span style=\"background-color: #272822\">                                             </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">                - `positions`: (B, N, 3) - Object centroids in meters (x, y, z)</span><span style=\"background-color: #272822\">                                   </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">                - `sizes`: (B, N, 3) - Half-extents (sx/2, sy/2, sz/2)</span><span style=\"background-color: #272822\">                                            </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">                - `object_indices`: (B, N) - Class indices [0, num_classes-1]</span><span style=\"background-color: #272822\">                                     </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">                - `one_hot`: (B, N, num_classes) - One-hot encoded classes</span><span style=\"background-color: #272822\">                                        </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">                - `is_empty`: (B, N) - Boolean mask (True = empty slot)</span><span style=\"background-color: #272822\">                                           </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">                - `orientations`: (B, N, 2) - [cos(θ), sin(θ)] for z-rotation</span><span style=\"background-color: #272822\">                                     </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">                - `device`: torch.device</span><span style=\"background-color: #272822\">                                                                          </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">                Where:</span><span style=\"background-color: #272822\">                                                                                            </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">                    - B = Batch size</span><span style=\"background-color: #272822\">                                                                              </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">                    - N = Max objects per scene</span><span style=\"background-color: #272822\">                                                                   </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        </span><span style=\"background-color: #272822\">                                                                                                          </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        - idx_to_labels: dictionary mapping class indices to class labels</span><span style=\"background-color: #272822\">                                         </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        - room_type: string, Example: \"bedroom\" or \"livingroom\"</span><span style=\"background-color: #272822\">                                                   </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        - Floor Polygons (floor_polygons): A list of ordered floor_polygons in the format [(x1, z1), (x2, z2), </span><span style=\"background-color: #272822\">   </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">...(xn, zn)]  where n &gt;= 4, and always forms a closed polygon</span><span style=\"background-color: #272822\">                                                     </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        - **kwargs: additional keyword arguments</span><span style=\"background-color: #272822\">                                                                  </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    Output:</span><span style=\"background-color: #272822\">                                                                                                       </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        reward: torch.Tensor of shape (len(parsed_scenes),)</span><span style=\"background-color: #272822\">                                                       </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    '''</span><span style=\"background-color: #272822\">                                                                                                           </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"background-color: #272822\">                                                                                                              </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    # Logic of reward function here</span><span style=\"background-color: #272822\">                                                                               </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    return reward</span><span style=\"background-color: #272822\">                                                                                                 </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">def test_reward(idx_to_labels, room_type, floor_polygons, **kwargs):</span><span style=\"background-color: #272822\">                                              </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    '''</span><span style=\"background-color: #272822\">                                                                                                           </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    Input:</span><span style=\"background-color: #272822\">                                                                                                        </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        - idx_to_labels: dictionary mapping class indices to class labels</span><span style=\"background-color: #272822\">                                         </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        - room_type: string, Example: \"bedroom\" or \"livingroom\"</span><span style=\"background-color: #272822\">                                                   </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        - floor_polygons: A list of ordered floor_polygons in the format [(x1, z1), (x2, z2), ...(xn, zn)]  where</span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">n &gt;= 4, and always forms a closed polygon</span><span style=\"background-color: #272822\">                                                                         </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        - **kwargs: additional keyword arguments</span><span style=\"background-color: #272822\">                                                                  </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    '''</span><span style=\"background-color: #272822\">                                                                                                           </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    # Create a test scene using create_scene_for_testing</span><span style=\"background-color: #272822\">                                                          </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    # Scene 1</span><span style=\"background-color: #272822\">                                                                                                     </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    num_objects_1 = 5</span><span style=\"background-color: #272822\">                                                                                             </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    class_label_indices_1 = [0, 1, 2, 3, 4]</span><span style=\"background-color: #272822\">                                                                       </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    translations_1 = [(0, 0, 0), (1, 0, 0), (2, 0, 0), (3, 0, 0), (4, 0, 0)]</span><span style=\"background-color: #272822\">                                      </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    sizes_1 = [(0.5, 0.5, 0.5), (0.5, 0.5, 0.5), (0.5, 0.5, 0.5), (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)]</span><span style=\"background-color: #272822\">               </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    orientations_1 = [(1, 0), (1, 0), (1, 0), (1, 0), (1, 0)]</span><span style=\"background-color: #272822\">                                                     </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    parsed_scene_1 = create_scene_for_testing(room_type, num_objects_1, class_label_indices_1, translations_1, </span><span style=\"background-color: #272822\">   </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">sizes_1, orientations_1)</span><span style=\"background-color: #272822\">                                                                                          </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"background-color: #272822\">                                                                                                              </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    # Scene 2</span><span style=\"background-color: #272822\">                                                                                                     </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    num_objects_2 = 6</span><span style=\"background-color: #272822\">                                                                                             </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    class_label_indices_2 = [0, 1, 2, 3, 4, 5]</span><span style=\"background-color: #272822\">                                                                    </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    translations_2 = [(0, 0, 0), (1, 0, 0), (2, 0, 0), (3, 0, 0), (4, 0, 0), (5, 0, 0),]</span><span style=\"background-color: #272822\">                          </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    sizes_2 = [(0.5, 0.5, 0.5), (0.5, 0.5, 0.5), (0.5, 0.5, 0.5), (0.5, 0.5, 0.5), (0.5, 0.5, 0.5), (0.5, 0.5, </span><span style=\"background-color: #272822\">   </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">0.5)]</span><span style=\"background-color: #272822\">                                                                                                             </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    orientations_2 = [(1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0)]</span><span style=\"background-color: #272822\">                                             </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    parsed_scene_2 = create_scene_for_testing(room_type, num_objects_2, class_label_indices_2, translations_2, </span><span style=\"background-color: #272822\">   </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">sizes_2, orientations_2)</span><span style=\"background-color: #272822\">                                                                                          </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"background-color: #272822\">                                                                                                              </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    # Scene 3</span><span style=\"background-color: #272822\">                                                                                                     </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    num_objects_3 = 4</span><span style=\"background-color: #272822\">                                                                                             </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    class_label_indices_3 = [0, 1, 3, 4]</span><span style=\"background-color: #272822\">                                                                          </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    translations_3 = [(0, 0, 0), (1, 0, 0), (2, 0, 0), (3, 0, 0)]</span><span style=\"background-color: #272822\">                                                 </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    sizes_3 = [(0.5, 0.5, 0.5), (0.5, 0.5, 0.5), (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)]</span><span style=\"background-color: #272822\">                                </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    orientations_3 = [(1, 0), (1, 0), (1, 0), (1, 0)]</span><span style=\"background-color: #272822\">                                                             </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    parsed_scene_3 = create_scene_for_testing(room_type, num_objects_3, class_label_indices_3, translations_3, </span><span style=\"background-color: #272822\">   </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">sizes_3, orientations_3)</span><span style=\"background-color: #272822\">                                                                                          </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"background-color: #272822\">                                                                                                              </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"background-color: #272822\">                                                                                                              </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    parsed_scenes = torch.stack([parsed_scene_1, parsed_scene_2, parsed_scene_3])</span><span style=\"background-color: #272822\">                                 </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    rewards = get_reward(parsed_scenes, idx_to_labels, room_type, floor_polygons)</span><span style=\"background-color: #272822\">                                 </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    print(\"Rewards:\", rewards)</span><span style=\"background-color: #272822\">                                                                                    </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    assert rewards.shape[0] == len(parsed_scenes)</span><span style=\"background-color: #272822\">                                                                 </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"background-color: #272822\">                                                                                                              </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    # write test cases for different scenarios to test syntax and basic functionality along with reward function </span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">specific test cases</span><span style=\"background-color: #272822\">                                                                                               </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    # TEST CASES HERE</span><span style=\"background-color: #272822\">                                                                                             </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">```json</span><span style=\"background-color: #272822\">                                                                                                           </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">{</span><span style=\"background-color: #272822\">                                                                                                                 </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">  \"rewards\": [</span><span style=\"background-color: #272822\">                                                                                                    </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    {</span><span style=\"background-color: #272822\">                                                                                                             </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">      \"id\": \"R1\",</span><span style=\"background-color: #272822\">                                                                                                 </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">      \"constraint_id\": \"C1\",</span><span style=\"background-color: #272822\">                                                                                      </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">      \"name\": \"descriptive_snake_case_name\",</span><span style=\"background-color: #272822\">                                                                      </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">      \"code\": \"Python Code implementing get_reward and test_reward functions as per the template\",</span><span style=\"background-color: #272822\">                </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">      \"success_threshold\": \"Value in terms of raw reward units as implemented in Python code indicating </span><span style=\"background-color: #272822\">          </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">satisfactory fulfillment of the constraint. This will be used to calculate success rate.\"</span><span style=\"background-color: #272822\">                         </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    }</span><span style=\"background-color: #272822\">                                                                                                             </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">  ]</span><span style=\"background-color: #272822\">                                                                                                               </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">}</span><span style=\"background-color: #272822\">                                                                                                                 </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">NOTE: You should use the utility functions exactly as the docstrings provided, all arguments should be passed in </span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">the same order as in the docstrings.</span><span style=\"background-color: #272822\">                                                                              </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃                                    \u001b[1mTASK: Constraints to reward code mapping\u001b[0m                                     ┃\n",
       "┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\n",
       "\n",
       "You are an expert in 3D scene generation, interior design, and reinforcement learning. Your task is to analyze     \n",
       "given constraints and convert them into verifiable reward functions in Python.                                     \n",
       "\n",
       "\n",
       "                                                    \u001b[1;4mUSER PROMPT\u001b[0m                                                    \n",
       "\n",
       "\"A bedroom with 4 ceiling_lamps forming a rectangular shape.\"                                                      \n",
       "\n",
       "\n",
       "                                                      \u001b[1;4mCONTEXT\u001b[0m                                                      \n",
       "\n",
       "                                                 \u001b[1mDataset: 3D-FRONT\u001b[0m                                                 \n",
       "\n",
       "The dataset being used is 3D-FRONT which uses 3D-FUTURE dataset for furniture models. 3D-FRONT is a collection of  \n",
       "synthetic, high-quality 3D indoor scenes, highlighted by professionally and distinctively designed layouts.        \n",
       "\n",
       "In this dataset, the following facts are important to know:                                                        \n",
       "\n",
       "\n",
       "                                                 \u001b[1;4mCoordinate System\u001b[0m                                                 \n",
       "\n",
       "\u001b[1;33m • \u001b[0mY-axis: Vertical (up direction)                                                                                 \n",
       "\u001b[1;33m • \u001b[0mXZ-plane: Floor plane                                                                                           \n",
       "\u001b[1;33m • \u001b[0mUnits: Meters (world coordinates, unnormalized)                                                                 \n",
       "\u001b[1;33m • \u001b[0mEmpty slots: Have index (num_classes-1), near-zero size/position                                                \n",
       "\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃                                     \u001b[1mImportant Facts about 3D-FRONT dataset\u001b[0m                                      ┃\n",
       "┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\n",
       "\n",
       "\u001b[1;33m • \u001b[0mCeiling objects are at y ≈ ceiling_height (typically 2.8m)                                                      \n",
       "\u001b[1;33m • \u001b[0mFloor objects have y ≈ object_height/2                                                                          \n",
       "\u001b[1;33m • \u001b[0mIgnore empty slots (is_empty == True) in calculations                                                           \n",
       "\n",
       "In this task, you are provided with a user prompt and a dataset context. Your task is to decompose the user prompt \n",
       "into verifiable constraints with Python reward functions.                                                          \n",
       "\n",
       "Here is the dataset information in JSON format about the specific room type: bedroom you will be working on:       \n",
       "{'room_type': 'bedroom', 'total_scenes': 4042, 'class_frequencies': {'nightstand': 0.27245508982035926,            \n",
       "'double_bed': 0.17138137518067315, 'wardrobe': 0.16079909147222796, 'pendant_lamp': 0.12693578360520338,           \n",
       "'ceiling_lamp': 0.06308073508156102, 'tv_stand': 0.029888498864340286, 'chair': 0.022816436093330582, 'single_bed':\n",
       "0.021216188313029113, 'dressing_table': 0.020854842040057817, 'cabinet': 0.020183770390253975, 'table':            \n",
       "0.019667561428866404, 'desk': 0.016260582283708445, 'stool': 0.011459838942804047, 'shelf': 0.0081561015899236,    \n",
       "'kids_bed': 0.0081561015899236, 'bookshelf': 0.0071753045632872185, 'children_cabinet': 0.0071753045632872185,     \n",
       "'dressing_chair': 0.006142886640512079, 'armchair': 0.003716704521990502, 'sofa': 0.0014970059880239522,           \n",
       "'coffee_table': 0.0009807970266363824}, 'furniture_counts': {'nightstand': 5278, 'double_bed': 3320, 'wardrobe':   \n",
       "3115, 'pendant_lamp': 2459, 'ceiling_lamp': 1222, 'tv_stand': 579, 'chair': 442, 'single_bed': 411,                \n",
       "'dressing_table': 404, 'cabinet': 391, 'table': 381, 'desk': 315, 'stool': 222, 'shelf': 158, 'kids_bed': 158,     \n",
       "'bookshelf': 139, 'children_cabinet': 139, 'dressing_chair': 119, 'armchair': 72, 'sofa': 29, 'coffee_table': 19}, \n",
       "'idx_to_labels': {'0': 'armchair', '1': 'bookshelf', '2': 'cabinet', '3': 'ceiling_lamp', '4': 'chair', '5':       \n",
       "'children_cabinet', '6': 'coffee_table', '7': 'desk', '8': 'double_bed', '9': 'dressing_chair', '10':              \n",
       "'dressing_table', '11': 'kids_bed', '12': 'nightstand', '13': 'pendant_lamp', '14': 'shelf', '15': 'single_bed',   \n",
       "'16': 'sofa', '17': 'stool', '18': 'table', '19': 'tv_stand', '20': 'wardrobe', '21': 'empty'},                    \n",
       "'num_classes_with_empty': 22, 'num_classes_without_empty': 21, 'max_objects': 12}                                  \n",
       "\n",
       "                                               \u001b[1mScene Representation\u001b[0m                                                \n",
       "\n",
       "A 3D scene is represented in batch format (parsed_scenes) a dictionary with the following keys and PyTorch tensors \n",
       "as values: - \u001b[1;36;40mpositions\u001b[0m: (B, N, 3) - Object centroids in meters (x, y, z) - \u001b[1;36;40msizes\u001b[0m: (B, N, 3) - Half-extents (sx/2,  \n",
       "sy/2, sz/2) - \u001b[1;36;40mobject_indices\u001b[0m: (B, N) - Class indices [0, num_classes-1] - \u001b[1;36;40mone_hot\u001b[0m: (B, N, num_classes) - One-hot   \n",
       "encoded classes - \u001b[1;36;40mis_empty\u001b[0m: (B, N) - Boolean mask (True = empty slot) - \u001b[1;36;40morientations\u001b[0m: (B, N, 2) - [cos(θ), sin(θ)] \n",
       "for z-rotation - \u001b[1;36;40mdevice\u001b[0m: torch.device Where: - B = Batch size - N = Max objects per scene                          \n",
       "\n",
       "\u001b[1mYou also have the following utility functions at your disposal which you can use according to the given docstrings.\u001b[0m\n",
       "\n",
       "{'find_object_front_and_back': {'function': <function find_object_front_and_back at 0x7fe8e21afd90>, 'description':\n",
       "'\\n    Find the coordinates of the front and back centers of a object.\\n\\n    Args:\\n        position: (1,3) tensor\n",
       "- object centroid (x, y, z)\\n        orientation: (1,2) tensor - [cos(θ), sin(θ)], z-rotation\\n        size: (1,3) \n",
       "tensor - half-extents (sx/2, sy/2, sz/2)\\n    \\n    Returns:\\n        front_center: (1,3) tensor - position of     \n",
       "object front\\n        back_center: (1,3) tensor - position of object back\\n    '}, 'find_closest_wall_to_object':  \n",
       "{'function': <function find_closest_wall_to_object at 0x7fe8e21afeb0>, 'description': \"\\n    Find which wall is    \n",
       "closest to the object's front or back and compute its distance.\\n\\n    Args:\\n        position: (1,3) tensor -     \n",
       "object centroid (x, y, z)\\n        orientation: (1,2) tensor - z-rotation\\n        size: (1,3) tensor -            \n",
       "half-extents (sx/2, sy/2, sz/2)\\n        floor_polygons: list of ordered floor polygon vertices in the format [(x1,\n",
       "z1), (x2, z2), ...(xn, zn)]  where n >= 4, and always forms a closed polygon\\n    \\n    Returns:\\n                 \n",
       "wall_index: (1) tensor - index of the wall in floor_polygons (i.e., wall_index = 0 means the wall formed by        \n",
       "floor_polygons[0] and floor_polygons[1])\\n        distance: (1) tensor - perpendicular distance from object        \n",
       "centroid to wall\\n    \"}, 'compute_angle_between_objects': {'function': <function compute_angle_between_objects at \n",
       "0x7fe8e21aff40>, 'description': '\\n    Calculate angle in degrees between two objects in xz-plane.\\n\\n    Args:\\n  \n",
       "orientation1: orientation of object 1,  (1,2) tensor - [cos(θ), sin(θ)], z-rotation\\n        orientation2:         \n",
       "orientation of object 2, (1,2) tensor - [cos(θ), sin(θ)], z-rotation\\n\\n    Returns:\\n        angle_radians: (1)   \n",
       "tensor - angle between objects\\n    '}, 'distance_2d': {'function': <function distance_2d at 0x7fe8df748040>,      \n",
       "'description': '\\n    Compute Euclidean distance in the XZ plane between two sets of points.\\n\\n    Args:\\n        \n",
       "position1: (1,3) tensor - xyz\\n        position2: (1,3) tensor - xyz\\n\\n    Returns:\\n        distances: (1) tensor\n",
       "- distance between points\\n    '}, 'get_object_count_in_a_scene': {'function': <function                           \n",
       "get_object_count_in_a_scene at 0x7fe8df7480d0>, 'description': '\\n    Count number of objects of a specific class  \n",
       "in each scene.\\n\\n    Args:\\n        one_hot: (B, N, num_classes) - One-hot encoded classes\\n        class_label:  \n",
       "string, e.g. \"ceiling_lamp\"\\n        idx_to_labels: dict, {idx: label}\\n\\n    Returns:\\n        count: int, number \n",
       "of objects of class_label in the scene\\n    '}, 'has_x_meter_clearance': {'function': <function                    \n",
       "has_x_meter_clearance at 0x7fe8df748160>, 'description': '\\n    Check whether there is at least x meters of path   \n",
       "clearance around objects.\\n\\n    Args:\\n        parsed_scenes: list/dict with scene info\\n        x: float,        \n",
       "required clearance in meters\\n        direction: float, z_angle in radians\\n    Returns:\\n        clearance_mask:  \n",
       "tensor/list (B,) - True if scene satisfies clearance\\n    '}, 'create_scene_for_testing': {'function': <function   \n",
       "create_scene_for_testing at 0x7fe8df7483a0>, 'description': '\\n    Create a scene for testing reward functions.\\n  \n",
       "Input:\\n        room_type: string, Example: \"bedroom\" or \"livingroom\"\\n        num_objects: int, number of objects \n",
       "in the scene\\n        class_label_indices: list of int, class indices\\n        translations: list of tuple, (x, y, \n",
       "z) translations\\n        sizes: list of tuple, (sx/2, sy/2, sz/2) sizes\\n        orientations: list of tuple,      \n",
       "(cos(θ), sin(θ)) orientations\\n        \\n    Output:\\n        parsed_scene: dict, scene representation\\n    '}}    \n",
       "\n",
       "     \u001b[1mThe baseline model is already trained on some universal constraints, so you do not need to consider these\u001b[0m     \n",
       "                       \u001b[1mconstraints while generating new ones. The universal constraints are:\u001b[0m                       \n",
       "\n",
       "{'must_have_furniture': {'function': <function compute_must_have_furniture_reward at 0x7fe8df749000>,              \n",
       "'description': \"\\n    Calculate reward based on whether the scene contains required furniture for the room         \n",
       "type.\\n\\n    For bedrooms: must have at least one bed (single_bed, double_bed, or kids_bed)\\n\\n    Args:\\n         \n",
       "parsed_scene: Dict returned by parse_and_descale_scenes()\\n        room_type: Type of room (default: 'bedroom').   \n",
       "Currently only 'bedroom' is supported.\\n\\n    Returns:\\n        rewards: Tensor of shape (B,) with must-have       \n",
       "furniture rewards for each scene\\n    \"}, 'non_penetration': {'function': <function compute_non_penetration_reward \n",
       "at 0x7fe8df7492d0>, 'description': '\\n    Calculate reward based on non-penetration constraint using penetration   \n",
       "depth.\\n\\n    Following the approach from original authors: reward = sum of negative signed distances.\\n    When   \n",
       "objects overlap, we get positive penetration depth, so reward is negative.\\n\\n    Args:\\n        parsed_scene: Dict\n",
       "returned by parse_and_descale_scenes()\\n\\n    Returns:\\n        rewards: Tensor of shape (B,) with non-penetration \n",
       "rewards for each scene\\n    '}, 'object_count': {'function': <function compute_object_count_reward at              \n",
       "0x7fe8df7497e0>, 'description': \"\\n    Calculate reward based on object count distribution.\\n\\n    Three modes:\\n  \n",
       "1. KL mode (default, recommended): Uses KL divergence between batch distribution\\n       and empirical training    \n",
       "distribution. Encourages diversity and prevents mode collapse.\\n    2. NLL mode: Uses negative log-likelihood per  \n",
       "scene (legacy)\\n    3. Gaussian mode: Uses squared deviation from mean (legacy)\\n\\n    Args:\\n        parsed_scene:\n",
       "Dict returned by parse_and_descale_scenes() with batch dimension\\n        mode: 'kl' (default), 'nll', or          \n",
       "'gaussian'\\n        target_count: Expected number of objects (used only for gaussian mode)\\n        std_dev:       \n",
       "Standard deviation (used only for gaussian mode)\\n        **kwargs: Additional arguments (ignored, for             \n",
       "compatibility)\\n\\n    Returns:\\n        rewards: Tensor of shape (B,) with object count rewards for each scene\\n   \n",
       "\"}, 'not_out_of_bound': {'function': <function compute_boundary_violation_reward at 0x7fe8df764a60>, 'description':\n",
       "\"\\n    Compute boundary violation reward using cached SDF grids.\\n    \\n    \u001b[1mIMPORTANT\u001b[0m: Call \u001b[1;36;40mprecompute_sdf_cache()\u001b[0m \n",
       "once before training to generate cache!\\n    \\n    Args:\\n        parsed_scene: Dictionary with positions, sizes,  \n",
       "is_empty, device\\n        floor_polygons: (B, num_vertices, 2) - only needed if cache doesn't exist\\n              \n",
       "indices: (B,) - scene indices for SDF lookup\\n        grid_resolution: SDF grid resolution\\n        sdf_cache_dir: \n",
       "Directory containing cached SDF grids\\n        \\n    Returns:\\n        rewards: (B, 1) - sum of negative violation \n",
       "distances per scene\\n    \"}, 'accessibility': {'function': <function compute_accessibility_reward at               \n",
       "0x7fe8df7664d0>, 'description': \"\\n    Compute accessibility reward using cached floor grids or computing          \n",
       "on-the-fly.\\n    \\n    Returns dict with 3 components:\\n    - coverage_ratio: [0, 1] - fraction of floor reachable \n",
       "from largest region\\n    - num_regions: [1, ∞) - number of disconnected regions\\n    - avg_clearance: meters -     \n",
       "average distance to nearest obstacle in reachable area\\n    \\n    Args:\\n        parsed_scenes: Dictionary with    \n",
       "positions, sizes, is_empty, device, object_types\\n        floor_polygons: (B, num_vertices, 2) - floor polygon     \n",
       "vertices\\n        is_val: Whether this is validation split\\n        indices: (B,) - scene indices for cache        \n",
       "lookup\\n        accessibility_cache: Pre-loaded AccessibilityCache instance (optional)\\n        grid_resolution:   \n",
       "Grid resolution in meters (default 0.2m = 20cm)\\n        agent_radius: Agent radius in meters (default 0.15m =     \n",
       "15cm)\\n        save_viz: Whether to save visualization images\\n        viz_dir: Directory to save visualizations\\n \n",
       "\\n    Returns:\\n        Dictionary with:\\n        - 'coverage_ratio': (B,) - reachable area ratio [0, 1]\\n        -\n",
       "'num_regions': (B,) - number of disconnected regions [1, ∞)\\n        - 'avg_clearance': (B,) - average clearance in\n",
       "meters\\n    \"}, 'gravity_following': {'function': <function compute_gravity_following_reward at 0x7fe8df765d80>,   \n",
       "'description': '\\n    Calculate gravity-following reward based on how close objects are to the ground.\\n    \\n     \n",
       "Objects should rest on the floor (y_min ≈ 0), except for ceiling objects.\\n    Only penalizes objects that are MORE\n",
       "than tolerance away from the floor(both sinking and floating cases).\\n    \\n    Args:\\n        parsed_scene: Dict  \n",
       "returned by parse_and_descale_scenes()\\n        tolerance: Distance threshold in meters (default 0.01m = 1cm)\\n    \n",
       "\\n    Returns:\\n        rewards: Tensor of shape (B,) with gravity-following rewards\\n    '},                      \n",
       "'night_tables_on_head_side': {'function': <function compute_nightstand_placement_reward at 0x7fe875d37640>,        \n",
       "'description': \"\\n    Penalizes scenes where:\\n      - Both nightstands are placed on the same side of the bed.\\n  \n",
       "- A nightstand is at the foot side of the bed (soft penalty based on distance).\\n    \\n    For each bed-nightstand \n",
       "pair:\\n    1. Find headboard position of bed (same logic as wall proximity)\\n    2. Determine which side of bed    \n",
       "each nightstand is on (left/right relative to headboard)\\n    3. Compute how far toward foot side it is; apply     \n",
       "distance-based penalty\\n    4. Penalize if both nightstands on same side or too far from head side\\n\\n    Args:\\n  \n",
       "parsed_scenes: Dict with keys:\\n            - 'positions': (B, N, 3) - object positions (x, y, z)\\n            -   \n",
       "'orientations': (B, N, 2) - [cos_theta, sin_theta]\\n            - 'sizes': (B, N, 3) - object half-extents (already\n",
       "halved)\\n            - 'object_indices': (B, N) - object class indices\\n            - 'is_empty': (B, N) - mask for\n",
       "empty slots\\n        floor_polygons: List of length B (not used but kept for signature compatibility)\\n            \n",
       "idx_to_labels: Dict mapping indices to object class names\\n\\n    Returns:\\n        rewards: (B,) - nightstand      \n",
       "placement reward per scene (negative penalty)\\n    \"}, 'axis_alignment': {'function': <function                    \n",
       "compute_axis_alignment_reward at 0x7fe875d377f0>, 'description': \"\\n    Reward objects for being axis-aligned      \n",
       "(parallel/perpendicular to walls).\\n\\n    Penalizes angular deviation from 0°, 90°, 180°, 270° for furniture that\\n\n",
       "should typically be placed against walls.\\n\\n    Args:\\n        parsed_scenes: Dict with keys:\\n            -      \n",
       "'orientations': (B, N, 2) - [cos_theta, sin_theta] for each object\\n            - 'object_indices': (B, N) - object\n",
       "class indices\\n            - 'is_empty': (B, N) - mask for empty slots\\n        idx_to_labels: Dict mapping indices\n",
       "to object class names\\n\\n    Returns:\\n        rewards: (B,) - alignment reward per scene (negative of total       \n",
       "violation)\\n    \"}, 'furniture_against_wall': {'function': <function compute_wall_proximity_reward at              \n",
       "0x7fe875d379a0>, 'description': \"\\n    Reward furniture for having their back/headboard close to walls.\\n\\n    For \n",
       "each furniture:\\n    1. Calculate headboard position based on rotation\\n    2. Cast ray from headboard toward      \n",
       "wall\\n    3. Find nearest wall edge intersection\\n    4. Measure distance\\n\\n    Args:\\n        parsed_scenes: Dict\n",
       "with keys:\\n            - 'positions': (B, N, 3) - object positions (x, y, z)\\n            - 'orientations': (B, N,\n",
       "2) - [cos_theta, sin_theta]\\n            - 'sizes': (B, N, 3) - object half-extents (already halved)\\n            -\n",
       "'object_indices': (B, N) - object class indices\\n            - 'is_empty': (B, N) - mask for empty slots\\n         \n",
       "floor_polygons: List of length B, each containing (M, 2) polygon vertices [x, z]\\n        idx_to_labels: Dict      \n",
       "mapping indices to object class names\\n        viz_batch_idx: (optional, int) If provided, will save a             \n",
       "visualization for this batch index.\\n\\n    Returns:\\n        rewards: (B,) - wall proximity reward per scene       \n",
       "(negative of total distance)\\n    \"}}                                                                              \n",
       "\n",
       "\n",
       "                                                     \u001b[1;4mYOUR TASK\u001b[0m                                                     \n",
       "\n",
       "Analyze the user prompt: A bedroom with 4 ceiling_lamps forming a rectangular shape., constraints to be satisfied  \n",
       "for that prompt: ```json { \"constraints\": [ { \"id\": \"C1\", \"name\": \"exact_ceiling_lamp_count\", \"description\": \"The  \n",
       "scene must contain exactly 4 objects of the class 'ceiling_lamp'.\" }, { \"id\": \"C2\", \"name\":                        \n",
       "\"ceiling_lamps_form_rectangle\", \"description\": \"The XZ-plane projections of the four 'ceiling_lamp' objects must   \n",
       "form a rectangle. This is verified by checking if, for any pairing of the four lamps into two diagonals, the       \n",
       "diagonals bisect each other and have equal length. This constraint only applies if there are exactly 4 ceiling     \n",
       "lamps.\" } ] }                                                                                                      \n",
       "\n",
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m                                                                                                                 \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mThe template for reward function to quantify each constraint satisfaction with python code is as follows:\u001b[0m\u001b[48;2;39;40;34m        \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m                                                                                                                 \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mdef get_reward(parsed_scenes, idx_to_labels, room_type, floor_polygons, **kwargs):\u001b[0m\u001b[48;2;39;40;34m                               \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    '''\u001b[0m\u001b[48;2;39;40;34m                                                                                                          \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    Input:\u001b[0m\u001b[48;2;39;40;34m                                                                                                       \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m        - parsed_scenes: list of parsed scenes\u001b[0m\u001b[48;2;39;40;34m                                                                   \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m            Format:\u001b[0m\u001b[48;2;39;40;34m                                                                                              \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m            Scenes are provided as dictionaries with PyTorch tensors:\u001b[0m\u001b[48;2;39;40;34m                                            \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m                - `positions`: (B, N, 3) - Object centroids in meters (x, y, z)\u001b[0m\u001b[48;2;39;40;34m                                  \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m                - `sizes`: (B, N, 3) - Half-extents (sx/2, sy/2, sz/2)\u001b[0m\u001b[48;2;39;40;34m                                           \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m                - `object_indices`: (B, N) - Class indices [0, num_classes-1]\u001b[0m\u001b[48;2;39;40;34m                                    \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m                - `one_hot`: (B, N, num_classes) - One-hot encoded classes\u001b[0m\u001b[48;2;39;40;34m                                       \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m                - `is_empty`: (B, N) - Boolean mask (True = empty slot)\u001b[0m\u001b[48;2;39;40;34m                                          \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m                - `orientations`: (B, N, 2) - [cos(θ), sin(θ)] for z-rotation\u001b[0m\u001b[48;2;39;40;34m                                    \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m                - `device`: torch.device\u001b[0m\u001b[48;2;39;40;34m                                                                         \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m                Where:\u001b[0m\u001b[48;2;39;40;34m                                                                                           \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m                    - B = Batch size\u001b[0m\u001b[48;2;39;40;34m                                                                             \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m                    - N = Max objects per scene\u001b[0m\u001b[48;2;39;40;34m                                                                  \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m        \u001b[0m\u001b[48;2;39;40;34m                                                                                                         \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m        - idx_to_labels: dictionary mapping class indices to class labels\u001b[0m\u001b[48;2;39;40;34m                                        \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m        - room_type: string, Example: \"bedroom\" or \"livingroom\"\u001b[0m\u001b[48;2;39;40;34m                                                  \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m        - Floor Polygons (floor_polygons): A list of ordered floor_polygons in the format [(x1, z1), (x2, z2), \u001b[0m\u001b[48;2;39;40;34m  \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m...(xn, zn)]  where n >= 4, and always forms a closed polygon\u001b[0m\u001b[48;2;39;40;34m                                                    \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m        - **kwargs: additional keyword arguments\u001b[0m\u001b[48;2;39;40;34m                                                                 \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m                                                                                                                 \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    Output:\u001b[0m\u001b[48;2;39;40;34m                                                                                                      \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m        reward: torch.Tensor of shape (len(parsed_scenes),)\u001b[0m\u001b[48;2;39;40;34m                                                      \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    '''\u001b[0m\u001b[48;2;39;40;34m                                                                                                          \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[48;2;39;40;34m                                                                                                             \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    # Logic of reward function here\u001b[0m\u001b[48;2;39;40;34m                                                                              \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    return reward\u001b[0m\u001b[48;2;39;40;34m                                                                                                \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m                                                                                                                 \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mdef test_reward(idx_to_labels, room_type, floor_polygons, **kwargs):\u001b[0m\u001b[48;2;39;40;34m                                             \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    '''\u001b[0m\u001b[48;2;39;40;34m                                                                                                          \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    Input:\u001b[0m\u001b[48;2;39;40;34m                                                                                                       \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m        - idx_to_labels: dictionary mapping class indices to class labels\u001b[0m\u001b[48;2;39;40;34m                                        \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m        - room_type: string, Example: \"bedroom\" or \"livingroom\"\u001b[0m\u001b[48;2;39;40;34m                                                  \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m        - floor_polygons: A list of ordered floor_polygons in the format [(x1, z1), (x2, z2), ...(xn, zn)]  where\u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mn >= 4, and always forms a closed polygon\u001b[0m\u001b[48;2;39;40;34m                                                                        \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m        - **kwargs: additional keyword arguments\u001b[0m\u001b[48;2;39;40;34m                                                                 \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    '''\u001b[0m\u001b[48;2;39;40;34m                                                                                                          \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    # Create a test scene using create_scene_for_testing\u001b[0m\u001b[48;2;39;40;34m                                                         \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    # Scene 1\u001b[0m\u001b[48;2;39;40;34m                                                                                                    \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    num_objects_1 = 5\u001b[0m\u001b[48;2;39;40;34m                                                                                            \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    class_label_indices_1 = [0, 1, 2, 3, 4]\u001b[0m\u001b[48;2;39;40;34m                                                                      \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    translations_1 = [(0, 0, 0), (1, 0, 0), (2, 0, 0), (3, 0, 0), (4, 0, 0)]\u001b[0m\u001b[48;2;39;40;34m                                     \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    sizes_1 = [(0.5, 0.5, 0.5), (0.5, 0.5, 0.5), (0.5, 0.5, 0.5), (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)]\u001b[0m\u001b[48;2;39;40;34m              \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    orientations_1 = [(1, 0), (1, 0), (1, 0), (1, 0), (1, 0)]\u001b[0m\u001b[48;2;39;40;34m                                                    \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    parsed_scene_1 = create_scene_for_testing(room_type, num_objects_1, class_label_indices_1, translations_1, \u001b[0m\u001b[48;2;39;40;34m  \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34msizes_1, orientations_1)\u001b[0m\u001b[48;2;39;40;34m                                                                                         \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[48;2;39;40;34m                                                                                                             \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    # Scene 2\u001b[0m\u001b[48;2;39;40;34m                                                                                                    \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    num_objects_2 = 6\u001b[0m\u001b[48;2;39;40;34m                                                                                            \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    class_label_indices_2 = [0, 1, 2, 3, 4, 5]\u001b[0m\u001b[48;2;39;40;34m                                                                   \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    translations_2 = [(0, 0, 0), (1, 0, 0), (2, 0, 0), (3, 0, 0), (4, 0, 0), (5, 0, 0),]\u001b[0m\u001b[48;2;39;40;34m                         \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    sizes_2 = [(0.5, 0.5, 0.5), (0.5, 0.5, 0.5), (0.5, 0.5, 0.5), (0.5, 0.5, 0.5), (0.5, 0.5, 0.5), (0.5, 0.5, \u001b[0m\u001b[48;2;39;40;34m  \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m0.5)]\u001b[0m\u001b[48;2;39;40;34m                                                                                                            \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    orientations_2 = [(1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0)]\u001b[0m\u001b[48;2;39;40;34m                                            \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    parsed_scene_2 = create_scene_for_testing(room_type, num_objects_2, class_label_indices_2, translations_2, \u001b[0m\u001b[48;2;39;40;34m  \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34msizes_2, orientations_2)\u001b[0m\u001b[48;2;39;40;34m                                                                                         \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[48;2;39;40;34m                                                                                                             \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    # Scene 3\u001b[0m\u001b[48;2;39;40;34m                                                                                                    \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    num_objects_3 = 4\u001b[0m\u001b[48;2;39;40;34m                                                                                            \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    class_label_indices_3 = [0, 1, 3, 4]\u001b[0m\u001b[48;2;39;40;34m                                                                         \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    translations_3 = [(0, 0, 0), (1, 0, 0), (2, 0, 0), (3, 0, 0)]\u001b[0m\u001b[48;2;39;40;34m                                                \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    sizes_3 = [(0.5, 0.5, 0.5), (0.5, 0.5, 0.5), (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)]\u001b[0m\u001b[48;2;39;40;34m                               \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    orientations_3 = [(1, 0), (1, 0), (1, 0), (1, 0)]\u001b[0m\u001b[48;2;39;40;34m                                                            \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    parsed_scene_3 = create_scene_for_testing(room_type, num_objects_3, class_label_indices_3, translations_3, \u001b[0m\u001b[48;2;39;40;34m  \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34msizes_3, orientations_3)\u001b[0m\u001b[48;2;39;40;34m                                                                                         \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[48;2;39;40;34m                                                                                                             \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[48;2;39;40;34m                                                                                                             \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    parsed_scenes = torch.stack([parsed_scene_1, parsed_scene_2, parsed_scene_3])\u001b[0m\u001b[48;2;39;40;34m                                \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    rewards = get_reward(parsed_scenes, idx_to_labels, room_type, floor_polygons)\u001b[0m\u001b[48;2;39;40;34m                                \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    print(\"Rewards:\", rewards)\u001b[0m\u001b[48;2;39;40;34m                                                                                   \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    assert rewards.shape[0] == len(parsed_scenes)\u001b[0m\u001b[48;2;39;40;34m                                                                \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[48;2;39;40;34m                                                                                                             \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    # write test cases for different scenarios to test syntax and basic functionality along with reward function \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mspecific test cases\u001b[0m\u001b[48;2;39;40;34m                                                                                              \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    # TEST CASES HERE\u001b[0m\u001b[48;2;39;40;34m                                                                                            \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m                                                                                                                 \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m                                                                                                                 \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m```json\u001b[0m\u001b[48;2;39;40;34m                                                                                                          \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m{\u001b[0m\u001b[48;2;39;40;34m                                                                                                                \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m  \"rewards\": [\u001b[0m\u001b[48;2;39;40;34m                                                                                                   \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    {\u001b[0m\u001b[48;2;39;40;34m                                                                                                            \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m      \"id\": \"R1\",\u001b[0m\u001b[48;2;39;40;34m                                                                                                \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m      \"constraint_id\": \"C1\",\u001b[0m\u001b[48;2;39;40;34m                                                                                     \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m      \"name\": \"descriptive_snake_case_name\",\u001b[0m\u001b[48;2;39;40;34m                                                                     \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m      \"code\": \"Python Code implementing get_reward and test_reward functions as per the template\",\u001b[0m\u001b[48;2;39;40;34m               \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m      \"success_threshold\": \"Value in terms of raw reward units as implemented in Python code indicating \u001b[0m\u001b[48;2;39;40;34m         \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34msatisfactory fulfillment of the constraint. This will be used to calculate success rate.\"\u001b[0m\u001b[48;2;39;40;34m                        \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    }\u001b[0m\u001b[48;2;39;40;34m                                                                                                            \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m  ]\u001b[0m\u001b[48;2;39;40;34m                                                                                                              \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m}\u001b[0m\u001b[48;2;39;40;34m                                                                                                                \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m                                                                                                                 \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mNOTE: You should use the utility functions exactly as the docstrings provided, all arguments should be passed in \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mthe same order as in the docstrings.\u001b[0m\u001b[48;2;39;40;34m                                                                             \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "console.print(Markdown(llm_instruction_2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1563e49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_response_2 = client.models.generate_content(\n",
    "    model=\"gemini-2.5-pro\",\n",
    "    contents=llm_instruction_2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4aabcadb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">{</span><span style=\"background-color: #272822\">                                                                                                                 </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">  </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">\"rewards\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">: [</span><span style=\"background-color: #272822\">                                                                                                    </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    {</span><span style=\"background-color: #272822\">                                                                                                             </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">      </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">\"id\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">: </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"R1\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">                                                                                                 </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">      </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">\"constraint_id\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">: </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"C1\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">                                                                                      </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">      </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">\"name\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">: </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"exact_ceiling_lamp_count_reward\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">                                                                  </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">      </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">\"code\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">: </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"import torch\\n\\ndef get_reward(parsed_scenes, idx_to_labels, room_type, floor_polygons, </span><span style=\"background-color: #272822\">           </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">**kwargs):\\n    '''\\n    Calculates a reward based on the number of ceiling lamps in the scene.\\n    The reward </span><span style=\"background-color: #272822\">  </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">is 0 if the count is exactly 4, and a negative penalty otherwise.\\n    The penalty is -abs(count - 4).\\n\\n    </span><span style=\"background-color: #272822\">    </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">Input:\\n        - parsed_scenes: Dictionary of scene tensors.\\n        - idx_to_labels: Dictionary mapping class </span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">indices to labels.\\n        - room_type: String, e.g., \\\"bedroom\\\".\\n        - floor_polygons: List of floor </span><span style=\"background-color: #272822\">     </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">polygon vertices.\\n        - **kwargs: Additional keyword arguments.\\n\\n    Output:\\n        reward: torch.Tensor</span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">of shape (B,)\\n    '''\\n    device = parsed_scenes['positions'].device\\n    batch_size = </span><span style=\"background-color: #272822\">                         </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">parsed_scenes['positions'].shape[0]\\n    rewards = torch.zeros(batch_size, device=device)\\n    \\n    try:\\n      </span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">class_to_idx = {v: k for k, v in idx_to_labels.items()}\\n        ceiling_lamp_idx = </span><span style=\"background-color: #272822\">                              </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">int(class_to_idx['ceiling_lamp'])\\n    except KeyError:\\n        # If 'ceiling_lamp' is not a valid class, return</span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">zero reward for all scenes\\n        return rewards\\n\\n    object_indices = parsed_scenes['object_indices']\\n    </span><span style=\"background-color: #272822\">  </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">is_empty = parsed_scenes['is_empty']\\n    \\n    # Count ceiling lamps in each scene, ignoring empty slots\\n    </span><span style=\"background-color: #272822\">   </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">is_ceiling_lamp = (object_indices == ceiling_lamp_idx) &amp; ~is_empty\\n    counts = is_ceiling_lamp.sum(dim=1)\\n    </span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\\n    target_count = 4\\n    \\n    # Reward is the negative absolute difference from the target count\\n    rewards</span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">= -torch.abs(counts - target_count).float()\\n    \\n    return rewards\\n\\ndef test_reward(idx_to_labels, </span><span style=\"background-color: #272822\">          </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">room_type, floor_polygons, create_scene_for_testing, **kwargs):\\n    '''\\n    Tests the get_reward function for </span><span style=\"background-color: #272822\">  </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">exact_ceiling_lamp_count.\\n    '''\\n    class_to_idx = {v: k for k, v in idx_to_labels.items()}\\n    lamp_idx = </span><span style=\"background-color: #272822\">  </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">int(class_to_idx['ceiling_lamp'])\\n    other_idx = int(class_to_idx['chair'])\\n\\n    # Scene 1: Perfect case with</span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">4 ceiling lamps\\n    scene_1 = create_scene_for_testing(\\n        room_type=room_type, num_objects=4,\\n        </span><span style=\"background-color: #272822\">   </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">class_label_indices=[lamp_idx, lamp_idx, lamp_idx, lamp_idx],\\n        translations=[(1, 2.8, 1), (1, 2.8, 3), </span><span style=\"background-color: #272822\">   </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">(3, 2.8, 1), (3, 2.8, 3)],\\n        sizes=[(0.1, 0.1, 0.1)] * 4,\\n        orientations=[(1, 0)] * 4\\n    )\\n\\n   </span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\"># Scene 2: Case with 3 ceiling lamps\\n    scene_2 = create_scene_for_testing(\\n        room_type=room_type, </span><span style=\"background-color: #272822\">      </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">num_objects=3,\\n        class_label_indices=[lamp_idx, lamp_idx, lamp_idx],\\n        translations=[(1, 2.8, 1), </span><span style=\"background-color: #272822\">  </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">(1, 2.8, 3), (3, 2.8, 1)],\\n        sizes=[(0.1, 0.1, 0.1)] * 3,\\n        orientations=[(1, 0)] * 3\\n    )\\n\\n   </span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\"># Scene 3: Case with 5 ceiling lamps\\n    scene_3 = create_scene_for_testing(\\n        room_type=room_type, </span><span style=\"background-color: #272822\">      </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">num_objects=5,\\n        class_label_indices=[lamp_idx] * 5,\\n        translations=[(1, 2.8, 1), (1, 2.8, 3), (3, </span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">2.8, 1), (3, 2.8, 3), (2, 2.8, 2)],\\n        sizes=[(0.1, 0.1, 0.1)] * 5,\\n        orientations=[(1, 0)] * 5\\n   </span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">)\\n    \\n    # Scene 4: Case with 0 ceiling lamps\\n    scene_4 = create_scene_for_testing(\\n        </span><span style=\"background-color: #272822\">              </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">room_type=room_type, num_objects=2,\\n        class_label_indices=[other_idx, other_idx],\\n        </span><span style=\"background-color: #272822\">                </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">translations=[(1, 1, 1), (2, 1, 2)],\\n        sizes=[(0.5, 0.5, 0.5)] * 2,\\n        orientations=[(1, 0)] * 2\\n  </span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">)\\n\\n    def stack_scenes(scenes):\\n        stacked = {}\\n        keys = scenes[0].keys()\\n        for key in </span><span style=\"background-color: #272822\">    </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">keys:\\n            if isinstance(scenes[0][key], torch.Tensor):\\n                max_n = max(s[key].shape[1] for </span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">s in scenes)\\n                padded_tensors = []\\n                for s in scenes:\\n                    tensor =</span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">s[key]\\n                    n = tensor.shape[1]\\n                    if n &lt; max_n:\\n                        </span><span style=\"background-color: #272822\">      </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">padding_shape = list(tensor.shape)\\n                        padding_shape[1] = max_n - n\\n                       </span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">padding = torch.zeros(padding_shape, dtype=tensor.dtype, device=tensor.device)\\n                        if key ==</span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">'is_empty':\\n                            padding = torch.ones(padding_shape, dtype=torch.bool, </span><span style=\"background-color: #272822\">                   </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">device=tensor.device)\\n                        padded_tensor = torch.cat([tensor, padding], dim=1)\\n             </span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">else:\\n                        padded_tensor = tensor\\n                    padded_tensors.append(padded_tensor)\\n</span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">stacked[key] = torch.cat(padded_tensors, dim=0)\\n            else:\\n                stacked[key] = </span><span style=\"background-color: #272822\">               </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">scenes[0][key]\\n        return stacked\\n\\n    parsed_scenes = stack_scenes([scene_1, scene_2, scene_3, </span><span style=\"background-color: #272822\">           </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">scene_4])\\n    \\n    rewards = get_reward(parsed_scenes, idx_to_labels, room_type, floor_polygons)\\n    </span><span style=\"background-color: #272822\">          </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">print(\\\"Testing exact_ceiling_lamp_count_reward...\\\")\\n    print(\\\"Rewards:\\\", rewards)\\n    \\n    assert </span><span style=\"background-color: #272822\">        </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">rewards.shape == (4,), f\\\"Expected shape (4,), got {rewards.shape}\\\"\\n    assert torch.isclose(rewards[0], </span><span style=\"background-color: #272822\">       </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">torch.tensor(0.0)), f\\\"Scene 1 (4 lamps) failed. Expected 0.0, got {rewards[0]}\\\"\\n    assert </span><span style=\"background-color: #272822\">                    </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">torch.isclose(rewards[1], torch.tensor(-1.0)), f\\\"Scene 2 (3 lamps) failed. Expected -1.0, got {rewards[1]}\\\"\\n  </span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">assert torch.isclose(rewards[2], torch.tensor(-1.0)), f\\\"Scene 3 (5 lamps) failed. Expected -1.0, got </span><span style=\"background-color: #272822\">            </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">{rewards[2]}\\\"\\n    assert torch.isclose(rewards[3], torch.tensor(-4.0)), f\\\"Scene 4 (0 lamps) failed. Expected </span><span style=\"background-color: #272822\">  </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">-4.0, got {rewards[3]}\\\"\\n    print(\\\"All tests for exact_ceiling_lamp_count_reward passed!\\\")\\n\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">                </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">      </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">\"success_threshold\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">: </span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">0.0</span><span style=\"background-color: #272822\">                                                                                    </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    },</span><span style=\"background-color: #272822\">                                                                                                            </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    {</span><span style=\"background-color: #272822\">                                                                                                             </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">      </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">\"id\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">: </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"R2\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">                                                                                                 </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">      </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">\"constraint_id\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">: </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"C2\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">                                                                                      </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">      </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">\"name\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">: </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"ceiling_lamps_form_rectangle_reward\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">                                                              </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">      </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">\"code\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">: </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"import torch\\nimport itertools\\nimport math\\n\\ndef get_reward(parsed_scenes, idx_to_labels, </span><span style=\"background-color: #272822\">       </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">room_type, floor_polygons, **kwargs):\\n    '''\\n    Calculates a reward if 4 ceiling lamps form a rectangle in </span><span style=\"background-color: #272822\">   </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">the XZ plane.\\n    A penalty is applied based on the deviation from a perfect rectangle.\\n    The deviation is </span><span style=\"background-color: #272822\">   </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">measured as the minimum sum of diagonal midpoint distance\\n    and diagonal length difference across all possible</span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">pairings.\\n    If the lamp count is not 4, the reward is 0.\\n\\n    Input:\\n        - parsed_scenes: Dictionary of</span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">scene tensors.\\n        - idx_to_labels: Dictionary mapping class indices to labels.\\n        - room_type: </span><span style=\"background-color: #272822\">       </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">String, e.g., \\\"bedroom\\\".\\n        - floor_polygons: List of floor polygon vertices.\\n        - **kwargs: </span><span style=\"background-color: #272822\">       </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">Additional keyword arguments.\\n\\n    Output:\\n        reward: torch.Tensor of shape (B,)\\n    '''\\n    device = </span><span style=\"background-color: #272822\">  </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">parsed_scenes['positions'].device\\n    batch_size = parsed_scenes['positions'].shape[0]\\n    rewards = </span><span style=\"background-color: #272822\">           </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">torch.zeros(batch_size, device=device)\\n    \\n    try:\\n        class_to_idx = {v: k for k, v in </span><span style=\"background-color: #272822\">                 </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">idx_to_labels.items()}\\n        ceiling_lamp_idx = int(class_to_idx['ceiling_lamp'])\\n    except KeyError:\\n     </span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">return rewards\\n\\n    positions = parsed_scenes['positions']\\n    object_indices = </span><span style=\"background-color: #272822\">                               </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">parsed_scenes['object_indices']\\n    is_empty = parsed_scenes['is_empty']\\n    \\n    for i in </span><span style=\"background-color: #272822\">                    </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">range(batch_size):\\n        scene_mask = (object_indices[i] == ceiling_lamp_idx) &amp; ~is_empty[i]\\n        </span><span style=\"background-color: #272822\">         </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">lamp_positions = positions[i, scene_mask, :]\\n        \\n        if lamp_positions.shape[0] != 4:\\n            </span><span style=\"background-color: #272822\">    </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">rewards[i] = 0.0\\n            continue\\n            \\n        points_xz = lamp_positions[:, [0, 2]]\\n        \\n  </span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">pairings = [((0, 1), (2, 3)), ((0, 2), (1, 3)), ((0, 3), (1, 2))]\\n        min_penalty = </span><span style=\"background-color: #272822\">                         </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">torch.tensor(float('inf'), device=device)\\n        \\n        for d1_indices, d2_indices in pairings:\\n           </span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">p_a, p_b = points_xz[d1_indices[0]], points_xz[d1_indices[1]]\\n            p_c, p_d = points_xz[d2_indices[0]], </span><span style=\"background-color: #272822\">  </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">points_xz[d2_indices[1]]\\n            \\n            midpoint1 = (p_a + p_b) / 2.0\\n            midpoint2 = (p_c +</span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">p_d) / 2.0\\n            midpoint_dist = torch.norm(midpoint1 - midpoint2)\\n            \\n            len1 = </span><span style=\"background-color: #272822\">      </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">torch.norm(p_a - p_b)\\n            len2 = torch.norm(p_c - p_d)\\n            length_diff = torch.abs(len1 - </span><span style=\"background-color: #272822\">      </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">len2)\\n            \\n            total_penalty = midpoint_dist + length_diff\\n            \\n            if </span><span style=\"background-color: #272822\">       </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">total_penalty &lt; min_penalty:\\n                min_penalty = total_penalty\\n                \\n        rewards[i] =</span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">-min_penalty\\n        \\n    return rewards\\n\\ndef test_reward(idx_to_labels, room_type, floor_polygons, </span><span style=\"background-color: #272822\">          </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">create_scene_for_testing, **kwargs):\\n    '''\\n    Tests the get_reward function for </span><span style=\"background-color: #272822\">                             </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">ceiling_lamps_form_rectangle.\\n    '''\\n    class_to_idx = {v: k for k, v in idx_to_labels.items()}\\n    lamp_idx</span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">= int(class_to_idx['ceiling_lamp'])\\n\\n    # Scene 1: Perfect rectangle\\n    scene_1 = </span><span style=\"background-color: #272822\">                           </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">create_scene_for_testing(\\n        room_type=room_type, num_objects=4,\\n        class_label_indices=[lamp_idx] * </span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">4,\\n        translations=[(1, 2.8, 1), (1, 2.8, 4), (5, 2.8, 4), (5, 2.8, 1)],\\n        sizes=[(0.1, 0.1, 0.1)] *</span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">4, orientations=[(1, 0)] * 4\\n    )\\n\\n    # Scene 2: Parallelogram (diagonals bisect but have different </span><span style=\"background-color: #272822\">         </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">lengths)\\n    # Penalty = |sqrt(80) - sqrt(20)| approx 4.472\\n    scene_2 = create_scene_for_testing(\\n        </span><span style=\"background-color: #272822\">   </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">room_type=room_type, num_objects=4,\\n        class_label_indices=[lamp_idx] * 4,\\n        translations=[(0, 2.8, </span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">0), (3, 2.8, 4), (8, 2.8, 4), (5, 2.8, 0)],\\n        sizes=[(0.1, 0.1, 0.1)] * 4, orientations=[(1, 0)] * 4\\n    </span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">)\\n    \\n    # Scene 3: General quadrilateral (midpoints and lengths differ)\\n    scene_3 = </span><span style=\"background-color: #272822\">                      </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">create_scene_for_testing(\\n        room_type=room_type, num_objects=4,\\n        class_label_indices=[lamp_idx] * </span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">4,\\n        translations=[(0, 2.8, 0), (1, 2.8, 3), (4, 2.8, 4), (5, 2.8, 1)],\\n        sizes=[(0.1, 0.1, 0.1)] *</span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">4, orientations=[(1, 0)] * 4\\n    )\\n\\n    # Scene 4: Case with 3 ceiling lamps (should have 0 reward)\\n    </span><span style=\"background-color: #272822\">      </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">scene_4 = create_scene_for_testing(\\n        room_type=room_type, num_objects=3,\\n        </span><span style=\"background-color: #272822\">                        </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">class_label_indices=[lamp_idx] * 3,\\n        translations=[(1, 2.8, 1), (1, 2.8, 3), (3, 2.8, 1)],\\n        </span><span style=\"background-color: #272822\">      </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">sizes=[(0.1, 0.1, 0.1)] * 3, orientations=[(1, 0)] * 3\\n    )\\n\\n    def stack_scenes(scenes):\\n        stacked =</span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">{}\\n        keys = scenes[0].keys()\\n        for key in keys:\\n            if isinstance(scenes[0][key], </span><span style=\"background-color: #272822\">         </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">torch.Tensor):\\n                max_n = max(s[key].shape[1] for s in scenes)\\n                padded_tensors = </span><span style=\"background-color: #272822\">   </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">[]\\n                for s in scenes:\\n                    tensor = s[key]\\n                    n = </span><span style=\"background-color: #272822\">               </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">tensor.shape[1]\\n                    if n &lt; max_n:\\n                        padding_shape = list(tensor.shape)\\n </span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">padding_shape[1] = max_n - n\\n                        padding = torch.zeros(padding_shape, dtype=tensor.dtype, </span><span style=\"background-color: #272822\">   </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">device=tensor.device)\\n                        if key == 'is_empty':\\n                            padding = </span><span style=\"background-color: #272822\">      </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">torch.ones(padding_shape, dtype=torch.bool, device=tensor.device)\\n                        padded_tensor = </span><span style=\"background-color: #272822\">       </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">torch.cat([tensor, padding], dim=1)\\n                    else:\\n                        padded_tensor = tensor\\n </span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">padded_tensors.append(padded_tensor)\\n                stacked[key] = torch.cat(padded_tensors, dim=0)\\n          </span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">else:\\n                stacked[key] = scenes[0][key]\\n        return stacked\\n        \\n    parsed_scenes = </span><span style=\"background-color: #272822\">      </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">stack_scenes([scene_1, scene_2, scene_3, scene_4])\\n    \\n    rewards = get_reward(parsed_scenes, idx_to_labels, </span><span style=\"background-color: #272822\"> </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">room_type, floor_polygons)\\n    print(\\\"Testing ceiling_lamps_form_rectangle_reward...\\\")\\n    </span><span style=\"background-color: #272822\">                   </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">print(\\\"Rewards:\\\", rewards)\\n    \\n    assert rewards.shape == (4,), f\\\"Expected shape (4,), got </span><span style=\"background-color: #272822\">                </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">{rewards.shape}\\\"\\n    assert torch.isclose(rewards[0], torch.tensor(0.0), atol=1e-6), f\\\"Scene 1 (rectangle) </span><span style=\"background-color: #272822\">    </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">failed. Expected 0.0, got {rewards[0]}\\\"\\n    expected_r2 = -(math.sqrt(80) - math.sqrt(20))\\n    assert </span><span style=\"background-color: #272822\">         </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">torch.isclose(rewards[1], torch.tensor(expected_r2), atol=1e-5), f\\\"Scene 2 (parallelogram) failed. Expected </span><span style=\"background-color: #272822\">     </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">{expected_r2:.4f}, got {rewards[1]:.4f}\\\"\\n    assert rewards[2] &lt; -0.1, f\\\"Scene 3 (quad) failed. Expected </span><span style=\"background-color: #272822\">      </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">significantly negative reward, got {rewards[2]}\\\"\\n    assert torch.isclose(rewards[3], torch.tensor(0.0)), </span><span style=\"background-color: #272822\">      </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">f\\\"Scene 4 (3 lamps) failed. Expected 0.0, got {rewards[3]}\\\"\\n    print(\\\"All tests for </span><span style=\"background-color: #272822\">                         </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">ceiling_lamps_form_rectangle_reward passed!\\\")\\n\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">                                                                </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">      </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">\"success_threshold\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">: </span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">-0.1</span><span style=\"background-color: #272822\">                                                                                   </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    }</span><span style=\"background-color: #272822\">                                                                                                             </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">  ]</span><span style=\"background-color: #272822\">                                                                                                               </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">}</span><span style=\"background-color: #272822\">                                                                                                                 </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m{\u001b[0m\u001b[48;2;39;40;34m                                                                                                                \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m  \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m\"rewards\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[48;2;39;40;34m                                                                                                   \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m{\u001b[0m\u001b[48;2;39;40;34m                                                                                                            \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m      \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m\"id\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"R1\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                                                                                \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m      \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m\"constraint_id\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"C1\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                                                                     \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m      \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m\"name\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"exact_ceiling_lamp_count_reward\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                                                 \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m      \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m\"code\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"import torch\\n\\ndef get_reward(parsed_scenes, idx_to_labels, room_type, floor_polygons, \u001b[0m\u001b[48;2;39;40;34m          \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m**kwargs):\\n    '''\\n    Calculates a reward based on the number of ceiling lamps in the scene.\\n    The reward \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mis 0 if the count is exactly 4, and a negative penalty otherwise.\\n    The penalty is -abs(count - 4).\\n\\n    \u001b[0m\u001b[48;2;39;40;34m   \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mInput:\\n        - parsed_scenes: Dictionary of scene tensors.\\n        - idx_to_labels: Dictionary mapping class \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mindices to labels.\\n        - room_type: String, e.g., \\\"bedroom\\\".\\n        - floor_polygons: List of floor \u001b[0m\u001b[48;2;39;40;34m    \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mpolygon vertices.\\n        - **kwargs: Additional keyword arguments.\\n\\n    Output:\\n        reward: torch.Tensor\u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mof shape (B,)\\n    '''\\n    device = parsed_scenes['positions'].device\\n    batch_size = \u001b[0m\u001b[48;2;39;40;34m                        \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mparsed_scenes['positions'].shape[0]\\n    rewards = torch.zeros(batch_size, device=device)\\n    \\n    try:\\n      \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mclass_to_idx = {v: k for k, v in idx_to_labels.items()}\\n        ceiling_lamp_idx = \u001b[0m\u001b[48;2;39;40;34m                             \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mint(class_to_idx['ceiling_lamp'])\\n    except KeyError:\\n        # If 'ceiling_lamp' is not a valid class, return\u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mzero reward for all scenes\\n        return rewards\\n\\n    object_indices = parsed_scenes['object_indices']\\n    \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mis_empty = parsed_scenes['is_empty']\\n    \\n    # Count ceiling lamps in each scene, ignoring empty slots\\n    \u001b[0m\u001b[48;2;39;40;34m  \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mis_ceiling_lamp = (object_indices == ceiling_lamp_idx) & ~is_empty\\n    counts = is_ceiling_lamp.sum(dim=1)\\n    \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\\n    target_count = 4\\n    \\n    # Reward is the negative absolute difference from the target count\\n    rewards\u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m= -torch.abs(counts - target_count).float()\\n    \\n    return rewards\\n\\ndef test_reward(idx_to_labels, \u001b[0m\u001b[48;2;39;40;34m         \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mroom_type, floor_polygons, create_scene_for_testing, **kwargs):\\n    '''\\n    Tests the get_reward function for \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mexact_ceiling_lamp_count.\\n    '''\\n    class_to_idx = {v: k for k, v in idx_to_labels.items()}\\n    lamp_idx = \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mint(class_to_idx['ceiling_lamp'])\\n    other_idx = int(class_to_idx['chair'])\\n\\n    # Scene 1: Perfect case with\u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m4 ceiling lamps\\n    scene_1 = create_scene_for_testing(\\n        room_type=room_type, num_objects=4,\\n        \u001b[0m\u001b[48;2;39;40;34m  \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mclass_label_indices=[lamp_idx, lamp_idx, lamp_idx, lamp_idx],\\n        translations=[(1, 2.8, 1), (1, 2.8, 3), \u001b[0m\u001b[48;2;39;40;34m  \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m(3, 2.8, 1), (3, 2.8, 3)],\\n        sizes=[(0.1, 0.1, 0.1)] * 4,\\n        orientations=[(1, 0)] * 4\\n    )\\n\\n   \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m# Scene 2: Case with 3 ceiling lamps\\n    scene_2 = create_scene_for_testing(\\n        room_type=room_type, \u001b[0m\u001b[48;2;39;40;34m     \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mnum_objects=3,\\n        class_label_indices=[lamp_idx, lamp_idx, lamp_idx],\\n        translations=[(1, 2.8, 1), \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m(1, 2.8, 3), (3, 2.8, 1)],\\n        sizes=[(0.1, 0.1, 0.1)] * 3,\\n        orientations=[(1, 0)] * 3\\n    )\\n\\n   \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m# Scene 3: Case with 5 ceiling lamps\\n    scene_3 = create_scene_for_testing(\\n        room_type=room_type, \u001b[0m\u001b[48;2;39;40;34m     \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mnum_objects=5,\\n        class_label_indices=[lamp_idx] * 5,\\n        translations=[(1, 2.8, 1), (1, 2.8, 3), (3, \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m2.8, 1), (3, 2.8, 3), (2, 2.8, 2)],\\n        sizes=[(0.1, 0.1, 0.1)] * 5,\\n        orientations=[(1, 0)] * 5\\n   \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m)\\n    \\n    # Scene 4: Case with 0 ceiling lamps\\n    scene_4 = create_scene_for_testing(\\n        \u001b[0m\u001b[48;2;39;40;34m             \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mroom_type=room_type, num_objects=2,\\n        class_label_indices=[other_idx, other_idx],\\n        \u001b[0m\u001b[48;2;39;40;34m               \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mtranslations=[(1, 1, 1), (2, 1, 2)],\\n        sizes=[(0.5, 0.5, 0.5)] * 2,\\n        orientations=[(1, 0)] * 2\\n  \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m)\\n\\n    def stack_scenes(scenes):\\n        stacked = {}\\n        keys = scenes[0].keys()\\n        for key in \u001b[0m\u001b[48;2;39;40;34m   \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mkeys:\\n            if isinstance(scenes[0][key], torch.Tensor):\\n                max_n = max(s[key].shape[1] for \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34ms in scenes)\\n                padded_tensors = []\\n                for s in scenes:\\n                    tensor =\u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34ms[key]\\n                    n = tensor.shape[1]\\n                    if n < max_n:\\n                        \u001b[0m\u001b[48;2;39;40;34m     \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mpadding_shape = list(tensor.shape)\\n                        padding_shape[1] = max_n - n\\n                       \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mpadding = torch.zeros(padding_shape, dtype=tensor.dtype, device=tensor.device)\\n                        if key ==\u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m'is_empty':\\n                            padding = torch.ones(padding_shape, dtype=torch.bool, \u001b[0m\u001b[48;2;39;40;34m                  \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mdevice=tensor.device)\\n                        padded_tensor = torch.cat([tensor, padding], dim=1)\\n             \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34melse:\\n                        padded_tensor = tensor\\n                    padded_tensors.append(padded_tensor)\\n\u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mstacked[key] = torch.cat(padded_tensors, dim=0)\\n            else:\\n                stacked[key] = \u001b[0m\u001b[48;2;39;40;34m              \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mscenes[0][key]\\n        return stacked\\n\\n    parsed_scenes = stack_scenes([scene_1, scene_2, scene_3, \u001b[0m\u001b[48;2;39;40;34m          \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mscene_4])\\n    \\n    rewards = get_reward(parsed_scenes, idx_to_labels, room_type, floor_polygons)\\n    \u001b[0m\u001b[48;2;39;40;34m         \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mprint(\\\"Testing exact_ceiling_lamp_count_reward...\\\")\\n    print(\\\"Rewards:\\\", rewards)\\n    \\n    assert \u001b[0m\u001b[48;2;39;40;34m       \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mrewards.shape == (4,), f\\\"Expected shape (4,), got {rewards.shape}\\\"\\n    assert torch.isclose(rewards[0], \u001b[0m\u001b[48;2;39;40;34m      \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mtorch.tensor(0.0)), f\\\"Scene 1 (4 lamps) failed. Expected 0.0, got {rewards[0]}\\\"\\n    assert \u001b[0m\u001b[48;2;39;40;34m                   \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mtorch.isclose(rewards[1], torch.tensor(-1.0)), f\\\"Scene 2 (3 lamps) failed. Expected -1.0, got {rewards[1]}\\\"\\n  \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34massert torch.isclose(rewards[2], torch.tensor(-1.0)), f\\\"Scene 3 (5 lamps) failed. Expected -1.0, got \u001b[0m\u001b[48;2;39;40;34m           \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m{rewards[2]}\\\"\\n    assert torch.isclose(rewards[3], torch.tensor(-4.0)), f\\\"Scene 4 (0 lamps) failed. Expected \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m-4.0, got {rewards[3]}\\\"\\n    print(\\\"All tests for exact_ceiling_lamp_count_reward passed!\\\")\\n\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m               \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m      \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m\"success_threshold\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m0.0\u001b[0m\u001b[48;2;39;40;34m                                                                                   \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m},\u001b[0m\u001b[48;2;39;40;34m                                                                                                           \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m{\u001b[0m\u001b[48;2;39;40;34m                                                                                                            \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m      \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m\"id\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"R2\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                                                                                \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m      \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m\"constraint_id\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"C2\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                                                                     \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m      \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m\"name\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"ceiling_lamps_form_rectangle_reward\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                                             \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m      \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m\"code\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"import torch\\nimport itertools\\nimport math\\n\\ndef get_reward(parsed_scenes, idx_to_labels, \u001b[0m\u001b[48;2;39;40;34m      \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mroom_type, floor_polygons, **kwargs):\\n    '''\\n    Calculates a reward if 4 ceiling lamps form a rectangle in \u001b[0m\u001b[48;2;39;40;34m  \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mthe XZ plane.\\n    A penalty is applied based on the deviation from a perfect rectangle.\\n    The deviation is \u001b[0m\u001b[48;2;39;40;34m  \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mmeasured as the minimum sum of diagonal midpoint distance\\n    and diagonal length difference across all possible\u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mpairings.\\n    If the lamp count is not 4, the reward is 0.\\n\\n    Input:\\n        - parsed_scenes: Dictionary of\u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mscene tensors.\\n        - idx_to_labels: Dictionary mapping class indices to labels.\\n        - room_type: \u001b[0m\u001b[48;2;39;40;34m      \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mString, e.g., \\\"bedroom\\\".\\n        - floor_polygons: List of floor polygon vertices.\\n        - **kwargs: \u001b[0m\u001b[48;2;39;40;34m      \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mAdditional keyword arguments.\\n\\n    Output:\\n        reward: torch.Tensor of shape (B,)\\n    '''\\n    device = \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mparsed_scenes['positions'].device\\n    batch_size = parsed_scenes['positions'].shape[0]\\n    rewards = \u001b[0m\u001b[48;2;39;40;34m          \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mtorch.zeros(batch_size, device=device)\\n    \\n    try:\\n        class_to_idx = {v: k for k, v in \u001b[0m\u001b[48;2;39;40;34m                \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34midx_to_labels.items()}\\n        ceiling_lamp_idx = int(class_to_idx['ceiling_lamp'])\\n    except KeyError:\\n     \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mreturn rewards\\n\\n    positions = parsed_scenes['positions']\\n    object_indices = \u001b[0m\u001b[48;2;39;40;34m                              \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mparsed_scenes['object_indices']\\n    is_empty = parsed_scenes['is_empty']\\n    \\n    for i in \u001b[0m\u001b[48;2;39;40;34m                   \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mrange(batch_size):\\n        scene_mask = (object_indices[i] == ceiling_lamp_idx) & ~is_empty[i]\\n        \u001b[0m\u001b[48;2;39;40;34m        \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mlamp_positions = positions[i, scene_mask, :]\\n        \\n        if lamp_positions.shape[0] != 4:\\n            \u001b[0m\u001b[48;2;39;40;34m   \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mrewards[i] = 0.0\\n            continue\\n            \\n        points_xz = lamp_positions[:, [0, 2]]\\n        \\n  \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mpairings = [((0, 1), (2, 3)), ((0, 2), (1, 3)), ((0, 3), (1, 2))]\\n        min_penalty = \u001b[0m\u001b[48;2;39;40;34m                        \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mtorch.tensor(float('inf'), device=device)\\n        \\n        for d1_indices, d2_indices in pairings:\\n           \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mp_a, p_b = points_xz[d1_indices[0]], points_xz[d1_indices[1]]\\n            p_c, p_d = points_xz[d2_indices[0]], \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mpoints_xz[d2_indices[1]]\\n            \\n            midpoint1 = (p_a + p_b) / 2.0\\n            midpoint2 = (p_c +\u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mp_d) / 2.0\\n            midpoint_dist = torch.norm(midpoint1 - midpoint2)\\n            \\n            len1 = \u001b[0m\u001b[48;2;39;40;34m     \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mtorch.norm(p_a - p_b)\\n            len2 = torch.norm(p_c - p_d)\\n            length_diff = torch.abs(len1 - \u001b[0m\u001b[48;2;39;40;34m     \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mlen2)\\n            \\n            total_penalty = midpoint_dist + length_diff\\n            \\n            if \u001b[0m\u001b[48;2;39;40;34m      \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mtotal_penalty < min_penalty:\\n                min_penalty = total_penalty\\n                \\n        rewards[i] =\u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m-min_penalty\\n        \\n    return rewards\\n\\ndef test_reward(idx_to_labels, room_type, floor_polygons, \u001b[0m\u001b[48;2;39;40;34m         \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mcreate_scene_for_testing, **kwargs):\\n    '''\\n    Tests the get_reward function for \u001b[0m\u001b[48;2;39;40;34m                            \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mceiling_lamps_form_rectangle.\\n    '''\\n    class_to_idx = {v: k for k, v in idx_to_labels.items()}\\n    lamp_idx\u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m= int(class_to_idx['ceiling_lamp'])\\n\\n    # Scene 1: Perfect rectangle\\n    scene_1 = \u001b[0m\u001b[48;2;39;40;34m                          \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mcreate_scene_for_testing(\\n        room_type=room_type, num_objects=4,\\n        class_label_indices=[lamp_idx] * \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m4,\\n        translations=[(1, 2.8, 1), (1, 2.8, 4), (5, 2.8, 4), (5, 2.8, 1)],\\n        sizes=[(0.1, 0.1, 0.1)] *\u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m4, orientations=[(1, 0)] * 4\\n    )\\n\\n    # Scene 2: Parallelogram (diagonals bisect but have different \u001b[0m\u001b[48;2;39;40;34m        \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mlengths)\\n    # Penalty = |sqrt(80) - sqrt(20)| approx 4.472\\n    scene_2 = create_scene_for_testing(\\n        \u001b[0m\u001b[48;2;39;40;34m  \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mroom_type=room_type, num_objects=4,\\n        class_label_indices=[lamp_idx] * 4,\\n        translations=[(0, 2.8, \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m0), (3, 2.8, 4), (8, 2.8, 4), (5, 2.8, 0)],\\n        sizes=[(0.1, 0.1, 0.1)] * 4, orientations=[(1, 0)] * 4\\n    \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m)\\n    \\n    # Scene 3: General quadrilateral (midpoints and lengths differ)\\n    scene_3 = \u001b[0m\u001b[48;2;39;40;34m                     \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mcreate_scene_for_testing(\\n        room_type=room_type, num_objects=4,\\n        class_label_indices=[lamp_idx] * \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m4,\\n        translations=[(0, 2.8, 0), (1, 2.8, 3), (4, 2.8, 4), (5, 2.8, 1)],\\n        sizes=[(0.1, 0.1, 0.1)] *\u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m4, orientations=[(1, 0)] * 4\\n    )\\n\\n    # Scene 4: Case with 3 ceiling lamps (should have 0 reward)\\n    \u001b[0m\u001b[48;2;39;40;34m     \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mscene_4 = create_scene_for_testing(\\n        room_type=room_type, num_objects=3,\\n        \u001b[0m\u001b[48;2;39;40;34m                       \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mclass_label_indices=[lamp_idx] * 3,\\n        translations=[(1, 2.8, 1), (1, 2.8, 3), (3, 2.8, 1)],\\n        \u001b[0m\u001b[48;2;39;40;34m     \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34msizes=[(0.1, 0.1, 0.1)] * 3, orientations=[(1, 0)] * 3\\n    )\\n\\n    def stack_scenes(scenes):\\n        stacked =\u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m{}\\n        keys = scenes[0].keys()\\n        for key in keys:\\n            if isinstance(scenes[0][key], \u001b[0m\u001b[48;2;39;40;34m        \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mtorch.Tensor):\\n                max_n = max(s[key].shape[1] for s in scenes)\\n                padded_tensors = \u001b[0m\u001b[48;2;39;40;34m  \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m[]\\n                for s in scenes:\\n                    tensor = s[key]\\n                    n = \u001b[0m\u001b[48;2;39;40;34m              \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mtensor.shape[1]\\n                    if n < max_n:\\n                        padding_shape = list(tensor.shape)\\n \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mpadding_shape[1] = max_n - n\\n                        padding = torch.zeros(padding_shape, dtype=tensor.dtype, \u001b[0m\u001b[48;2;39;40;34m  \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mdevice=tensor.device)\\n                        if key == 'is_empty':\\n                            padding = \u001b[0m\u001b[48;2;39;40;34m     \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mtorch.ones(padding_shape, dtype=torch.bool, device=tensor.device)\\n                        padded_tensor = \u001b[0m\u001b[48;2;39;40;34m      \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mtorch.cat([tensor, padding], dim=1)\\n                    else:\\n                        padded_tensor = tensor\\n \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mpadded_tensors.append(padded_tensor)\\n                stacked[key] = torch.cat(padded_tensors, dim=0)\\n          \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34melse:\\n                stacked[key] = scenes[0][key]\\n        return stacked\\n        \\n    parsed_scenes = \u001b[0m\u001b[48;2;39;40;34m     \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mstack_scenes([scene_1, scene_2, scene_3, scene_4])\\n    \\n    rewards = get_reward(parsed_scenes, idx_to_labels, \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mroom_type, floor_polygons)\\n    print(\\\"Testing ceiling_lamps_form_rectangle_reward...\\\")\\n    \u001b[0m\u001b[48;2;39;40;34m                  \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mprint(\\\"Rewards:\\\", rewards)\\n    \\n    assert rewards.shape == (4,), f\\\"Expected shape (4,), got \u001b[0m\u001b[48;2;39;40;34m               \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m{rewards.shape}\\\"\\n    assert torch.isclose(rewards[0], torch.tensor(0.0), atol=1e-6), f\\\"Scene 1 (rectangle) \u001b[0m\u001b[48;2;39;40;34m   \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mfailed. Expected 0.0, got {rewards[0]}\\\"\\n    expected_r2 = -(math.sqrt(80) - math.sqrt(20))\\n    assert \u001b[0m\u001b[48;2;39;40;34m        \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mtorch.isclose(rewards[1], torch.tensor(expected_r2), atol=1e-5), f\\\"Scene 2 (parallelogram) failed. Expected \u001b[0m\u001b[48;2;39;40;34m    \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m{expected_r2:.4f}, got {rewards[1]:.4f}\\\"\\n    assert rewards[2] < -0.1, f\\\"Scene 3 (quad) failed. Expected \u001b[0m\u001b[48;2;39;40;34m     \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34msignificantly negative reward, got {rewards[2]}\\\"\\n    assert torch.isclose(rewards[3], torch.tensor(0.0)), \u001b[0m\u001b[48;2;39;40;34m     \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mf\\\"Scene 4 (3 lamps) failed. Expected 0.0, got {rewards[3]}\\\"\\n    print(\\\"All tests for \u001b[0m\u001b[48;2;39;40;34m                        \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mceiling_lamps_form_rectangle_reward passed!\\\")\\n\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                                               \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m      \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m\"success_threshold\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m-0.1\u001b[0m\u001b[48;2;39;40;34m                                                                                  \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m}\u001b[0m\u001b[48;2;39;40;34m                                                                                                            \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m  \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[48;2;39;40;34m                                                                                                              \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m}\u001b[0m\u001b[48;2;39;40;34m                                                                                                                \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "console.print(Markdown(llm_response_2.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f3a198e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R1 C1 exact_ceiling_lamp_count_reward\n",
      "Saved code to dynamic_reward_functions/R1_exact_ceiling_lamp_count_reward.py\n",
      "R2 C2 ceiling_lamps_form_rectangle_reward\n",
      "Saved code to dynamic_reward_functions/R2_ceiling_lamps_form_rectangle_reward.py\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "rewards_dict = json.loads(llm_response_2.text.split(\"```json\")[1].split(\"```\")[0])\n",
    "rewards = rewards_dict[\"rewards\"]\n",
    "import os\n",
    "output_dir = \"dynamic_reward_functions\"\n",
    "if os.path.exists(output_dir):\n",
    "    import shutil\n",
    "    shutil.rmtree(os.path.abspath(output_dir))\n",
    "\n",
    "for reward in rewards:\n",
    "    print(reward[\"id\"], reward[\"constraint_id\"], reward[\"name\"])\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    # Write the code to a file named after the reward's snake_case name\n",
    "    file_path = os.path.join(output_dir, f\"{reward['id']}_{reward['name']}.py\")\n",
    "    with open(file_path, \"w\") as f:\n",
    "        f.write(reward[\"code\"])\n",
    "\n",
    "    print(f\"Saved code to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5a56910",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pulchowk/3dhope_rl/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "No GUI library found. Simple-3dviz will be running headless only.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'R2_ceiling_lamps_form_rectangle_reward': <function test_reward at 0x7fe842f965f0>, 'R1_exact_ceiling_lamp_count_reward': <function test_reward at 0x7fe842f975b0>}\n",
      "R2_ceiling_lamps_form_rectangle_reward\n",
      "<function test_reward at 0x7fe842f965f0>\n",
      "Testing ceiling_lamps_form_rectangle_reward...\n",
      "Rewards: tensor([-0.0000, -4.4721, -2.1847,  0.0000], device='cuda:0')\n",
      "All tests for ceiling_lamps_form_rectangle_reward passed!\n",
      "R1_exact_ceiling_lamp_count_reward\n",
      "<function test_reward at 0x7fe842f975b0>\n",
      "Testing exact_ceiling_lamp_count_reward...\n",
      "Rewards: tensor([-0., -1., -1., -4.], device='cuda:0')\n",
      "All tests for exact_ceiling_lamp_count_reward passed!\n"
     ]
    }
   ],
   "source": [
    "# run the get_reward_stats_from_dataset and get_reward_stats_from_baseline functions to get reward statistics, can be helpful to figure out how difficult each constraint is to satisfy for the generator\n",
    "from dynamic_constraint_rewards.commons import import_dynamic_reward_functions\n",
    "from dynamic_constraint_rewards.get_reward_stats_from_baseline import get_reward_stats_from_baseline\n",
    "from universal_constraint_rewards.commons import idx_to_labels\n",
    "\n",
    "reward_code_dir = \"dynamic_reward_functions\"\n",
    "\n",
    "import importlib\n",
    "\n",
    "\n",
    "\n",
    "get_reward_functions, test_reward_functions = import_dynamic_reward_functions(reward_code_dir)  \n",
    "\n",
    "floor_polygons = [[-3,-3],[-3,3],[3,3],[3,-3]]\n",
    "\n",
    "print(test_reward_functions)\n",
    "\n",
    "for test_reward_function_name, test_reward_function in test_reward_functions.items():\n",
    "    print(test_reward_function_name)\n",
    "    print(test_reward_function)\n",
    "    test_reward_function(idx_to_labels, ROOM_TYPE, floor_polygons, create_scene_for_testing=create_scene_for_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c93257ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating CustomDataset: [Errno 2] No such file or directory: '/home/pulchowk/ThreedFront/bedroom/dataset_stats.txt'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4015658/3172228710.py:10: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with hydra.initialize_config_dir(config_dir):\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/pulchowk/ThreedFront/bedroom/dataset_stats.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m     cfg \u001b[38;5;241m=\u001b[39m hydra\u001b[38;5;241m.\u001b[39mcompose(config_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m, overrides\u001b[38;5;241m=\u001b[39moverrides)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# print(cfg)\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m stats \u001b[38;5;241m=\u001b[39m \u001b[43mget_reward_stats_from_baseline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mget_reward_functions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_scenes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# algorithm=\"scene_diffuser_flux_transformer\",\u001b[39;49;00m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m9xplsx0a\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# algorithm_classifier_free_guidance_use_floor=False,\u001b[39;49;00m\n\u001b[1;32m     23\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/3dhope_rl/dynamic_constraint_rewards/get_reward_stats_from_baseline.py:71\u001b[0m, in \u001b[0;36mget_reward_stats_from_baseline\u001b[0;34m(reward_functions, load, dataset, config, dataset_processed_scene_data_path, dataset_max_num_objects_per_scene, num_scenes, algorithm, algorithm_trainer, experiment_find_unused_parameters, algorithm_classifier_free_guidance_use, algorithm_classifier_free_guidance_use_floor, algorithm_classifier_free_guidance_weight, algorithm_custom_loss, algorithm_ema_use, algorithm_noise_schedule_scheduler, algorithm_noise_schedule_ddim_num_inference_timesteps)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;03mSample scenes from baseline model and compute reward statistics.\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;124;03m    {\"reward_function_name\": {\"min\": float, \"max\": float, \"mean\": float, \"stddev\": float}}\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 71\u001b[0m     custom_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mCustomDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msplits\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError creating CustomDataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/3dhope_rl/steerable_scene_generation/datasets/custom_scene/custom_scene_final.py:90\u001b[0m, in \u001b[0;36mCustomDataset.__init__\u001b[0;34m(self, cfg, split, ckpt_path)\u001b[0m\n\u001b[1;32m     84\u001b[0m     split_names \u001b[38;5;241m=\u001b[39m [split]\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# print(f\"[Ashok] max_num_objects_per_scene: {cfg.max_num_objects_per_scene}\")\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# import sys; sys.exit();\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# Load ThreedFront raw and encoded datasets\u001b[39;00m\n\u001b[0;32m---> 90\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_dataset, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoded_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mget_dataset_raw_and_encoded\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[43mupdate_data_file_paths\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_cfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_num_objects_per_scene\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_room_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnetwork_cfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mroom_mask_condition\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# HF dataset features are not used in this ThreedFront path\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhf_dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/3dhope_rl/steerable_scene_generation/datasets/custom_scene/threed_front_encoding.py:105\u001b[0m, in \u001b[0;36mget_dataset_raw_and_encoded\u001b[0;34m(config, filter_fn, path_to_bounds, augmentations, split, max_length, include_room_mask)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_dataset_raw_and_encoded\u001b[39m(\n\u001b[1;32m     97\u001b[0m     config,\n\u001b[1;32m     98\u001b[0m     filter_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m s: s,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    103\u001b[0m     include_room_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    104\u001b[0m ):\n\u001b[0;32m--> 105\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mget_raw_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath_to_bounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_room_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_room_mask\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m dataset_encoding_factory(\n\u001b[1;32m    109\u001b[0m         config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_type\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    110\u001b[0m         dataset,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    113\u001b[0m         max_length,\n\u001b[1;32m    114\u001b[0m     )\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dataset, encoding\n",
      "File \u001b[0;32m~/ThreedFront/threed_front/datasets/__init__.py:29\u001b[0m, in \u001b[0;36mget_raw_dataset\u001b[0;34m(config, filter_fn, path_to_bounds, split, include_edges, include_room_mask)\u001b[0m\n\u001b[1;32m     26\u001b[0m     splits_builder \u001b[38;5;241m=\u001b[39m CSVSplitsBuilder(config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mannotation_file\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     27\u001b[0m     split_scene_ids \u001b[38;5;241m=\u001b[39m splits_builder\u001b[38;5;241m.\u001b[39mget_splits(split)\n\u001b[0;32m---> 29\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mCachedThreedFront\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdataset_directory\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscene_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_scene_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43minclude_edges\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_edges\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_floor_plan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_room_mask\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     37\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m ThreedFront\u001b[38;5;241m.\u001b[39mfrom_dataset_directory(\n\u001b[1;32m     38\u001b[0m         config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset_directory\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     39\u001b[0m         config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath_to_model_info\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m         filter_fn\n\u001b[1;32m     44\u001b[0m     )\n",
      "File \u001b[0;32m~/ThreedFront/threed_front/datasets/threed_front.py:266\u001b[0m, in \u001b[0;36mCachedThreedFront.__init__\u001b[0;34m(self, base_dir, config, scene_ids, parse_floor_plan, rendered_name, include_edges)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig \u001b[38;5;241m=\u001b[39m config\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# Load training set data stats\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_train_stats\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain_stats\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;66;03m# Find subdirectory names where the scene id is in the specified list\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tags \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m([tag \u001b[38;5;28;01mfor\u001b[39;00m tag \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_base_dir)\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tag\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m scene_ids])\n",
      "File \u001b[0;32m~/ThreedFront/threed_front/datasets/threed_front.py:578\u001b[0m, in \u001b[0;36mCachedThreedFront._parse_train_stats\u001b[0;34m(self, train_stats)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_parse_train_stats\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_stats):\n\u001b[0;32m--> 578\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_base_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_stats\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    579\u001b[0m         train_stats \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_centroids \u001b[38;5;241m=\u001b[39m train_stats[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbounds_translations\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/pulchowk/ThreedFront/bedroom/dataset_stats.txt'"
     ]
    }
   ],
   "source": [
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "import os\n",
    "\n",
    "# Convert relative config dir to absolute path to avoid HydraException\n",
    "config_dir = os.path.abspath(\"../configurations\")\n",
    "\n",
    "# To override OmegaConf config values (e.g. set dataset=\"custom_scene\"), \n",
    "# you can pass overrides as a list to hydra.compose:\n",
    "with hydra.initialize_config_dir(config_dir):\n",
    "    overrides = [\"dataset=custom_scene\", \"algorithm=scene_diffuser_midiffusion\"]\n",
    "    cfg = hydra.compose(config_name=\"config\", overrides=overrides)\n",
    "\n",
    "# print(cfg)\n",
    "\n",
    "stats = get_reward_stats_from_baseline(\n",
    "    get_reward_functions,\n",
    "    num_scenes=1000,\n",
    "    config=cfg,\n",
    "    # algorithm=\"scene_diffuser_flux_transformer\",\n",
    "    load=\"9xplsx0a\",\n",
    "    # algorithm_classifier_free_guidance_use_floor=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "436f4f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">{'experiment': {'debug': '${debug}', 'tasks': ['training'], 'seed': 42, 'matmul_precision': 'high',                \n",
       "'find_unused_parameters': False, 'training': {'load_weights_only': False, 'precision': 32, 'compile': False, 'lr': \n",
       "0.0002, 'batch_size': 256, 'max_epochs': -1, 'max_steps': 1000000, 'max_time': None, 'log_every_n_steps': 25,      \n",
       "'fast_dev_run': False, 'pin_memory': True, 'prefetch_factor': 10, 'data': {'num_workers': 12, 'shuffle': True},    \n",
       "'optim': {'accumulate_grad_batches': 1, 'gradient_clip_val': 1.0}, 'checkpointing': {'every_n_train_steps': 10000, \n",
       "'every_n_epochs': None, 'train_time_interval': None, 'enable_version_counter': False, 'save_top_k': 100, 'monitor':\n",
       "'validation/loss', 'mode': 'min', 'save_last': False}, 'weight_decay': 0.001}, 'validation': {'precision': 32,     \n",
       "'compile': False, 'batch_size': 256, 'val_every_n_step': 5000, 'val_every_n_epoch': None, 'limit_batch': None,     \n",
       "'pin_memory': False, 'prefetch_factor': 5, 'data': {'num_workers': 12, 'shuffle': False}}, 'test': {'precision':   \n",
       "32, 'compile': False, 'batch_size': 256, 'limit_batch': 1, 'inference_mode': False, 'pin_memory': False,           \n",
       "'prefetch_factor': 2, 'data': {'num_workers': 12, 'shuffle': False}}, 'lr_scheduler': {'name': 'cosine',           \n",
       "'num_warmup_steps': 5000, 'epochs_as_steps': '${equal:${experiment.training.max_steps},-1}'}, 'reset_lr_scheduler':\n",
       "False}, 'dataset': {'debug': '${debug}', 'processed_scene_data_path':                                              \n",
       "'/media/ajad/YourBook/AshokSaugatResearchBackup/AshokSaugatResearch/steerable-scene-generation/MiData',            \n",
       "'model_path_vec_len': 22, 'max_num_objects_per_scene': 12, 'translation_vec_len': 3, 'rotation_parametrization':   \n",
       "'procrustes', 'drake_package_maps': [{'package_name': 'tri', 'package_file_path': 'data/tri/package.xml'},         \n",
       "{'package_name': 'gazebo', 'package_file_path': 'data/gazebo/package.xml'}, {'package_name': 'greg',               \n",
       "'package_file_path': 'data/greg/package.xml'}], 'static_directive': None, 'use_permutation_augmentation': False,   \n",
       "'keep_dataset_in_memory': False, 'classifier_free_guidance': '${algorithm.classifier_free_guidance}',              \n",
       "'custom_data_batch_mix': {'use': False, 'label_probs': [0.5, 0.5]}, 'subdataset_sampling': {'use': False,          \n",
       "'use_infinite_iterators': True, 'buffer_size': 2048, 'probabilities': {}}, 'static_subdataset_prompts': {'use':    \n",
       "False, 'name_to_prompt': {}}, 'random_dataset_sampling': {'use': False, 'num_samples': 1000000.0}, 'val_ratio':    \n",
       "0.01, 'test_ratio': 0.001, '_name': 'custom_scene', 'data': {'path_to_processed_data':                             \n",
       "'/home/pulchowk/ThreedFront', 'path_to_dataset_files': '/home/pulchowk/ThreedFront/dataset_files',                 \n",
       "'dataset_directory': 'bedroom', 'dataset_type': 'cached_threedfront', 'encoding_type':                             \n",
       "'cached_diffusion_cosin_angle_wocm_no_prm', 'annotation_file': 'bedroom_threed_front_splits_original.csv',         \n",
       "'augmentations': ['fixed_rotations'], 'train_stats': 'dataset_stats.txt', 'room_layout_size': '64,64', 'room_type':\n",
       "'bedroom'}, 'network': {'type': 'diffusion_scene_layout_mixed', 'sample_num_points': 12, 'max_cuboids': 19,        \n",
       "'angle_dim': 2, 'room_mask_condition': True, 'room_latent_dim': 64, 'position_condition': False,                   \n",
       "'position_emb_dim': 0, 'time_num': 1000, 'diffusion_semantic_kwargs': {'att_1': 0.99999, 'att_T': 9e-06, 'ctt_1':  \n",
       "9e-06, 'ctt_T': 0.99999, 'model_output_type': 'x0', 'mask_weight': 1, 'auxiliary_loss_weight': 0.0005,             \n",
       "'adaptive_auxiliary_loss': True}, 'diffusion_geometric_kwargs': {'_type': 'fc'}}, 'feature_extractor': {'name':    \n",
       "'pointnet_simple', 'feat_units': [4, 64, 64, 512, 64]}, 'training': {'splits': ['train', 'val'], 'epochs': 50000,  \n",
       "'batch_size': 64, 'n_processes': 1, 'save_frequency': 100, 'max_grad_norm': 10, 'optimizer': 'Adam',               \n",
       "'weight_decay': 0.0, 'schedule': 'step', 'lr': 0.0002, 'lr_step': 10000, 'lr_decay': 0.5}, 'validation': {'splits':\n",
       "['test'], 'frequency': 100, 'batch_size': 64}, 'logger': {'type': 'wandb', 'project': 'MiDiffusion',               \n",
       "'schedule_type': 'linear', 'beta_start': 0.0001, 'beta_end': 0.02, 'loss_type': 'mse', 'model_mean_type': 'eps',   \n",
       "'model_var_type': 'fixedsmall', 'net_type': 'transformer', 'net_kwargs': {'seperate_all': True, 'n_layer': 8,      \n",
       "'n_embd': 512, 'n_head': 4, 'dim_feedforward': 2048, 'dropout': 0.1, 'activate': 'GELU', 'timestep_type':          \n",
       "'adalayernorm_abs', 'mlp_ratio': 4}}, 'sdf_cache_dir': './sdf_cache/', 'accessibility_cache_dir':                  \n",
       "'./accessibility_cache/'}, 'algorithm': {'debug': '${debug}', 'lr': '${experiment.training.lr}', 'dataset':        \n",
       "'${dataset}', 'translation_vec_len': '${dataset.translation_vec_len}', 'rotation_parametrization':                 \n",
       "'${dataset.rotation_parametrization}', 'model_path_vec_len': '${dataset.model_path_vec_len}',                      \n",
       "'max_num_objects_per_scene': '${dataset.max_num_objects_per_scene}', 'processed_scene_data_path':                  \n",
       "'${dataset.processed_scene_data_path}', 'drake_package_maps': '${dataset.drake_package_maps}', 'static_directive': \n",
       "'${dataset.static_directive}', 'trainer': 'mixed', 'lr_scheduler': '${experiment.lr_scheduler}',                   \n",
       "'reset_lr_scheduler': '${experiment.reset_lr_scheduler}', 'weight_decay': '${experiment.training.weight_decay}',   \n",
       "'max_epochs': '${experiment.training.max_epochs}', 'loss': {'use_separate_loss_per_object_attribute': True,        \n",
       "'object_translation_attribute_weight': 1.0, 'object_rotation_attribute_weight': 1.0,                               \n",
       "'object_model_attribute_weight': 1.0, 'use_iou_regularization': False, 'iou_weight': 0.1}, 'noise_schedule':       \n",
       "{'scheduler': 'ddpm', 'num_train_timesteps': 1000, 'beta_schedule': 'linear', 'ddim': {'num_inference_timesteps':  \n",
       "50, 'eta': 1.0}}, 'num_additional_tokens_for_sampling': 0, 'ema': {'use': True, 'log_at_train': False,             \n",
       "'update_after_step': 0.0, 'inv_gamma': 1.0, 'power': 0.75, 'min_value': 0.0, 'max_value': 0.9999},                 \n",
       "'classifier_free_guidance': {'use': True, 'txt_encoder': 'bert', 'txt_encoder_size': 'base', 'txt_encoder_coarse': \n",
       "None, 'txt_encoder_coarse_size': '', 'max_length': 110, 'masking_prob': 0.1, 'masking_prob_coarse': 0.1, 'weight': \n",
       "-1.0, 'sampling': {'use_data_labels': False, 'labels': 'A scene with 10 objects.'}, 'use_floor': False},           \n",
       "'postprocessing': {'apply_non_penetration_projection': False, 'apply_forward_simulation': False, 'num_workers':    \n",
       "100, 'return_original_scenes_on_failure': False, 'non_penetration_projection': {'translation_only': True,          \n",
       "'influence_distance': 0.03, 'solver_name': 'snopt', 'iteration_limit': 5000, 'discard_failed_projection_scenes':   \n",
       "True}, 'forward_simulation': {'simulation_time_s': 2.5, 'time_step': 0.001, 'timeout_s': 180.0}}, 'sample_metrics':\n",
       "{'compute_scene_distance_between_samples': False, 'duplicate_distance_theshold': 0.001,                            \n",
       "'compute_scene_penetration': False, 'batch_size': 100, 'num_workers': 100}, 'visualization': {'use_blender_server':\n",
       "False, 'blender_server_url': 'http://127.0.0.1:8000', 'visualize_proximity': False, 'weld_objects': True,          \n",
       "'camera_pose': {'tri_table': {'xyz': [0.0, 0.0, 1.5], 'rpy': [-3.14, 0.0, 1.57]}, 'dimsum_table': {'xyz': [0.0,    \n",
       "0.0, 1.7], 'rpy': [-3.14, 0.0, 1.57]}, 'shelf': {'xyz': [1.2, 0.0, 0.1], 'rpy': [0.0, -1.57, 0.0]}, 'room': {'xyz':\n",
       "[0.0, 0.0, 13.0], 'rpy': [-3.14, 0.0, 1.57]}}, 'image_width': 640, 'image_height': 480, 'background_color': [1.0,  \n",
       "1.0, 1.0], 'num_workers': 100, 'visualize_intermediate_scenes': False, 'num_intermediate_scenes_to_visualize': 5}, \n",
       "'test': {'use_ema': True, 'num_samples_to_render': 0, 'num_samples_to_render_as_label': 0,                         \n",
       "'num_samples_to_visualize': 0, 'num_directives_to_generate': 0, 'num_samples_to_save_as_pickle': 0,                \n",
       "'sample_batch_size': None}, 'validation': {'num_samples_to_render': 0, 'num_samples_to_visualize': 0,              \n",
       "'num_directives_to_generate': 0, 'num_samples_to_compute_physical_feasibility_metrics_for': 100,                   \n",
       "'sample_batch_size': None}, 'predict': {'do_sample': True, 'do_rearrange': False, 'do_complete': False,            \n",
       "'do_inference_time_search': False, 'do_inpainting': False, 'do_sample_scenes_with_k_closest_training_examples':    \n",
       "False, 'inference_time_search': {'use_non_penetration_objective': False, 'use_physical_feasibility_objective':     \n",
       "False, 'use_object_number_objective': True, 'max_steps': 1000, 'non_penetration': {'threshold': -0.001},           \n",
       "'physical_feasibility': {'use_sim': True, 'sim_duration': 0.1, 'sim_time_step': 0.001, 'sim_translation_threshold':\n",
       "0.001, 'sim_rotation_threshold': 0.01, 'static_equilibrium_distance_threshold': 0.001,                             \n",
       "'exclude_welded_objects_from_non_penetration_masking': True}, 'mcts': {'branching_factor': 3, 'exploration_weight':\n",
       "1.4, 'only_consider_children_with_different_mask': False}}, 'sample_scenes_with_k_closest_training_examples':      \n",
       "{'num_k': 3, 'batch_size': 50000}}, 'custom': {'loss': True, 'obj_vec_len': 30, 'obj_diff_vec_len': 30,            \n",
       "'save_pickle': True, 'num_classes': 22, 'translation_dim': 3, 'size_dim': 3, 'angle_dim': 2, 'objfeat_dim': 0,     \n",
       "'old': False, 'use': True}, 'ddpo': {'use_non_penetration_reward': False, 'use_object_number_reward': False,       \n",
       "'use_prompt_following_reward': False, 'use_physical_feasible_objects_reward': False, 'use_iou_reward': False,      \n",
       "'use_custom_non_penetration_reward': False, 'use_has_sofa_reward': False, 'use_universal_reward': False,           \n",
       "'use_composite_reward': True, 'dynamic_constraint_rewards': {'use': False, 'reward_code_dir':                      \n",
       "'/media/ajad/YourBook/AshokSaugatResearchBackup/AshokSaugatResearch/steerable-scene-generation/dynamic_constraint_r\n",
       "ewards/dynamic_reward_functions', 'user_query': 'a kids room', 'room_type': 'bedroom', 'stats_path':               \n",
       "'/media/ajad/YourBook/AshokSaugatResearchBackup/AshokSaugatResearch/steerable-scene-generation/dynamic_constraint_r\n",
       "ewards/stats.json', 'universal_weight': 1.0, 'dynamic_weight': 1.0, 'universal_importance_weights':                \n",
       "{'must_have_furniture': 1.0, 'non_penetration': 1.0, 'object_count': 1.0}}, 'batch_size': 32,                      \n",
       "'last_n_timesteps_only': 0, 'n_timesteps_to_sample': 0, 'advantage_max': 5.0, 'num_reward_workers': 1, 'ppo':      \n",
       "{'num_epochs': 4, 'clip_range': 0.0001}, 'ddpm_reg_weight': 500.0, 'physical_feasibility':                         \n",
       "{'non_penetration_threshold': -0.001, 'use_sim': True, 'sim_duration': 0.1, 'sim_time_step': 0.001,                \n",
       "'sim_translation_threshold': 0.001, 'sim_rotation_threshold': 0.01, 'static_equilibrium_distance_threshold':       \n",
       "0.001}, 'universal_reward': {'use_physcene_reward': False, 'room_type': 'bedroom', 'importance_weights':           \n",
       "{'must_have_furniture': 1.0, 'gravity': 1.0, 'non_penetration': 1.0, 'object_count': 1.0}}},                       \n",
       "'continuous_discrete_only': {'continuous_only': False, 'discrete_only': False}, 'model': {'seperate_all': True,    \n",
       "'n_layer': 8, 'n_embd': 512, 'n_head': 4, 'dim_feedforward': 2048, 'dropout': 0.1, 'activate': 'GELU',             \n",
       "'timestep_type': 'adalayernorm_abs', 'mlp_type': 'fc'}}, 'debug': False, 'wandb': {'entity': '078bct021-ashok-d',  \n",
       "'project': '3dhope_rl', 'mode': 'online'}, 'resume': None, 'load': None, 'use_best': False, 'checkpoint_version':  \n",
       "None, 'expiration_days': 90}                                                                                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "{'experiment': {'debug': '${debug}', 'tasks': ['training'], 'seed': 42, 'matmul_precision': 'high',                \n",
       "'find_unused_parameters': False, 'training': {'load_weights_only': False, 'precision': 32, 'compile': False, 'lr': \n",
       "0.0002, 'batch_size': 256, 'max_epochs': -1, 'max_steps': 1000000, 'max_time': None, 'log_every_n_steps': 25,      \n",
       "'fast_dev_run': False, 'pin_memory': True, 'prefetch_factor': 10, 'data': {'num_workers': 12, 'shuffle': True},    \n",
       "'optim': {'accumulate_grad_batches': 1, 'gradient_clip_val': 1.0}, 'checkpointing': {'every_n_train_steps': 10000, \n",
       "'every_n_epochs': None, 'train_time_interval': None, 'enable_version_counter': False, 'save_top_k': 100, 'monitor':\n",
       "'validation/loss', 'mode': 'min', 'save_last': False}, 'weight_decay': 0.001}, 'validation': {'precision': 32,     \n",
       "'compile': False, 'batch_size': 256, 'val_every_n_step': 5000, 'val_every_n_epoch': None, 'limit_batch': None,     \n",
       "'pin_memory': False, 'prefetch_factor': 5, 'data': {'num_workers': 12, 'shuffle': False}}, 'test': {'precision':   \n",
       "32, 'compile': False, 'batch_size': 256, 'limit_batch': 1, 'inference_mode': False, 'pin_memory': False,           \n",
       "'prefetch_factor': 2, 'data': {'num_workers': 12, 'shuffle': False}}, 'lr_scheduler': {'name': 'cosine',           \n",
       "'num_warmup_steps': 5000, 'epochs_as_steps': '${equal:${experiment.training.max_steps},-1}'}, 'reset_lr_scheduler':\n",
       "False}, 'dataset': {'debug': '${debug}', 'processed_scene_data_path':                                              \n",
       "'/media/ajad/YourBook/AshokSaugatResearchBackup/AshokSaugatResearch/steerable-scene-generation/MiData',            \n",
       "'model_path_vec_len': 22, 'max_num_objects_per_scene': 12, 'translation_vec_len': 3, 'rotation_parametrization':   \n",
       "'procrustes', 'drake_package_maps': [{'package_name': 'tri', 'package_file_path': 'data/tri/package.xml'},         \n",
       "{'package_name': 'gazebo', 'package_file_path': 'data/gazebo/package.xml'}, {'package_name': 'greg',               \n",
       "'package_file_path': 'data/greg/package.xml'}], 'static_directive': None, 'use_permutation_augmentation': False,   \n",
       "'keep_dataset_in_memory': False, 'classifier_free_guidance': '${algorithm.classifier_free_guidance}',              \n",
       "'custom_data_batch_mix': {'use': False, 'label_probs': [0.5, 0.5]}, 'subdataset_sampling': {'use': False,          \n",
       "'use_infinite_iterators': True, 'buffer_size': 2048, 'probabilities': {}}, 'static_subdataset_prompts': {'use':    \n",
       "False, 'name_to_prompt': {}}, 'random_dataset_sampling': {'use': False, 'num_samples': 1000000.0}, 'val_ratio':    \n",
       "0.01, 'test_ratio': 0.001, '_name': 'custom_scene', 'data': {'path_to_processed_data':                             \n",
       "'/home/pulchowk/ThreedFront', 'path_to_dataset_files': '/home/pulchowk/ThreedFront/dataset_files',                 \n",
       "'dataset_directory': 'bedroom', 'dataset_type': 'cached_threedfront', 'encoding_type':                             \n",
       "'cached_diffusion_cosin_angle_wocm_no_prm', 'annotation_file': 'bedroom_threed_front_splits_original.csv',         \n",
       "'augmentations': ['fixed_rotations'], 'train_stats': 'dataset_stats.txt', 'room_layout_size': '64,64', 'room_type':\n",
       "'bedroom'}, 'network': {'type': 'diffusion_scene_layout_mixed', 'sample_num_points': 12, 'max_cuboids': 19,        \n",
       "'angle_dim': 2, 'room_mask_condition': True, 'room_latent_dim': 64, 'position_condition': False,                   \n",
       "'position_emb_dim': 0, 'time_num': 1000, 'diffusion_semantic_kwargs': {'att_1': 0.99999, 'att_T': 9e-06, 'ctt_1':  \n",
       "9e-06, 'ctt_T': 0.99999, 'model_output_type': 'x0', 'mask_weight': 1, 'auxiliary_loss_weight': 0.0005,             \n",
       "'adaptive_auxiliary_loss': True}, 'diffusion_geometric_kwargs': {'_type': 'fc'}}, 'feature_extractor': {'name':    \n",
       "'pointnet_simple', 'feat_units': [4, 64, 64, 512, 64]}, 'training': {'splits': ['train', 'val'], 'epochs': 50000,  \n",
       "'batch_size': 64, 'n_processes': 1, 'save_frequency': 100, 'max_grad_norm': 10, 'optimizer': 'Adam',               \n",
       "'weight_decay': 0.0, 'schedule': 'step', 'lr': 0.0002, 'lr_step': 10000, 'lr_decay': 0.5}, 'validation': {'splits':\n",
       "['test'], 'frequency': 100, 'batch_size': 64}, 'logger': {'type': 'wandb', 'project': 'MiDiffusion',               \n",
       "'schedule_type': 'linear', 'beta_start': 0.0001, 'beta_end': 0.02, 'loss_type': 'mse', 'model_mean_type': 'eps',   \n",
       "'model_var_type': 'fixedsmall', 'net_type': 'transformer', 'net_kwargs': {'seperate_all': True, 'n_layer': 8,      \n",
       "'n_embd': 512, 'n_head': 4, 'dim_feedforward': 2048, 'dropout': 0.1, 'activate': 'GELU', 'timestep_type':          \n",
       "'adalayernorm_abs', 'mlp_ratio': 4}}, 'sdf_cache_dir': './sdf_cache/', 'accessibility_cache_dir':                  \n",
       "'./accessibility_cache/'}, 'algorithm': {'debug': '${debug}', 'lr': '${experiment.training.lr}', 'dataset':        \n",
       "'${dataset}', 'translation_vec_len': '${dataset.translation_vec_len}', 'rotation_parametrization':                 \n",
       "'${dataset.rotation_parametrization}', 'model_path_vec_len': '${dataset.model_path_vec_len}',                      \n",
       "'max_num_objects_per_scene': '${dataset.max_num_objects_per_scene}', 'processed_scene_data_path':                  \n",
       "'${dataset.processed_scene_data_path}', 'drake_package_maps': '${dataset.drake_package_maps}', 'static_directive': \n",
       "'${dataset.static_directive}', 'trainer': 'mixed', 'lr_scheduler': '${experiment.lr_scheduler}',                   \n",
       "'reset_lr_scheduler': '${experiment.reset_lr_scheduler}', 'weight_decay': '${experiment.training.weight_decay}',   \n",
       "'max_epochs': '${experiment.training.max_epochs}', 'loss': {'use_separate_loss_per_object_attribute': True,        \n",
       "'object_translation_attribute_weight': 1.0, 'object_rotation_attribute_weight': 1.0,                               \n",
       "'object_model_attribute_weight': 1.0, 'use_iou_regularization': False, 'iou_weight': 0.1}, 'noise_schedule':       \n",
       "{'scheduler': 'ddpm', 'num_train_timesteps': 1000, 'beta_schedule': 'linear', 'ddim': {'num_inference_timesteps':  \n",
       "50, 'eta': 1.0}}, 'num_additional_tokens_for_sampling': 0, 'ema': {'use': True, 'log_at_train': False,             \n",
       "'update_after_step': 0.0, 'inv_gamma': 1.0, 'power': 0.75, 'min_value': 0.0, 'max_value': 0.9999},                 \n",
       "'classifier_free_guidance': {'use': True, 'txt_encoder': 'bert', 'txt_encoder_size': 'base', 'txt_encoder_coarse': \n",
       "None, 'txt_encoder_coarse_size': '', 'max_length': 110, 'masking_prob': 0.1, 'masking_prob_coarse': 0.1, 'weight': \n",
       "-1.0, 'sampling': {'use_data_labels': False, 'labels': 'A scene with 10 objects.'}, 'use_floor': False},           \n",
       "'postprocessing': {'apply_non_penetration_projection': False, 'apply_forward_simulation': False, 'num_workers':    \n",
       "100, 'return_original_scenes_on_failure': False, 'non_penetration_projection': {'translation_only': True,          \n",
       "'influence_distance': 0.03, 'solver_name': 'snopt', 'iteration_limit': 5000, 'discard_failed_projection_scenes':   \n",
       "True}, 'forward_simulation': {'simulation_time_s': 2.5, 'time_step': 0.001, 'timeout_s': 180.0}}, 'sample_metrics':\n",
       "{'compute_scene_distance_between_samples': False, 'duplicate_distance_theshold': 0.001,                            \n",
       "'compute_scene_penetration': False, 'batch_size': 100, 'num_workers': 100}, 'visualization': {'use_blender_server':\n",
       "False, 'blender_server_url': 'http://127.0.0.1:8000', 'visualize_proximity': False, 'weld_objects': True,          \n",
       "'camera_pose': {'tri_table': {'xyz': [0.0, 0.0, 1.5], 'rpy': [-3.14, 0.0, 1.57]}, 'dimsum_table': {'xyz': [0.0,    \n",
       "0.0, 1.7], 'rpy': [-3.14, 0.0, 1.57]}, 'shelf': {'xyz': [1.2, 0.0, 0.1], 'rpy': [0.0, -1.57, 0.0]}, 'room': {'xyz':\n",
       "[0.0, 0.0, 13.0], 'rpy': [-3.14, 0.0, 1.57]}}, 'image_width': 640, 'image_height': 480, 'background_color': [1.0,  \n",
       "1.0, 1.0], 'num_workers': 100, 'visualize_intermediate_scenes': False, 'num_intermediate_scenes_to_visualize': 5}, \n",
       "'test': {'use_ema': True, 'num_samples_to_render': 0, 'num_samples_to_render_as_label': 0,                         \n",
       "'num_samples_to_visualize': 0, 'num_directives_to_generate': 0, 'num_samples_to_save_as_pickle': 0,                \n",
       "'sample_batch_size': None}, 'validation': {'num_samples_to_render': 0, 'num_samples_to_visualize': 0,              \n",
       "'num_directives_to_generate': 0, 'num_samples_to_compute_physical_feasibility_metrics_for': 100,                   \n",
       "'sample_batch_size': None}, 'predict': {'do_sample': True, 'do_rearrange': False, 'do_complete': False,            \n",
       "'do_inference_time_search': False, 'do_inpainting': False, 'do_sample_scenes_with_k_closest_training_examples':    \n",
       "False, 'inference_time_search': {'use_non_penetration_objective': False, 'use_physical_feasibility_objective':     \n",
       "False, 'use_object_number_objective': True, 'max_steps': 1000, 'non_penetration': {'threshold': -0.001},           \n",
       "'physical_feasibility': {'use_sim': True, 'sim_duration': 0.1, 'sim_time_step': 0.001, 'sim_translation_threshold':\n",
       "0.001, 'sim_rotation_threshold': 0.01, 'static_equilibrium_distance_threshold': 0.001,                             \n",
       "'exclude_welded_objects_from_non_penetration_masking': True}, 'mcts': {'branching_factor': 3, 'exploration_weight':\n",
       "1.4, 'only_consider_children_with_different_mask': False}}, 'sample_scenes_with_k_closest_training_examples':      \n",
       "{'num_k': 3, 'batch_size': 50000}}, 'custom': {'loss': True, 'obj_vec_len': 30, 'obj_diff_vec_len': 30,            \n",
       "'save_pickle': True, 'num_classes': 22, 'translation_dim': 3, 'size_dim': 3, 'angle_dim': 2, 'objfeat_dim': 0,     \n",
       "'old': False, 'use': True}, 'ddpo': {'use_non_penetration_reward': False, 'use_object_number_reward': False,       \n",
       "'use_prompt_following_reward': False, 'use_physical_feasible_objects_reward': False, 'use_iou_reward': False,      \n",
       "'use_custom_non_penetration_reward': False, 'use_has_sofa_reward': False, 'use_universal_reward': False,           \n",
       "'use_composite_reward': True, 'dynamic_constraint_rewards': {'use': False, 'reward_code_dir':                      \n",
       "'/media/ajad/YourBook/AshokSaugatResearchBackup/AshokSaugatResearch/steerable-scene-generation/dynamic_constraint_r\n",
       "ewards/dynamic_reward_functions', 'user_query': 'a kids room', 'room_type': 'bedroom', 'stats_path':               \n",
       "'/media/ajad/YourBook/AshokSaugatResearchBackup/AshokSaugatResearch/steerable-scene-generation/dynamic_constraint_r\n",
       "ewards/stats.json', 'universal_weight': 1.0, 'dynamic_weight': 1.0, 'universal_importance_weights':                \n",
       "{'must_have_furniture': 1.0, 'non_penetration': 1.0, 'object_count': 1.0}}, 'batch_size': 32,                      \n",
       "'last_n_timesteps_only': 0, 'n_timesteps_to_sample': 0, 'advantage_max': 5.0, 'num_reward_workers': 1, 'ppo':      \n",
       "{'num_epochs': 4, 'clip_range': 0.0001}, 'ddpm_reg_weight': 500.0, 'physical_feasibility':                         \n",
       "{'non_penetration_threshold': -0.001, 'use_sim': True, 'sim_duration': 0.1, 'sim_time_step': 0.001,                \n",
       "'sim_translation_threshold': 0.001, 'sim_rotation_threshold': 0.01, 'static_equilibrium_distance_threshold':       \n",
       "0.001}, 'universal_reward': {'use_physcene_reward': False, 'room_type': 'bedroom', 'importance_weights':           \n",
       "{'must_have_furniture': 1.0, 'gravity': 1.0, 'non_penetration': 1.0, 'object_count': 1.0}}},                       \n",
       "'continuous_discrete_only': {'continuous_only': False, 'discrete_only': False}, 'model': {'seperate_all': True,    \n",
       "'n_layer': 8, 'n_embd': 512, 'n_head': 4, 'dim_feedforward': 2048, 'dropout': 0.1, 'activate': 'GELU',             \n",
       "'timestep_type': 'adalayernorm_abs', 'mlp_type': 'fc'}}, 'debug': False, 'wandb': {'entity': '078bct021-ashok-d',  \n",
       "'project': '3dhope_rl', 'mode': 'online'}, 'resume': None, 'load': None, 'use_best': False, 'checkpoint_version':  \n",
       "None, 'expiration_days': 90}                                                                                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "console.print(Markdown(str(cfg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe53c791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curriculum development based on reward statistics and constraints\n",
    "# constraits cleaning to keep only most relevant constraints and which are not already covered by universal rewards\n",
    "# and return rewards for first stage training\n",
    "# if absolutely necessay, hardcode some feature vectors using impainting, mask and initial scene features with hardcoded values <how to do it, teach it>\n",
    "\n",
    "llm_instruction_3 = f\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "llm_response_3 = None\n",
    "\n",
    "# reward weights for dynamic and universal rewards\n",
    "\n",
    "llm_instruction_4 = f\"\"\"\n",
    "\n",
    "importance weight for each of dynamic and universal reward components. it should be noted that each reward components is converted to the range [-1, 1] before applying the weighted sum so the weights should purely be based on the importance of the rewards. this is aimed to reduce conflicting rewards because some dynamic reward may try to conflict with these universal ones.\n",
    "\"\"\"\n",
    "\n",
    "llm_response_4 = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec6c08f",
   "metadata": {},
   "source": [
    "## Phase 2: RL Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6e6df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run training loop for N steps with the selected rewards and weights,\n",
    "# lr and ddmp_regularization_weight appropriate\n",
    "# if test cases fail or syntax errors occur, provide feedback to LLM with error messages and fix the code automatically"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef08c48c",
   "metadata": {},
   "source": [
    "## Phase 3: Feedback to LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763a290c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run get_reward_stats_from_baseline now baseline is the current model after RL training, get stats\n",
    "\n",
    "llm_instruction_5 = f\"\"\"\n",
    "{all_info_from_phase_1}\n",
    "\n",
    "{feedback_stats}\n",
    "\n",
    "return {\n",
    "  \"rewards\": [\n",
    "    {\n",
    "      \"id\": \"R1\",\n",
    "      \"constraint_id\": \"C1\",\n",
    "      \"name\": \"descriptive_snake_case_name\",\n",
    "      \"code\": \"python code implementing get_reward and test_reward functions as per the template\",\n",
    "      \"success_threshold\": \"value in raw reward units as in python implementation indicating satisfactory fulfillment of the constraint. this will be used to calculate success rate.\"\n",
    "    }\n",
    "  ],\n",
    "  \"weights\": {\n",
    "    \"R1\": x  \n",
    "  }\n",
    "    \n",
    "\n",
    "            \n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f083fb29",
   "metadata": {},
   "source": [
    "## Phase 4: Further RL training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8827a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adcc469",
   "metadata": {},
   "source": [
    "## Repeat if necessary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "steerable-scene-generation-py3.10 (3.10.19)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
