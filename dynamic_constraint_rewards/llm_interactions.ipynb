{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66721571",
   "metadata": {},
   "source": [
    "## PHASE 0: System Initialization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4180206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# different generator for different room types, so different dataset_context for each room type\n",
    "ROOM_TYPE = \"bedroom\"\n",
    "\n",
    "\n",
    "# different generator for different room types, so different dataset_context for each room type\n",
    "ROOM_TYPE = \"bedroom\"\n",
    "# general intro, idx_to_labels, coordinate system, measurement units,\n",
    "def get_dataset_context(room_type):\n",
    "    if room_type == \"bedroom\":\n",
    "        dataset_context = {  \n",
    "            \"room_type\": \"bedroom\",\n",
    "            \"total_scenes\": 4042,\n",
    "            \"class_frequencies\": {\n",
    "                \"nightstand\": 0.27245508982035926,\n",
    "                \"double_bed\": 0.17138137518067315,\n",
    "                \"wardrobe\": 0.16079909147222796,\n",
    "                \"pendant_lamp\": 0.12693578360520338,\n",
    "                \"ceiling_lamp\": 0.06308073508156102,\n",
    "                \"tv_stand\": 0.029888498864340286,\n",
    "                \"chair\": 0.022816436093330582,\n",
    "                \"single_bed\": 0.021216188313029113,\n",
    "                \"dressing_table\": 0.020854842040057817,\n",
    "                \"cabinet\": 0.020183770390253975,\n",
    "                \"table\": 0.019667561428866404,\n",
    "                \"desk\": 0.016260582283708445,\n",
    "                \"stool\": 0.011459838942804047,\n",
    "                \"shelf\": 0.0081561015899236,\n",
    "                \"kids_bed\": 0.0081561015899236,\n",
    "                \"bookshelf\": 0.0071753045632872185,\n",
    "                \"children_cabinet\": 0.0071753045632872185,\n",
    "                \"dressing_chair\": 0.006142886640512079,\n",
    "                \"armchair\": 0.003716704521990502,\n",
    "                \"sofa\": 0.0014970059880239522,\n",
    "                \"coffee_table\": 0.0009807970266363824\n",
    "            },\n",
    "            \"furniture_counts\": {\n",
    "                \"nightstand\": 5278,\n",
    "                \"double_bed\": 3320,\n",
    "                \"wardrobe\": 3115,\n",
    "                \"pendant_lamp\": 2459,\n",
    "                \"ceiling_lamp\": 1222,\n",
    "                \"tv_stand\": 579,\n",
    "                \"chair\": 442,\n",
    "                \"single_bed\": 411,\n",
    "                \"dressing_table\": 404,\n",
    "                \"cabinet\": 391,\n",
    "                \"table\": 381,\n",
    "                \"desk\": 315,\n",
    "                \"stool\": 222,\n",
    "                \"shelf\": 158,\n",
    "                \"kids_bed\": 158,\n",
    "                \"bookshelf\": 139,\n",
    "                \"children_cabinet\": 139,\n",
    "                \"dressing_chair\": 119,\n",
    "                \"armchair\": 72,\n",
    "                \"sofa\": 29,\n",
    "                \"coffee_table\": 19\n",
    "            },\n",
    "            \"idx_to_labels\": {\n",
    "                \"0\": \"armchair\",\n",
    "                \"1\": \"bookshelf\",\n",
    "                \"2\": \"cabinet\",\n",
    "                \"3\": \"ceiling_lamp\",\n",
    "                \"4\": \"chair\",\n",
    "                \"5\": \"children_cabinet\",\n",
    "                \"6\": \"coffee_table\",\n",
    "                \"7\": \"desk\",\n",
    "                \"8\": \"double_bed\",\n",
    "                \"9\": \"dressing_chair\",\n",
    "                \"10\": \"dressing_table\",\n",
    "                \"11\": \"kids_bed\",\n",
    "                \"12\": \"nightstand\",\n",
    "                \"13\": \"pendant_lamp\",\n",
    "                \"14\": \"shelf\",\n",
    "                \"15\": \"single_bed\",\n",
    "                \"16\": \"sofa\",\n",
    "                \"17\": \"stool\",\n",
    "                \"18\": \"table\",\n",
    "                \"19\": \"tv_stand\",\n",
    "                \"20\": \"wardrobe\",\n",
    "                \"21\": \"empty\"\n",
    "            },\n",
    "            \"num_classes_with_empty\": 22,\n",
    "            \"num_classes_without_empty\": 21,\n",
    "            \"room_type\": \"bedroom\",\n",
    "            \"max_objects\": 12\n",
    "        }\n",
    "    elif room_type == \"livingroom\":\n",
    "        dataset_context = {\n",
    "            \"room_type\": \"livingroom\",\n",
    "        \"total_scenes\": 2926,\n",
    "        \"class_frequencies\": {\n",
    "                \"dining_chair\": 0.25492085340674464,\n",
    "                \"pendant_lamp\": 0.13282863041982107,\n",
    "                \"coffee_table\": 0.08616655196145905,\n",
    "                \"corner_side_table\": 0.07240192704748796,\n",
    "                \"dining_table\": 0.06951135581555402,\n",
    "                \"tv_stand\": 0.06221610461114935,\n",
    "                \"multi_seat_sofa\": 0.05299380591878871,\n",
    "                \"armchair\": 0.048313833448038544,\n",
    "                \"console_table\": 0.037026841018582245,\n",
    "                \"lounge_chair\": 0.03234686854783207,\n",
    "                \"stool\": 0.0264280798348245,\n",
    "                \"cabinet\": 0.023124569855471438,\n",
    "                \"bookshelf\": 0.02202339986235375,\n",
    "                \"loveseat_sofa\": 0.020922229869236062,\n",
    "                \"ceiling_lamp\": 0.018169304886441844,\n",
    "                \"wine_cabinet\": 0.012112869924294563,\n",
    "                \"l_shaped_sofa\": 0.01032346868547832,\n",
    "                \"round_end_table\": 0.0057811424638678595,\n",
    "                \"shelf\": 0.0035788024776324846,\n",
    "                \"chinese_chair\": 0.0031658637302133517,\n",
    "                \"wardrobe\": 0.0027529249827942187,\n",
    "                \"chaise_longue_sofa\": 0.0011011699931176876,\n",
    "                \"desk\": 0.0009635237439779766,\n",
    "                \"lazy_sofa\": 0.0008258774948382657\n",
    "            },\n",
    "            \"furniture_counts\": {\n",
    "                \"dining_chair\": 1852,\n",
    "                \"pendant_lamp\": 965,\n",
    "                \"coffee_table\": 626,\n",
    "                \"corner_side_table\": 526,\n",
    "                \"dining_table\": 505,\n",
    "                \"tv_stand\": 452,\n",
    "                \"multi_seat_sofa\": 385,\n",
    "                \"armchair\": 351,\n",
    "                \"console_table\": 269,\n",
    "                \"lounge_chair\": 235,\n",
    "                \"stool\": 192,\n",
    "                \"cabinet\": 168,\n",
    "                \"bookshelf\": 160,\n",
    "                \"loveseat_sofa\": 152,\n",
    "                \"ceiling_lamp\": 132,\n",
    "                \"wine_cabinet\": 88,\n",
    "                \"l_shaped_sofa\": 75,\n",
    "                \"round_end_table\": 42,\n",
    "                \"shelf\": 26,\n",
    "                \"chinese_chair\": 23,\n",
    "                \"wardrobe\": 20,\n",
    "                \"chaise_longue_sofa\": 8,\n",
    "                \"desk\": 7,\n",
    "                \"lazy_sofa\": 6\n",
    "            },\n",
    "            \"idx_to_labels\": {\n",
    "                \"0\": \"armchair\",\n",
    "                \"1\": \"bookshelf\",\n",
    "                \"2\": \"cabinet\",\n",
    "                \"3\": \"ceiling_lamp\",\n",
    "                \"4\": \"chaise_longue_sofa\",\n",
    "                \"5\": \"chinese_chair\",\n",
    "                \"6\": \"coffee_table\",\n",
    "                \"7\": \"console_table\",\n",
    "                \"8\": \"corner_side_table\",\n",
    "                \"9\": \"desk\",\n",
    "                \"10\": \"dining_chair\",\n",
    "                \"11\": \"dining_table\",\n",
    "                \"12\": \"l_shaped_sofa\",\n",
    "                \"13\": \"lazy_sofa\",\n",
    "                \"14\": \"lounge_chair\",\n",
    "                \"15\": \"loveseat_sofa\",\n",
    "                \"16\": \"multi_seat_sofa\",\n",
    "                \"17\": \"pendant_lamp\",\n",
    "                \"18\": \"round_end_table\",\n",
    "                \"19\": \"shelf\",\n",
    "                \"20\": \"stool\",\n",
    "                \"21\": \"tv_stand\",\n",
    "                \"22\": \"wardrobe\",\n",
    "                \"23\": \"wine_cabinet\",\n",
    "                \"24\": \"empty\"\n",
    "                },\n",
    "            \"num_classes_with_empty\": 25,\n",
    "            \"num_classes_without_empty\": 24,\n",
    "            \"room_type\": \"livingroom\",\n",
    "            \"max_objects\": 21\n",
    "        }\n",
    "    else:\n",
    "        raise ValueError(f\"Room type {room_type} not supported\")\n",
    "\n",
    "    return dataset_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "734f48b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_facts = \"\"\"\n",
    "The dataset being used is 3D-FRONT which uses 3D-FUTURE dataset for furniture models. 3D-FRONT is a collection of synthetic, high-quality 3D indoor scenes, highlighted by professionally and distinctively designed layouts.\n",
    "\n",
    "In this dataset, the following facts are important to know:\n",
    "\n",
    "## Coordinate System\n",
    "- Y-axis: Vertical (up direction)\n",
    "- XZ-plane: Floor plane\n",
    "- Units: Meters (world coordinates, unnormalized)\n",
    "- Empty slots: Have index (num_classes-1), near-zero size/position\n",
    "\n",
    "# Important Facts about 3D-FRONT dataset\n",
    "- Ceiling objects are at y ≈ ceiling_height (typically 2.8m)\n",
    "- Floor objects have y ≈ object_height/2\n",
    "- Ignore empty slots (is_empty == True) in calculations\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c6f83c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_representation = \"\"\"\n",
    "A 3D scene is represented in batch format (parsed_scenes) a dictionary with the following keys and PyTorch tensors as values:\n",
    "    - `positions`: (B, N, 3) - Object centroids in meters (x, y, z)\n",
    "    - `sizes`: (B, N, 3) - Half-extents (sx/2, sy/2, sz/2)\n",
    "    - `object_indices`: (B, N) - Class indices [0, num_classes-1]\n",
    "    - `one_hot`: (B, N, num_classes) - One-hot encoded classes\n",
    "    - `is_empty`: (B, N) - Boolean mask (True = empty slot)\n",
    "    - `orientations`: (B, N, 2) - [cos(θ), sin(θ)] for z-rotation\n",
    "    - `device`: torch.device\n",
    "    Where:\n",
    "        - B = Batch size\n",
    "        - N = Max objects per scene\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cad5d80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility functions for reward calculations\n",
    "import torch\n",
    "\n",
    "# Function templates for utility functions used in reward computations\n",
    "def find_object_front_and_back(position, orientation, size):\n",
    "    \"\"\"\n",
    "    Find the coordinates of the front and back centers of a object.\n",
    "\n",
    "    Args:\n",
    "        position: (1,3) tensor - object centroid (x, y, z)\n",
    "        orientation: (1,2) tensor - [cos(θ), sin(θ)], z-rotation\n",
    "        size: (1,3) tensor - half-extents (sx/2, sy/2, sz/2)\n",
    "    \n",
    "    Returns:\n",
    "        front_center: (1,3) tensor - position of object front\n",
    "        back_center: (1,3) tensor - position of object back\n",
    "    \"\"\"\n",
    "    \n",
    "    position_x, position_y, position_z = position[0]\n",
    "    orientation_cos, orientation_sin = orientation[0]\n",
    "    size_x, _, size_z = size[0]\n",
    "\n",
    "    front_center = torch.tensor([position_x + size_x * orientation_cos, position_y, position_z + size_z * orientation_sin], device=position.device)\n",
    "    back_center = torch.tensor([position_x - size_x * orientation_cos, position_y, position_z - size_z * orientation_sin], device=position.device)\n",
    "    return front_center, back_center\n",
    "\n",
    "def find_closest_wall_to_object(position, orientation, size, floor_polygons):\n",
    "    \"\"\"\n",
    "    Find which wall is closest to the object's front or back and compute its distance.\n",
    "\n",
    "    Args:\n",
    "        position: (1,3) tensor - object centroid (x, y, z)\n",
    "        orientation: (1,2) tensor - z-rotation\n",
    "        size: (1,3) tensor - half-extents (sx/2, sy/2, sz/2)\n",
    "        floor_polygons: list of ordered floor polygon vertices in the format [(x1, z1), (x2, z2), ...(xn, zn)]  where n >= 4, and always forms a closed polygon\n",
    "    \n",
    "    Returns:\n",
    "        wall_index: (1) tensor - index of the wall in floor_polygons (i.e., wall_index = 0 means the wall formed by floor_polygons[0] and floor_polygons[1])\n",
    "        distance: (1) tensor - perpendicular distance from object centroid to wall\n",
    "    \"\"\"\n",
    "    front_center, back_center = find_object_front_and_back(position, orientation, size)\n",
    "    distances = []\n",
    "    for i in range(len(floor_polygons)):\n",
    "        point1 = floor_polygons[i]\n",
    "        point2 = floor_polygons[(i+1)%len(floor_polygons)]\n",
    "        midpoint = (point1 + point2) / 2\n",
    "        distance_front = distance_2d(front_center, midpoint)\n",
    "        distance_back = distance_2d(back_center, midpoint)\n",
    "        distances.append(min(distance_front, distance_back))\n",
    "    return distances.index(min(distances)), min(distances)\n",
    "\n",
    "def compute_angle_between_objects(orientation1, orientation2):\n",
    "    \"\"\"\n",
    "    Calculate angle in degrees between two objects in xz-plane.\n",
    "\n",
    "    Args:\n",
    "        orientation1: orientation of object 1,  (1,2) tensor - [cos(θ), sin(θ)], z-rotation\n",
    "        orientation2: orientation of object 2, (1,2) tensor - [cos(θ), sin(θ)], z-rotation\n",
    "\n",
    "    Returns:\n",
    "        angle_radians: (1) tensor - angle between objects\n",
    "    \"\"\"\n",
    "    # Calculate angle in degrees between the facing direction vectors of two objects in xz-plane\n",
    "    # (i.e., project orientation onto xz-plane, compute relative angle)\n",
    "    orientation1_angle = torch.atan2(orientation1[1], orientation1[0])\n",
    "    orientation2_angle = torch.atan2(orientation2[1], orientation2[0])\n",
    "    delta = orientation2_angle - orientation1_angle\n",
    "    # unwrap to [-pi, pi]\n",
    "    angle_radians = (delta + torch.pi) % (2 * torch.pi) - torch.pi\n",
    "    \n",
    "    return angle_radians\n",
    "    \n",
    "def distance_2d(point1, point2):\n",
    "    \"\"\"\n",
    "    Compute Euclidean distance in the XZ plane between two sets of points.\n",
    "\n",
    "    Args:\n",
    "        position1: (1,3) tensor - xyz\n",
    "        position2: (1,3) tensor - xyz\n",
    "\n",
    "    Returns:\n",
    "        distances: (1) tensor - distance between points\n",
    "    \"\"\"\n",
    "    return torch.sqrt((point1[0] - point2[0])**2 + (point1[2] - point2[2])**2)\n",
    "\n",
    "def get_object_count_in_a_scene(one_hot, class_label, idx_to_labels):\n",
    "    \"\"\"\n",
    "    Count number of objects of a specific class in each scene.\n",
    "\n",
    "    Args:\n",
    "        one_hot: (B, N, num_classes) - One-hot encoded classes\n",
    "        class_label: string, e.g. \"ceiling_lamp\"\n",
    "        idx_to_labels: dict, {idx: label}\n",
    "\n",
    "    Returns:\n",
    "        count: int, number of objects of class_label in the scene\n",
    "    \"\"\"\n",
    "    \n",
    "    labels_to_idx = {v: k for k, v in idx_to_labels.items()}\n",
    "    \n",
    "    for i in range(one_hot.shape[1]):\n",
    "        if one_hot[0, i, labels_to_idx[class_label]] == 1.0:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def has_x_meter_clearance(parsed_scenes, x, direction):\n",
    "    \"\"\"\n",
    "    Check whether there is at least x meters of path clearance around objects.\n",
    "\n",
    "    Args:\n",
    "        parsed_scenes: list/dict with scene info\n",
    "        x: float, required clearance in meters\n",
    "        direction: float, z_angle in radians\n",
    "    Returns:\n",
    "        clearance_mask: tensor/list (B,) - True if scene satisfies clearance\n",
    "    \"\"\"\n",
    "    raise NotImplementedError(\"This function is not implemented\")\n",
    "    \n",
    "    \n",
    "\n",
    "# Utility function to create a scene for testing reward functions\n",
    "def create_scene_for_testing(room_type, num_objects, class_label_indices, translations, sizes, orientations):\n",
    "    \"\"\"\n",
    "    Create a scene for testing reward functions.\n",
    "    Input:\n",
    "        room_type: string, Example: \"bedroom\" or \"livingroom\"\n",
    "        num_objects: int, number of objects in the scene\n",
    "        class_label_indices: list of int, class indices\n",
    "        translations: list of tuple, (x, y, z) translations\n",
    "        sizes: list of tuple, (sx/2, sy/2, sz/2) sizes\n",
    "        orientations: list of tuple, (cos(θ), sin(θ)) orientations\n",
    "        \n",
    "    Output:\n",
    "        parsed_scene: dict, scene representation\n",
    "    \"\"\"\n",
    "\n",
    "    # Infer num_classes and max_objects if not provided\n",
    "    if num_classes is None:\n",
    "        num_classes = max(class_label_indices) + 2  # +1 for max idx, +1 for \"empty\"\n",
    "    if max_objects is None:\n",
    "        max_objects = num_objects\n",
    "\n",
    "    B = 1  # Single scene for testing\n",
    "    N = max_objects\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # Create empty arrays\n",
    "    one_hot = torch.zeros(B, N, num_classes, dtype=torch.float32, device=device)\n",
    "    positions = torch.zeros(B, N, 3, dtype=torch.float32, device=device)\n",
    "    obj_sizes = torch.zeros(B, N, 3, dtype=torch.float32, device=device)\n",
    "    obj_orientations = torch.zeros(B, N, 2, dtype=torch.float32, device=device)\n",
    "    object_indices = torch.full((B, N), num_classes-1, dtype=torch.long, device=device)  # default is empty class\n",
    "    is_empty = torch.ones(B, N, dtype=torch.bool, device=device)  # mark all empty by default\n",
    "\n",
    "    for i in range(num_objects):\n",
    "        idx = class_label_indices[i]\n",
    "        one_hot[0, i, idx] = 1.0\n",
    "        positions[0, i] = torch.tensor(translations[i], dtype=torch.float32, device=device)\n",
    "        obj_sizes[0, i] = torch.tensor(sizes[i], dtype=torch.float32, device=device)\n",
    "        obj_orientations[0, i] = torch.tensor(orientations[i], dtype=torch.float32, device=device)\n",
    "        object_indices[0, i] = idx\n",
    "        is_empty[0, i] = False\n",
    "\n",
    "    # Fill the one_hot for empty slots (if any)\n",
    "    for i in range(num_objects, N):\n",
    "        one_hot[0, i, num_classes - 1] = 1.0  # Mark as \"empty\"\n",
    "\n",
    "    parsed_scene = {\n",
    "        \"one_hot\": one_hot,  # (B, N, num_classes)\n",
    "        \"positions\": positions,  # (B, N, 3)\n",
    "        \"sizes\": obj_sizes,      # (B, N, 3) (half-extents)\n",
    "        \"orientations\": obj_orientations,  # (B, N, 2)\n",
    "        \"object_indices\": object_indices,  # (B, N)\n",
    "        \"is_empty\": is_empty,              # (B, N)\n",
    "        \"room_type\": room_type,\n",
    "        \"device\": torch.device(device),\n",
    "    }\n",
    "    return parsed_scene\n",
    "\n",
    "    \n",
    "\n",
    "# A dictionary of all utility functions stated above with key as function name and value as a dictionary with a function and its description (function docstring itself)\n",
    "utility_functions = {\n",
    "    \"find_object_front_and_back\": {\n",
    "        \"function\": find_object_front_and_back,\n",
    "        \"description\": find_object_front_and_back.__doc__,\n",
    "    },\n",
    "    \"find_closest_wall_to_object\": {\n",
    "        \"function\": find_closest_wall_to_object,\n",
    "        \"description\": find_closest_wall_to_object.__doc__,\n",
    "    },\n",
    "    \"compute_angle_between_objects\": {\n",
    "        \"function\": compute_angle_between_objects,\n",
    "        \"description\": compute_angle_between_objects.__doc__,\n",
    "    },\n",
    "    \"distance_2d\": {\n",
    "        \"function\": distance_2d,\n",
    "        \"description\": distance_2d.__doc__,\n",
    "    },\n",
    "    \"get_object_count_in_a_scene\": {\n",
    "        \"function\": get_object_count_in_a_scene,\n",
    "        \"description\": get_object_count_in_a_scene.__doc__,\n",
    "    },\n",
    "    \"has_x_meter_clearance\": {\n",
    "        \"function\": has_x_meter_clearance,\n",
    "        \"description\": has_x_meter_clearance.__doc__,\n",
    "    },\n",
    "    \"create_scene_for_testing\": {\n",
    "        \"function\": create_scene_for_testing,\n",
    "        \"description\": create_scene_for_testing.__doc__,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7386f32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reward function template, put the detailed arg datatypes and descriptions\n",
    "reward_function_template = f\"\"\"\n",
    "def get_reward(parsed_scenes, idx_to_labels, room_type, floor_polygons, **kwargs):\n",
    "    '''\n",
    "    Input:\n",
    "        - parsed_scenes: list of parsed scenes\n",
    "            Format:\n",
    "            Scenes are provided as dictionaries with PyTorch tensors:\n",
    "                - `positions`: (B, N, 3) - Object centroids in meters (x, y, z)\n",
    "                - `sizes`: (B, N, 3) - Half-extents (sx/2, sy/2, sz/2)\n",
    "                - `object_indices`: (B, N) - Class indices [0, num_classes-1]\n",
    "                - `one_hot`: (B, N, num_classes) - One-hot encoded classes\n",
    "                - `is_empty`: (B, N) - Boolean mask (True = empty slot)\n",
    "                - `orientations`: (B, N, 2) - [cos(θ), sin(θ)] for z-rotation\n",
    "                - `device`: torch.device\n",
    "                Where:\n",
    "                    - B = Batch size\n",
    "                    - N = Max objects per scene\n",
    "        \n",
    "        - idx_to_labels: dictionary mapping class indices to class labels\n",
    "        - room_type: string, Example: \"bedroom\" or \"livingroom\"\n",
    "        - Floor Polygons (floor_polygons): A list of ordered floor_polygons in the format [(x1, z1), (x2, z2), ...(xn, zn)]  where n >= 4, and always forms a closed polygon\n",
    "        - **kwargs: additional keyword arguments\n",
    "\n",
    "    Output:\n",
    "        reward: torch.Tensor of shape (len(parsed_scenes),)\n",
    "    '''\n",
    "    \n",
    "    # Logic of reward function here\n",
    "    return reward\n",
    "\n",
    "def test_reward(idx_to_labels, room_type, floor_polygons):\n",
    "    '''\n",
    "    Input:\n",
    "        - idx_to_labels: dictionary mapping class indices to class labels\n",
    "        - room_type: string, Example: \"bedroom\" or \"livingroom\"\n",
    "        - floor_polygons: A list of ordered floor_polygons in the format [(x1, z1), (x2, z2), ...(xn, zn)]  where n >= 4, and always forms a closed polygon\n",
    "    '''\n",
    "    # Create a test scene using create_scene_for_testing\n",
    "    # Scene 1\n",
    "    num_objects_1 = 5\n",
    "    class_label_indices_1 = [0, 1, 2, 3, 4]\n",
    "    translations_1 = [(0, 0, 0), (1, 0, 0), (2, 0, 0), (3, 0, 0), (4, 0, 0)]\n",
    "    sizes_1 = [(0.5, 0.5, 0.5), (0.5, 0.5, 0.5), (0.5, 0.5, 0.5), (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)]\n",
    "    orientations_1 = [(1, 0), (1, 0), (1, 0), (1, 0), (1, 0)]\n",
    "    parsed_scene_1 = create_scene_for_testing(room_type, num_objects_1, class_label_indices_1, translations_1, sizes_1, orientations_1)\n",
    "    \n",
    "    # Scene 2\n",
    "    num_objects_2 = 6\n",
    "    class_label_indices_2 = [0, 1, 2, 3, 4, 5]\n",
    "    translations_2 = [(0, 0, 0), (1, 0, 0), (2, 0, 0), (3, 0, 0), (4, 0, 0), (5, 0, 0),]\n",
    "    sizes_2 = [(0.5, 0.5, 0.5), (0.5, 0.5, 0.5), (0.5, 0.5, 0.5), (0.5, 0.5, 0.5), (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)]\n",
    "    orientations_2 = [(1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0)]\n",
    "    parsed_scene_2 = create_scene_for_testing(room_type, num_objects_2, class_label_indices_2, translations_2, sizes_2, orientations_2)\n",
    "    \n",
    "    # Scene 3\n",
    "    num_objects_3 = 4\n",
    "    class_label_indices_3 = [0, 1, 3, 4]\n",
    "    translations_3 = [(0, 0, 0), (1, 0, 0), (2, 0, 0), (3, 0, 0)]\n",
    "    sizes_3 = [(0.5, 0.5, 0.5), (0.5, 0.5, 0.5), (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)]\n",
    "    orientations_3 = [(1, 0), (1, 0), (1, 0), (1, 0)]\n",
    "    parsed_scene_3 = create_scene_for_testing(room_type, num_objects_3, class_label_indices_3, translations_3, sizes_3, orientations_3)\n",
    "    \n",
    "    \n",
    "    parsed_scenes = torch.stack([parsed_scene_1, parsed_scene_2, parsed_scene_3])\n",
    "    rewards = get_reward(parsed_scenes, idx_to_labels, room_type, floor_polygons)\n",
    "    print(\"Rewards:\", rewards)\n",
    "    assert rewards.shape[0] == len(parsed_scenes)\n",
    "    \n",
    "    # write test cases for different scenarios to test syntax and basic functionality along with reward function specific test cases\n",
    "    # TEST CASES HERE\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3caa372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from universal_constraint_rewards import must_have_furniture_reward, non_penetration_reward, object_count_reward, not_out_of_bound_reward, accessibility_reward, gravity_following_reward, night_tables_on_head_side_reward, axis_alignment_reward, furniture_against_wall_reward\n",
    "# info about universal reward functions\n",
    "\n",
    "from universal_constraint_rewards.commons import get_all_universal_reward_functions\n",
    "\n",
    "universal_rewards_info = get_all_universal_reward_functions()\n",
    "universal_rewards_info_with_docstrings = {}\n",
    "\n",
    "for reward_name, reward_info in universal_rewards_info.items():\n",
    "    universal_rewards_info_with_docstrings[reward_name] = {\n",
    "        \"function\": reward_info,\n",
    "        \"description\": reward_info.__doc__,\n",
    "    }\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "# universal_rewards_info = {\n",
    "#     \"must_have_furniture_reward\": {\n",
    "#         \"function\": must_have_furniture_reward,\n",
    "#         \"description\": must_have_furniture_reward.__doc__,\n",
    "#     },\n",
    "#     \"non_penetration_reward\": {\n",
    "#         \"function\": non_penetration_reward,\n",
    "#         \"description\": non_penetration_reward.__doc__,\n",
    "#     },\n",
    "#     \"object_count_reward\": {\n",
    "#         \"function\": object_count_reward,\n",
    "#         \"description\": object_count_reward.__doc__,\n",
    "#     },\n",
    "#     \"not_out_of_bound_reward\": {\n",
    "#         \"function\": not_out_of_bound_reward,\n",
    "#         \"description\": not_out_of_bound_reward.__doc__,\n",
    "#     },\n",
    "#     \"accessibility_reward\": {\n",
    "#         \"function\": accessibility_reward,\n",
    "#         \"description\": accessibility_reward.__doc__,\n",
    "#     },\n",
    "#     \"gravity_following_reward\": {\n",
    "#         \"function\": gravity_following_reward,\n",
    "#         \"description\": gravity_following_reward.__doc__,\n",
    "#     },\n",
    "#     \"axis_alignment_reward\": {\n",
    "#         \"function\": axis_alignment_reward,\n",
    "#         \"description\": axis_alignment_reward.__doc__,\n",
    "#     },\n",
    "#     \"furniture_against_wall_reward\": {\n",
    "#         \"function\": furniture_against_wall_reward,\n",
    "#         \"description\": furniture_against_wall_reward.__doc__,\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# if ROOM_TYPE == \"bedroom\":\n",
    "#     universal_rewards_info[\"night_tables_on_head_side_reward\"] = {\n",
    "#         \"function\": night_tables_on_head_side_reward,\n",
    "#         \"description\": night_tables_on_head_side_reward.__doc__,\n",
    "#     }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190cb236",
   "metadata": {},
   "source": [
    "## PHASE 1: Initial Constraint Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e821a953",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_PROMPT = \"A bedroom with 4 ceiling_lamps forming a rectangular shape.\" # out of distribution example\n",
    "ROOM_TYPE = \"bedroom\"\n",
    "\n",
    "dataset_context = get_dataset_context(ROOM_TYPE)\n",
    "\n",
    "# Avoid using f-string here to prevent invalid format specifier error\n",
    "llm_instruction_1 = f\"\"\"\n",
    "# TASK: Constraint Decomposition for 3D Scene Generation\n",
    "\n",
    "You are an expert in 3D scene generation, interior design, and reinforcement learning. Your task is to analyze a user prompt and decompose it into verifiable constraints with Python reward functions.\n",
    "\n",
    "## USER PROMPT\n",
    "\\\"{USER_PROMPT}\\\"\n",
    "\n",
    "## CONTEXT\n",
    "\n",
    "### Dataset: 3D-FRONT\n",
    "{dataset_facts}\n",
    "\n",
    "Note: While generating constraints, no need to verify these facts with you constraints, focus on the constraints other than these facts.\n",
    "\n",
    "In this task, you are provided with a user prompt and a dataset context. Your task is to decompose the user prompt into verifiable constraints with Python reward functions.\n",
    "\n",
    "Here is the dataset information in JSON format about the specific room type: {ROOM_TYPE} you will be working on:\n",
    "{dataset_context}\n",
    "\n",
    "\n",
    "## YOUR TASK\n",
    "\n",
    "Analyze the user prompt and provide a comprehensive JSON response with the following structure:\n",
    "\n",
    "### 1. CONSTRAINT DECOMPOSITION\n",
    "\n",
    "Generate ALL constraints needed to satisfy the prompt. For each constraint:\n",
    "\n",
    "```json\n",
    "{{\n",
    "  \"constraints\": [\n",
    "    {{\n",
    "      \"id\": \"C1\",\n",
    "      \"name\": \"descriptive_snake_case_name\",\n",
    "      \"description\": \"Clear description of what this checks\"\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "```\n",
    "\n",
    "Note: The baseline model is already trained on some universal constraints, so you do not need to consider these constraints while generating new ones. The universal constraints are:\n",
    "{universal_rewards_info}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "697377ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# TASK: Constraint Decomposition for 3D Scene Generation\n",
      "\n",
      "You are an expert in 3D scene generation, interior design, and reinforcement learning. Your task is to analyze a user prompt and decompose it into verifiable constraints with Python reward functions.\n",
      "\n",
      "## USER PROMPT\n",
      "\"A bedroom with 4 ceiling_lamps forming a rectangular shape.\"\n",
      "\n",
      "## CONTEXT\n",
      "\n",
      "### Dataset: 3D-FRONT\n",
      "\n",
      "The dataset being used is 3D-FRONT which uses 3D-FUTURE dataset for furniture models. 3D-FRONT is a collection of synthetic, high-quality 3D indoor scenes, highlighted by professionally and distinctively designed layouts.\n",
      "\n",
      "In this dataset, the following facts are important to know:\n",
      "\n",
      "## Coordinate System\n",
      "- Y-axis: Vertical (up direction)\n",
      "- XZ-plane: Floor plane\n",
      "- Units: Meters (world coordinates, unnormalized)\n",
      "- Empty slots: Have index (num_classes-1), near-zero size/position\n",
      "\n",
      "# Important Facts about 3D-FRONT dataset\n",
      "- Ceiling objects are at y ≈ ceiling_height (typically 2.8m)\n",
      "- Floor objects have y ≈ object_height/2\n",
      "- Ignore empty slots (is_empty == True) in calculations\n",
      "\n",
      "\n",
      "In this task, you are provided with a user prompt and a dataset context. Your task is to decompose the user prompt into verifiable constraints with Python reward functions.\n",
      "\n",
      "Here is the dataset information in JSON format about the specific room type: bedroom you will be working on:\n",
      "{'room_type': 'bedroom', 'total_scenes': 4042, 'class_frequencies': {'nightstand': 0.27245508982035926, 'double_bed': 0.17138137518067315, 'wardrobe': 0.16079909147222796, 'pendant_lamp': 0.12693578360520338, 'ceiling_lamp': 0.06308073508156102, 'tv_stand': 0.029888498864340286, 'chair': 0.022816436093330582, 'single_bed': 0.021216188313029113, 'dressing_table': 0.020854842040057817, 'cabinet': 0.020183770390253975, 'table': 0.019667561428866404, 'desk': 0.016260582283708445, 'stool': 0.011459838942804047, 'shelf': 0.0081561015899236, 'kids_bed': 0.0081561015899236, 'bookshelf': 0.0071753045632872185, 'children_cabinet': 0.0071753045632872185, 'dressing_chair': 0.006142886640512079, 'armchair': 0.003716704521990502, 'sofa': 0.0014970059880239522, 'coffee_table': 0.0009807970266363824}, 'furniture_counts': {'nightstand': 5278, 'double_bed': 3320, 'wardrobe': 3115, 'pendant_lamp': 2459, 'ceiling_lamp': 1222, 'tv_stand': 579, 'chair': 442, 'single_bed': 411, 'dressing_table': 404, 'cabinet': 391, 'table': 381, 'desk': 315, 'stool': 222, 'shelf': 158, 'kids_bed': 158, 'bookshelf': 139, 'children_cabinet': 139, 'dressing_chair': 119, 'armchair': 72, 'sofa': 29, 'coffee_table': 19}, 'idx_to_labels': {'0': 'armchair', '1': 'bookshelf', '2': 'cabinet', '3': 'ceiling_lamp', '4': 'chair', '5': 'children_cabinet', '6': 'coffee_table', '7': 'desk', '8': 'double_bed', '9': 'dressing_chair', '10': 'dressing_table', '11': 'kids_bed', '12': 'nightstand', '13': 'pendant_lamp', '14': 'shelf', '15': 'single_bed', '16': 'sofa', '17': 'stool', '18': 'table', '19': 'tv_stand', '20': 'wardrobe', '21': 'empty'}, 'num_classes_with_empty': 22, 'num_classes_without_empty': 21, 'max_objects': 12}\n",
      "\n",
      "\n",
      "## YOUR TASK\n",
      "\n",
      "Analyze the user prompt and provide a comprehensive JSON response with the following structure:\n",
      "\n",
      "### 1. CONSTRAINT DECOMPOSITION\n",
      "\n",
      "Generate ALL constraints needed to satisfy the prompt. For each constraint:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"constraints\": [\n",
      "    {\n",
      "      \"id\": \"C1\",\n",
      "      \"name\": \"descriptive_snake_case_name\",\n",
      "      \"description\": \"Clear description of what this checks\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(llm_instruction_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c380d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"constraints\": [\n",
      "    {\n",
      "      \"id\": \"C1\",\n",
      "      \"name\": \"exact_ceiling_lamp_count\",\n",
      "      \"description\": \"Verifies that the scene contains exactly 4 objects of the class 'ceiling_lamp'.\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"C2\",\n",
      "      \"name\": \"ceiling_lamp_vertical_placement\",\n",
      "      \"description\": \"Verifies that all 'ceiling_lamp' objects are positioned near the ceiling. Based on the 3D-FRONT dataset, their Y-coordinate should be close to the typical ceiling height (e.g., 2.8 meters).\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"C3\",\n",
      "      \"name\": \"ceiling_lamp_rectangular_formation\",\n",
      "      \"description\": \"Verifies that the 3D positions of the four 'ceiling_lamp' objects form a rectangle. This is checked by projecting their positions onto the XZ (floor) plane and ensuring that one of the three possible pairings of the four points results in diagonals that are both equal in length and share a common midpoint. This confirms the quadrilateral is a rectangle.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "llm_response_1 = client.models.generate_content(\n",
    "    model=\"gemini-2.5-pro\",\n",
    "    contents=llm_instruction_1,\n",
    ")\n",
    "\n",
    "print(llm_response_1.text)\n",
    "\n",
    "# TODO: It is rechecking the already stated facts, we need to avoid that. (like ceiling lamps are at ceiling height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa7e009",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'llm_response_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 32\u001b[0m\n\u001b[1;32m      1\u001b[0m llm_instruction_2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124m# TASK: Constraint Decomposition for 3D Scene Generation\u001b[39m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;124mYou are an expert in 3D scene generation, interior design, and reinforcement learning. Your task is to analyze a user prompt and decompose it into verifiable constraints with Python reward functions.\u001b[39m\n\u001b[1;32m      5\u001b[0m \n\u001b[1;32m      6\u001b[0m \u001b[38;5;124m## USER PROMPT\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mUSER_PROMPT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m \u001b[38;5;124m## CONTEXT\u001b[39m\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m \u001b[38;5;124m### Dataset: 3D-FRONT\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;132;01m{\u001b[39;00mdataset_facts\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \n\u001b[1;32m     14\u001b[0m \u001b[38;5;124mIn this task, you are provided with a user prompt and a dataset context. Your task is to decompose the user prompt into verifiable constraints with Python reward functions.\u001b[39m\n\u001b[1;32m     15\u001b[0m \n\u001b[1;32m     16\u001b[0m \u001b[38;5;124mHere is the dataset information in JSON format about the specific room type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mROOM_TYPE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m you will be working on:\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;132;01m{\u001b[39;00mget_dataset_context(ROOM_TYPE)\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \n\u001b[1;32m     19\u001b[0m \n\u001b[1;32m     20\u001b[0m \u001b[38;5;124m### Scene Representation\u001b[39m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;132;01m{\u001b[39;00mscene_representation\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \n\u001b[1;32m     23\u001b[0m \u001b[38;5;124m### Available Utility Functions\u001b[39m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;132;01m{\u001b[39;00mutility_functions\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \n\u001b[1;32m     26\u001b[0m \u001b[38;5;124m### Universal Rewards (Already Implemented)\u001b[39m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;132;01m{\u001b[39;00muniversal_rewards_info\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \n\u001b[1;32m     29\u001b[0m \n\u001b[1;32m     30\u001b[0m \u001b[38;5;124m## YOUR TASK\u001b[39m\n\u001b[1;32m     31\u001b[0m \n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;124mAnalyze the user prompt, constraints to be satisfied for that prompt \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mllm_response_1\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and our codebase information, provide a comprehensive JSON response with the following structure:\u001b[39m\n\u001b[1;32m     33\u001b[0m \n\u001b[1;32m     34\u001b[0m \u001b[38;5;124m### 1. Reward Functions to quantify each constraint satisfaction with signature \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreward_function_template\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \n\u001b[1;32m     36\u001b[0m \u001b[38;5;124m```json\u001b[39m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;132;01m{\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrewards\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m [\u001b[39m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;250m      \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mR1\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;124m      \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstraint_id\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC1\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;124m      \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdescriptive_snake_case_name\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;124m      \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython code implementing get_reward and test_reward functions as per the template\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;124m      \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msuccess_threshold\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue in raw reward units as in python implementation indicating satisfactory fulfillment of the constraint. this will be used to calculate success rate.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;124m  ]\u001b[39m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;124m```\u001b[39m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     51\u001b[0m llm_response_2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'llm_response_1' is not defined"
     ]
    }
   ],
   "source": [
    "llm_instruction_2 = f\"\"\"\n",
    "# TASK: Constraints to reward code mapping\n",
    "\n",
    "You are an expert in 3D scene generation, interior design, and reinforcement learning.\n",
    "Your task is to analyze given constraints and convert them into verifiable reward functions in Python.\n",
    "\n",
    "## USER PROMPT\n",
    "\"{USER_PROMPT}\"\n",
    "\n",
    "## CONTEXT\n",
    "\n",
    "### Dataset: 3D-FRONT\n",
    "{dataset_facts}\n",
    "\n",
    "In this task, you are provided with a user prompt and a dataset context. Your task is to decompose the user prompt into verifiable constraints with Python reward functions.\n",
    "\n",
    "Here is the dataset information in JSON format about the specific room type: {ROOM_TYPE} you will be working on:\n",
    "{get_dataset_context(ROOM_TYPE)}\n",
    "\n",
    "\n",
    "### Scene Representation\n",
    "{scene_representation}\n",
    "\n",
    "### You also have the following utility functions at your disposal which you can use according to the given docstrings.\n",
    "{utility_functions}\n",
    "\n",
    "### We also have trained a baseline model with these universal rewards\n",
    "{universal_rewards_info}\n",
    "\n",
    "\n",
    "## YOUR TASK\n",
    "\n",
    "Analyze the user prompt, constraints to be satisfied for that prompt {llm_response_1} and our codebase information, provide a comprehensive JSON response with the following structure:\n",
    "\n",
    "### 1. Reward Functions to quantify each constraint satisfaction with signature {reward_function_template}\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"rewards\": [\n",
    "    {\n",
    "      \"id\": \"R1\",\n",
    "      \"constraint_id\": \"C1\",\n",
    "      \"name\": \"descriptive_snake_case_name\",\n",
    "      \"code\": \"python code implementing get_reward and test_reward functions as per the template\",\n",
    "      \"success_threshold\": \"value in raw reward units as in python implementation indicating satisfactory fulfillment of the constraint. this will be used to calculate success rate.\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "llm_response_2 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a56910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the get_reward_stats_from_dataset and get_reward_stats_from_baseline functions to get reward statistics, can be helpful to figure out how difficult each constraint is to satisfy for the generator\n",
    "\n",
    "dataset_reward_stats = get_reward_stats_from_dataset(llm_response_2)\n",
    "baseline_reward_stats = get_reward_stats_from_baseline(llm_response_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe53c791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curriculum development based on reward statistics and constraints\n",
    "# constraits cleaning to keep only most relevant constraints and which are not already covered by universal rewards\n",
    "# and return rewards for first stage training\n",
    "# if absolutely necessay, hardcode some feature vectors using impainting, mask and initial scene features with hardcoded values <how to do it, teach it>\n",
    "\n",
    "llm_instruction_3 = f\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "llm_response_3 = None\n",
    "\n",
    "# reward weights for dynamic and universal rewards\n",
    "\n",
    "llm_instruction_4 = f\"\"\"\n",
    "\n",
    "importance weight for each of dynamic and universal reward components. it should be noted that each reward components is converted to the range [-1, 1] before applying the weighted sum so the weights should purely be based on the importance of the rewards. this is aimed to reduce conflicting rewards because some dynamic reward may try to conflict with these universal ones.\n",
    "\"\"\"\n",
    "\n",
    "llm_response_4 = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec6c08f",
   "metadata": {},
   "source": [
    "## Phase 2: RL Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6e6df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run training loop for N steps with the selected rewards and weights,\n",
    "# lr and ddmp_regularization_weight appropriate\n",
    "# if test cases fail or syntax errors occur, provide feedback to LLM with error messages and fix the code automatically"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef08c48c",
   "metadata": {},
   "source": [
    "## Phase 3: Feedback to LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763a290c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run get_reward_stats_from_baseline now baseline is the current model after RL training, get stats\n",
    "\n",
    "llm_instruction_5 = f\"\"\"\n",
    "{all_info_from_phase_1}\n",
    "\n",
    "{feedback_stats}\n",
    "\n",
    "return {\n",
    "  \"rewards\": [\n",
    "    {\n",
    "      \"id\": \"R1\",\n",
    "      \"constraint_id\": \"C1\",\n",
    "      \"name\": \"descriptive_snake_case_name\",\n",
    "      \"code\": \"python code implementing get_reward and test_reward functions as per the template\",\n",
    "      \"success_threshold\": \"value in raw reward units as in python implementation indicating satisfactory fulfillment of the constraint. this will be used to calculate success rate.\"\n",
    "    }\n",
    "  ],\n",
    "  \"weights\": {\n",
    "    \"R1\": x  \n",
    "  }\n",
    "    \n",
    "\n",
    "            \n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f083fb29",
   "metadata": {},
   "source": [
    "## Phase 4: Further RL training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8827a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adcc469",
   "metadata": {},
   "source": [
    "## Repeat if necessary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
